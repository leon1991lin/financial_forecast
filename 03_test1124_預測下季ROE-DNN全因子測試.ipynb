{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c79ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "#建立與 MySQL 的連結\n",
    "class mysql_engine():\n",
    " def __init__(self,db):\n",
    "  self.user='root'\n",
    "  self.passwd=''\n",
    "  self.host='localhost'\n",
    "  self.port = '3306'\n",
    "  self.db_name= db\n",
    "  self.engine = create_engine('mysql+pymysql://{0}:{1}@{2}:{3}/{4}?charset=utf8'.format(self.user,self.passwd,self.host,self.port,self.db_name))\n",
    "\n",
    "def get_data(sql,db):\n",
    " pg_enine = mysql_engine(db)\n",
    " try:\n",
    "  with pg_enine.engine.connect() as con, con.begin():\n",
    "   df = pd.read_sql(sql,con) # 獲取資料\n",
    "  con.close()\n",
    " except:\n",
    "  df = None\n",
    " return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cfd6d1",
   "metadata": {},
   "source": [
    "# 1. 以純財務資料建立最小可行性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb4e83",
   "metadata": {},
   "source": [
    "# 取 X值 (20183-20211) 財務數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96065a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "company_factor = get_data(\"\"\"SELECT \n",
    "                            net_profit_rate,\n",
    "                            operating_gross_rate, \n",
    "                            roe_rate,\n",
    "                            roa_rate,\n",
    "                            current_rate, \n",
    "                            quick_rate,  \n",
    "                            debt_rate,  \n",
    "                            receivables_turnover_rate, \n",
    "                            cash_reinvest_rate\n",
    "                            FROM tfb103d_project.datamining_alldata_afetl\n",
    "                            WHERE stock_report_date < '20212';\"\"\",'tfb103d_project')\n",
    "\n",
    "#稅後淨利率 #營業毛利率 #流動比率 #速動比率 #負債比率 #應收帳款週轉率  #現金再投資比率 #董監事持股比利 \n",
    "#董監事質押比利 #外資持股比例 # >1000張大股東持股比率 # <400張股東持股比率\n",
    "#平均持股張數\n",
    "\n",
    "                            \n",
    "                            \n",
    "company_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "239de635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tibame\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram and normal probability plot\n",
    "from scipy import stats\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "sns.distplot(company_factor['roe_rate']);\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "res = stats.probplot(company_factor['roe_rate'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd2bc445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tibame\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='roe_rate'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(company_factor['roe_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f437c4",
   "metadata": {},
   "source": [
    "# 取 Y值 (20184-20212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a70b212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roe_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>11.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>6.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      roe_rate\n",
       "0         0.42\n",
       "1        -0.20\n",
       "2         0.85\n",
       "3         0.17\n",
       "4        -0.80\n",
       "...        ...\n",
       "1634      4.01\n",
       "1635      6.07\n",
       "1636     11.76\n",
       "1637      4.71\n",
       "1638      6.52\n",
       "\n",
       "[1639 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Roe_rul = get_data(\"\"\"SELECT roe_rate\n",
    "                      FROM tfb103d_project.datamining_alldata_afetl\n",
    "                      WHERE stock_report_date > '20183';\"\"\",'tfb103d_project')\n",
    "Roe_rul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c9285",
   "metadata": {},
   "source": [
    "<h1>資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6fa79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roe_rate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#缺值檢視\n",
    "company_factor.isnull().sum()\n",
    "Roe_rul.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2a4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將數值轉為 1,0 編碼，作為模型的預測目標(應變數)\n",
    "def encoding(r,th):\n",
    "    if r >= th:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d2eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義股東權益報酬率 >平均者為表現良好\n",
    "m2 = Roe_rul['roe_rate'].mean()\n",
    "Roe_rul['roe_rate1'] = Roe_rul.apply(lambda r : encoding(r['roe_rate'],m2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc6d72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  (1639, 9)\n",
      "y.shape:  (1639,)\n",
      "y.sum(): 884\n"
     ]
    }
   ],
   "source": [
    "X = company_factor\n",
    "\n",
    "y = Roe_rul['roe_rate1']\n",
    "\n",
    "print(\"x.shape: \" ,X.shape)\n",
    "print(\"y.shape: \" ,y.shape)\n",
    "print('y.sum():',y.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce922e8d",
   "metadata": {},
   "source": [
    "<h3>ROE:  755 筆標記為 0 ； 884 筆為 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2794c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入數據調成標準值以免各特徵影響不同\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8b354e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tibame\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "sns.distplot(X_scaled[:,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57516542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tibame\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(X_scaled[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "170d89f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 1311 D: 9\n"
     ]
    }
   ],
   "source": [
    "#分割資料為 測試集 與 訓練集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2,random_state=1)\n",
    "N, D = X_train.shape\n",
    "print (\"N:\", N, \"D:\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3624053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout,LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5500f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 DNN模型 for ROE 預測\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(D,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "#編譯模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c658781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1280      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,361\n",
      "Trainable params: 3,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "87ebd2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.6049 - val_loss: 0.5570 - val_accuracy: 0.7774\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7353 - val_loss: 0.4960 - val_accuracy: 0.7957\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.7803 - val_loss: 0.4791 - val_accuracy: 0.8049\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8002 - val_loss: 0.4720 - val_accuracy: 0.7988\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7864 - val_loss: 0.4678 - val_accuracy: 0.8018\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7803 - val_loss: 0.4674 - val_accuracy: 0.8018\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7986 - val_loss: 0.4634 - val_accuracy: 0.8049\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.8108 - val_loss: 0.4612 - val_accuracy: 0.8018\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7979 - val_loss: 0.4589 - val_accuracy: 0.8018\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7979 - val_loss: 0.4588 - val_accuracy: 0.8018\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.8017 - val_loss: 0.4563 - val_accuracy: 0.8049\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8032 - val_loss: 0.4563 - val_accuracy: 0.8018\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.8032 - val_loss: 0.4561 - val_accuracy: 0.8018\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.8154 - val_loss: 0.4565 - val_accuracy: 0.8018\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8093 - val_loss: 0.4563 - val_accuracy: 0.7957\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.8040 - val_loss: 0.4564 - val_accuracy: 0.8049\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8108 - val_loss: 0.4571 - val_accuracy: 0.8079\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.8131 - val_loss: 0.4531 - val_accuracy: 0.8110\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8169 - val_loss: 0.4508 - val_accuracy: 0.8110\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8223 - val_loss: 0.4503 - val_accuracy: 0.8110\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8223 - val_loss: 0.4487 - val_accuracy: 0.8079\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.8207 - val_loss: 0.4488 - val_accuracy: 0.8018\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.8215 - val_loss: 0.4492 - val_accuracy: 0.8079\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.8291 - val_loss: 0.4499 - val_accuracy: 0.8079\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.8223 - val_loss: 0.4491 - val_accuracy: 0.8079\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.8268 - val_loss: 0.4485 - val_accuracy: 0.8079\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8185 - val_loss: 0.4466 - val_accuracy: 0.8049\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.8169 - val_loss: 0.4455 - val_accuracy: 0.8079\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8192 - val_loss: 0.4447 - val_accuracy: 0.8079\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8230 - val_loss: 0.4425 - val_accuracy: 0.8079\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.8146 - val_loss: 0.4427 - val_accuracy: 0.8079\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8200 - val_loss: 0.4444 - val_accuracy: 0.8079\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8238 - val_loss: 0.4435 - val_accuracy: 0.8079\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8276 - val_loss: 0.4426 - val_accuracy: 0.8110\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8223 - val_loss: 0.4441 - val_accuracy: 0.8079\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8307 - val_loss: 0.4436 - val_accuracy: 0.8079\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.8276 - val_loss: 0.4433 - val_accuracy: 0.8079\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8192 - val_loss: 0.4416 - val_accuracy: 0.8079\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8246 - val_loss: 0.4420 - val_accuracy: 0.8110\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8207 - val_loss: 0.4439 - val_accuracy: 0.8049\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8253 - val_loss: 0.4434 - val_accuracy: 0.8140\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8383 - val_loss: 0.4450 - val_accuracy: 0.8079\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.8398 - val_loss: 0.4458 - val_accuracy: 0.8079\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.8207 - val_loss: 0.4454 - val_accuracy: 0.8079\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8230 - val_loss: 0.4450 - val_accuracy: 0.8140\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8291 - val_loss: 0.4468 - val_accuracy: 0.8110\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8284 - val_loss: 0.4450 - val_accuracy: 0.8079\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8200 - val_loss: 0.4467 - val_accuracy: 0.8140\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8322 - val_loss: 0.4473 - val_accuracy: 0.8140\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.8223 - val_loss: 0.4445 - val_accuracy: 0.8140\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "# 四捨五入得到 0,1\n",
    "# 將預測值從(N,1)壓扁成 (N,) \n",
    "P = np.round(pred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9476dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 588us/step - loss: 0.3815 - accuracy: 0.8406\n",
      "Train score: [0.3814779818058014, 0.8405796885490417]\n",
      "11/11 [==============================] - 0s 598us/step - loss: 0.4445 - accuracy: 0.8140\n",
      "Test score: [0.4445402920246124, 0.8140243887901306]\n",
      "f1_score: 0.8355795148247979\n"
     ]
    }
   ],
   "source": [
    "# 評估模型 - evaluate() returns loss and accuracy\n",
    "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
    "print(\"Test score:\", model.evaluate(X_test, y_test))\n",
    "print(\"f1_score:\",f1_score(y_test, P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "7aff8692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f09a864940>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 劃出 model.fit() training 和 validating 的 loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7d3238e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f09ad73700>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 劃出準確性 accuracy \n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b98a0458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,  36],\n",
       "       [ 24, 156]], dtype=int64)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "pred_test = np.round(pred_test).flatten()\n",
    "cm = confusion_matrix(y_test, pred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cad29",
   "metadata": {},
   "source": [
    "# 2.分批加入 環境因素 檢視模型預測能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6453584c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operating_gross_rate</th>\n",
       "      <th>net_profit_rate</th>\n",
       "      <th>revenue_growth_rate</th>\n",
       "      <th>current_rate</th>\n",
       "      <th>quick_rate</th>\n",
       "      <th>debt_rate</th>\n",
       "      <th>receivables_turnover_rate</th>\n",
       "      <th>cash_reinvest_rate</th>\n",
       "      <th>roe_rate</th>\n",
       "      <th>roa_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>export_usd_value_37071000</th>\n",
       "      <th>export_usd_value_37079090</th>\n",
       "      <th>export_usd_value_37050000306</th>\n",
       "      <th>export_usd_value_848620</th>\n",
       "      <th>export_usd_value_848610</th>\n",
       "      <th>export_usd_value_381800</th>\n",
       "      <th>new_cases_smoothed_USA</th>\n",
       "      <th>new_cases_smoothed_OWID_EUR</th>\n",
       "      <th>new_cases_smoothed_TWN</th>\n",
       "      <th>people_fully_vaccinated_per_hundred_USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.03</td>\n",
       "      <td>13.35</td>\n",
       "      <td>17.77</td>\n",
       "      <td>154.53</td>\n",
       "      <td>103.70</td>\n",
       "      <td>18.22</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>433</td>\n",
       "      <td>15698</td>\n",
       "      <td>18323</td>\n",
       "      <td>61504</td>\n",
       "      <td>3021</td>\n",
       "      <td>107270</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.93</td>\n",
       "      <td>5.22</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>166.92</td>\n",
       "      <td>110.41</td>\n",
       "      <td>16.86</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>395</td>\n",
       "      <td>17864</td>\n",
       "      <td>27973</td>\n",
       "      <td>93168</td>\n",
       "      <td>2669</td>\n",
       "      <td>112119</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.03</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-6.33</td>\n",
       "      <td>171.94</td>\n",
       "      <td>109.89</td>\n",
       "      <td>16.38</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>309</td>\n",
       "      <td>16779</td>\n",
       "      <td>17192</td>\n",
       "      <td>72410</td>\n",
       "      <td>4024</td>\n",
       "      <td>96978</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.10</td>\n",
       "      <td>10.26</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>174.72</td>\n",
       "      <td>114.79</td>\n",
       "      <td>16.63</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>326</td>\n",
       "      <td>19927</td>\n",
       "      <td>19788</td>\n",
       "      <td>77517</td>\n",
       "      <td>3432</td>\n",
       "      <td>98799</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.78</td>\n",
       "      <td>2.29</td>\n",
       "      <td>-6.54</td>\n",
       "      <td>170.04</td>\n",
       "      <td>116.92</td>\n",
       "      <td>17.45</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>339</td>\n",
       "      <td>20499</td>\n",
       "      <td>19911</td>\n",
       "      <td>118643</td>\n",
       "      <td>3547</td>\n",
       "      <td>90681</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>30.43</td>\n",
       "      <td>14.75</td>\n",
       "      <td>37.71</td>\n",
       "      <td>326.95</td>\n",
       "      <td>199.20</td>\n",
       "      <td>25.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>6.29</td>\n",
       "      <td>4.71</td>\n",
       "      <td>...</td>\n",
       "      <td>378</td>\n",
       "      <td>22722</td>\n",
       "      <td>18682</td>\n",
       "      <td>71220</td>\n",
       "      <td>2776</td>\n",
       "      <td>95038</td>\n",
       "      <td>1818.75</td>\n",
       "      <td>5251.16</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>24.76</td>\n",
       "      <td>10.91</td>\n",
       "      <td>10.95</td>\n",
       "      <td>299.48</td>\n",
       "      <td>181.73</td>\n",
       "      <td>27.74</td>\n",
       "      <td>4.28</td>\n",
       "      <td>6.49</td>\n",
       "      <td>4.01</td>\n",
       "      <td>2.97</td>\n",
       "      <td>...</td>\n",
       "      <td>474</td>\n",
       "      <td>20831</td>\n",
       "      <td>23548</td>\n",
       "      <td>83758</td>\n",
       "      <td>1824</td>\n",
       "      <td>93532</td>\n",
       "      <td>26218.70</td>\n",
       "      <td>22066.62</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>22.61</td>\n",
       "      <td>15.41</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>363.99</td>\n",
       "      <td>240.63</td>\n",
       "      <td>23.66</td>\n",
       "      <td>6.20</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.61</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>21623</td>\n",
       "      <td>21166</td>\n",
       "      <td>88039</td>\n",
       "      <td>509</td>\n",
       "      <td>96949</td>\n",
       "      <td>50018.10</td>\n",
       "      <td>27565.47</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>23.05</td>\n",
       "      <td>29.47</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>317.33</td>\n",
       "      <td>230.20</td>\n",
       "      <td>26.09</td>\n",
       "      <td>8.12</td>\n",
       "      <td>11.28</td>\n",
       "      <td>11.76</td>\n",
       "      <td>8.79</td>\n",
       "      <td>...</td>\n",
       "      <td>338</td>\n",
       "      <td>22734</td>\n",
       "      <td>26507</td>\n",
       "      <td>125111</td>\n",
       "      <td>2209</td>\n",
       "      <td>104276</td>\n",
       "      <td>134753.31</td>\n",
       "      <td>197678.98</td>\n",
       "      <td>7.04</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>29.71</td>\n",
       "      <td>13.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>281.91</td>\n",
       "      <td>191.93</td>\n",
       "      <td>29.32</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-3.70</td>\n",
       "      <td>4.71</td>\n",
       "      <td>3.41</td>\n",
       "      <td>...</td>\n",
       "      <td>295</td>\n",
       "      <td>21578</td>\n",
       "      <td>21595</td>\n",
       "      <td>173860</td>\n",
       "      <td>3284</td>\n",
       "      <td>108639</td>\n",
       "      <td>120178.33</td>\n",
       "      <td>179397.16</td>\n",
       "      <td>6.49</td>\n",
       "      <td>15.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      operating_gross_rate  net_profit_rate  revenue_growth_rate  \\\n",
       "0                    38.03            13.35                17.77   \n",
       "1                    40.93             5.22                -0.91   \n",
       "2                    37.03            -3.00                -6.33   \n",
       "3                    32.10            10.26                -2.46   \n",
       "4                    28.78             2.29                -6.54   \n",
       "...                    ...              ...                  ...   \n",
       "1634                 30.43            14.75                37.71   \n",
       "1635                 24.76            10.91                10.95   \n",
       "1636                 22.61            15.41                -3.71   \n",
       "1637                 23.05            29.47                -2.52   \n",
       "1638                 29.71            13.09                 0.17   \n",
       "\n",
       "      current_rate  quick_rate  debt_rate  receivables_turnover_rate  \\\n",
       "0           154.53      103.70      18.22                       3.31   \n",
       "1           166.92      110.41      16.86                       4.35   \n",
       "2           171.94      109.89      16.38                       0.99   \n",
       "3           174.72      114.79      16.63                       2.00   \n",
       "4           170.04      116.92      17.45                       3.10   \n",
       "...            ...         ...        ...                        ...   \n",
       "1634        326.95      199.20      25.75                       1.99   \n",
       "1635        299.48      181.73      27.74                       4.28   \n",
       "1636        363.99      240.63      23.66                       6.20   \n",
       "1637        317.33      230.20      26.09                       8.12   \n",
       "1638        281.91      191.93      29.32                       1.95   \n",
       "\n",
       "      cash_reinvest_rate  roe_rate  roa_rate  ...  export_usd_value_37071000  \\\n",
       "0                   1.74      1.07      0.91  ...                        433   \n",
       "1                   1.34      0.42      0.37  ...                        395   \n",
       "2                   1.51     -0.20     -0.14  ...                        309   \n",
       "3                   2.17      0.85      0.74  ...                        326   \n",
       "4                   4.32      0.17      0.17  ...                        339   \n",
       "...                  ...       ...       ...  ...                        ...   \n",
       "1634               -0.03      6.29      4.71  ...                        378   \n",
       "1635                6.49      4.01      2.97  ...                        474   \n",
       "1636                5.25      6.07      4.61  ...                        362   \n",
       "1637               11.28     11.76      8.79  ...                        338   \n",
       "1638               -3.70      4.71      3.41  ...                        295   \n",
       "\n",
       "      export_usd_value_37079090  export_usd_value_37050000306  \\\n",
       "0                         15698                         18323   \n",
       "1                         17864                         27973   \n",
       "2                         16779                         17192   \n",
       "3                         19927                         19788   \n",
       "4                         20499                         19911   \n",
       "...                         ...                           ...   \n",
       "1634                      22722                         18682   \n",
       "1635                      20831                         23548   \n",
       "1636                      21623                         21166   \n",
       "1637                      22734                         26507   \n",
       "1638                      21578                         21595   \n",
       "\n",
       "      export_usd_value_848620  export_usd_value_848610  \\\n",
       "0                       61504                     3021   \n",
       "1                       93168                     2669   \n",
       "2                       72410                     4024   \n",
       "3                       77517                     3432   \n",
       "4                      118643                     3547   \n",
       "...                       ...                      ...   \n",
       "1634                    71220                     2776   \n",
       "1635                    83758                     1824   \n",
       "1636                    88039                      509   \n",
       "1637                   125111                     2209   \n",
       "1638                   173860                     3284   \n",
       "\n",
       "      export_usd_value_381800  new_cases_smoothed_USA  \\\n",
       "0                      107270                    0.00   \n",
       "1                      112119                    0.00   \n",
       "2                       96978                    0.00   \n",
       "3                       98799                    0.00   \n",
       "4                       90681                    0.00   \n",
       "...                       ...                     ...   \n",
       "1634                    95038                 1818.75   \n",
       "1635                    93532                26218.70   \n",
       "1636                    96949                50018.10   \n",
       "1637                   104276               134753.31   \n",
       "1638                   108639               120178.33   \n",
       "\n",
       "      new_cases_smoothed_OWID_EUR  new_cases_smoothed_TWN  \\\n",
       "0                            0.00                    0.00   \n",
       "1                            0.00                    0.00   \n",
       "2                            0.00                    0.00   \n",
       "3                            0.00                    0.00   \n",
       "4                            0.00                    0.00   \n",
       "...                           ...                     ...   \n",
       "1634                      5251.16                    6.72   \n",
       "1635                     22066.62                    4.34   \n",
       "1636                     27565.47                    4.07   \n",
       "1637                    197678.98                    7.04   \n",
       "1638                    179397.16                    6.49   \n",
       "\n",
       "      people_fully_vaccinated_per_hundred_USA  \n",
       "0                                        0.00  \n",
       "1                                        0.00  \n",
       "2                                        0.00  \n",
       "3                                        0.00  \n",
       "4                                        0.00  \n",
       "...                                       ...  \n",
       "1634                                     0.00  \n",
       "1635                                     0.00  \n",
       "1636                                     0.00  \n",
       "1637                                     0.29  \n",
       "1638                                    15.95  \n",
       "\n",
       "[1639 rows x 61 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取得需要的特徵\n",
    "addenv_factor2 = get_data(\"\"\"SELECT *\n",
    "                            FROM tfb103d_project.datamining_alldata_afetl\n",
    "                            WHERE stock_report_date < '20212';\"\"\",'tfb103d_project')\n",
    "\n",
    "addenv_factor2 = addenv_factor2.drop([\"stock_code\",\"stock_report_date\"],axis = 1 )\n",
    "\n",
    "addenv_factor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b90d25a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2.shape:  (1639, 61)\n",
      "y1.shape:  (1639,)\n",
      "y1.sum(): 884\n"
     ]
    }
   ],
   "source": [
    "X2 = addenv_factor2\n",
    "\n",
    "y1 = Roe_rul['roe_rate1']\n",
    "print(\"X2.shape: \" ,X2.shape)\n",
    "print(\"y1.shape: \" ,y1.shape)\n",
    "print('y1.sum():',y1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4de3c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入數據調成標準值以免各特徵影響不同\n",
    "# you'll learn why scaling is needed in a later course\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "def mean_norm(df_input):\n",
    "    return df_input.apply(lambda x: ((x-df_input.mean())/ df_input.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62acac0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operating_gross_rate</th>\n",
       "      <th>net_profit_rate</th>\n",
       "      <th>revenue_growth_rate</th>\n",
       "      <th>current_rate</th>\n",
       "      <th>quick_rate</th>\n",
       "      <th>debt_rate</th>\n",
       "      <th>receivables_turnover_rate</th>\n",
       "      <th>cash_reinvest_rate</th>\n",
       "      <th>roe_rate</th>\n",
       "      <th>roa_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>export_usd_value_37071000</th>\n",
       "      <th>export_usd_value_37079090</th>\n",
       "      <th>export_usd_value_37050000306</th>\n",
       "      <th>export_usd_value_848620</th>\n",
       "      <th>export_usd_value_848610</th>\n",
       "      <th>export_usd_value_381800</th>\n",
       "      <th>new_cases_smoothed_USA</th>\n",
       "      <th>new_cases_smoothed_OWID_EUR</th>\n",
       "      <th>new_cases_smoothed_TWN</th>\n",
       "      <th>people_fully_vaccinated_per_hundred_USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310530</td>\n",
       "      <td>0.214147</td>\n",
       "      <td>0.195944</td>\n",
       "      <td>-0.553189</td>\n",
       "      <td>-0.513366</td>\n",
       "      <td>-0.818028</td>\n",
       "      <td>-0.161824</td>\n",
       "      <td>-0.205327</td>\n",
       "      <td>-0.182515</td>\n",
       "      <td>-0.220846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.373233</td>\n",
       "      <td>-1.970904</td>\n",
       "      <td>-0.906099</td>\n",
       "      <td>-1.108827</td>\n",
       "      <td>0.353536</td>\n",
       "      <td>1.099460</td>\n",
       "      <td>-0.625915</td>\n",
       "      <td>-0.552314</td>\n",
       "      <td>-0.874567</td>\n",
       "      <td>-0.322412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.420361</td>\n",
       "      <td>0.060193</td>\n",
       "      <td>-0.294623</td>\n",
       "      <td>-0.520781</td>\n",
       "      <td>-0.494960</td>\n",
       "      <td>-0.898471</td>\n",
       "      <td>-0.064074</td>\n",
       "      <td>-0.239816</td>\n",
       "      <td>-0.290044</td>\n",
       "      <td>-0.381183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645715</td>\n",
       "      <td>-1.007964</td>\n",
       "      <td>2.049630</td>\n",
       "      <td>-0.080664</td>\n",
       "      <td>-0.027240</td>\n",
       "      <td>1.817215</td>\n",
       "      <td>-0.625915</td>\n",
       "      <td>-0.552314</td>\n",
       "      <td>-0.874567</td>\n",
       "      <td>-0.322412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.272657</td>\n",
       "      <td>-0.095466</td>\n",
       "      <td>-0.436961</td>\n",
       "      <td>-0.507650</td>\n",
       "      <td>-0.496387</td>\n",
       "      <td>-0.926863</td>\n",
       "      <td>-0.379883</td>\n",
       "      <td>-0.225158</td>\n",
       "      <td>-0.392611</td>\n",
       "      <td>-0.532612</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000772</td>\n",
       "      <td>-1.490323</td>\n",
       "      <td>-1.252516</td>\n",
       "      <td>-0.754698</td>\n",
       "      <td>1.438532</td>\n",
       "      <td>-0.423973</td>\n",
       "      <td>-0.625915</td>\n",
       "      <td>-0.552314</td>\n",
       "      <td>-0.874567</td>\n",
       "      <td>-0.322412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085944</td>\n",
       "      <td>0.155633</td>\n",
       "      <td>-0.335329</td>\n",
       "      <td>-0.500379</td>\n",
       "      <td>-0.482945</td>\n",
       "      <td>-0.912075</td>\n",
       "      <td>-0.284953</td>\n",
       "      <td>-0.168251</td>\n",
       "      <td>-0.218909</td>\n",
       "      <td>-0.271322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675303</td>\n",
       "      <td>-0.090814</td>\n",
       "      <td>-0.457379</td>\n",
       "      <td>-0.588868</td>\n",
       "      <td>0.798135</td>\n",
       "      <td>-0.154426</td>\n",
       "      <td>-0.625915</td>\n",
       "      <td>-0.552314</td>\n",
       "      <td>-0.874567</td>\n",
       "      <td>-0.322412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.039793</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>-0.442476</td>\n",
       "      <td>-0.512620</td>\n",
       "      <td>-0.477102</td>\n",
       "      <td>-0.863573</td>\n",
       "      <td>-0.181562</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>-0.331402</td>\n",
       "      <td>-0.440567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426416</td>\n",
       "      <td>0.163481</td>\n",
       "      <td>-0.419705</td>\n",
       "      <td>0.746536</td>\n",
       "      <td>0.922537</td>\n",
       "      <td>-1.356062</td>\n",
       "      <td>-0.625915</td>\n",
       "      <td>-0.552314</td>\n",
       "      <td>-0.874567</td>\n",
       "      <td>-0.322412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0.022697</td>\n",
       "      <td>0.240658</td>\n",
       "      <td>0.719600</td>\n",
       "      <td>-0.102197</td>\n",
       "      <td>-0.251399</td>\n",
       "      <td>-0.372635</td>\n",
       "      <td>-0.285892</td>\n",
       "      <td>-0.357940</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.907451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320247</td>\n",
       "      <td>1.151762</td>\n",
       "      <td>-0.796139</td>\n",
       "      <td>-0.793339</td>\n",
       "      <td>0.088507</td>\n",
       "      <td>-0.711134</td>\n",
       "      <td>-0.588310</td>\n",
       "      <td>-0.478457</td>\n",
       "      <td>1.381120</td>\n",
       "      <td>-0.322412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>-0.192042</td>\n",
       "      <td>0.167942</td>\n",
       "      <td>0.016839</td>\n",
       "      <td>-0.174049</td>\n",
       "      <td>-0.299321</td>\n",
       "      <td>-0.254929</td>\n",
       "      <td>-0.070653</td>\n",
       "      <td>0.204228</td>\n",
       "      <td>0.303849</td>\n",
       "      <td>0.390810</td>\n",
       "      <td>...</td>\n",
       "      <td>2.158186</td>\n",
       "      <td>0.311078</td>\n",
       "      <td>0.694283</td>\n",
       "      <td>-0.386217</td>\n",
       "      <td>-0.941320</td>\n",
       "      <td>-0.934054</td>\n",
       "      <td>-0.083800</td>\n",
       "      <td>-0.241950</td>\n",
       "      <td>0.582231</td>\n",
       "      <td>-0.322412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>-0.273468</td>\n",
       "      <td>0.253157</td>\n",
       "      <td>-0.368156</td>\n",
       "      <td>-0.005312</td>\n",
       "      <td>-0.137752</td>\n",
       "      <td>-0.496257</td>\n",
       "      <td>0.109809</td>\n",
       "      <td>0.097313</td>\n",
       "      <td>0.644634</td>\n",
       "      <td>0.877759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.663179</td>\n",
       "      <td>-0.035307</td>\n",
       "      <td>-0.247208</td>\n",
       "      <td>-2.363822</td>\n",
       "      <td>-0.428265</td>\n",
       "      <td>0.408293</td>\n",
       "      <td>-0.164609</td>\n",
       "      <td>0.491601</td>\n",
       "      <td>-0.322412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>-0.256804</td>\n",
       "      <td>0.519405</td>\n",
       "      <td>-0.336905</td>\n",
       "      <td>-0.127359</td>\n",
       "      <td>-0.166362</td>\n",
       "      <td>-0.352525</td>\n",
       "      <td>0.290272</td>\n",
       "      <td>0.617232</td>\n",
       "      <td>1.585929</td>\n",
       "      <td>2.118886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.445561</td>\n",
       "      <td>1.157097</td>\n",
       "      <td>1.600605</td>\n",
       "      <td>0.956559</td>\n",
       "      <td>-0.524846</td>\n",
       "      <td>0.656285</td>\n",
       "      <td>2.160336</td>\n",
       "      <td>2.228015</td>\n",
       "      <td>1.488534</td>\n",
       "      <td>-0.259081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>-0.004572</td>\n",
       "      <td>0.209224</td>\n",
       "      <td>-0.266261</td>\n",
       "      <td>-0.220006</td>\n",
       "      <td>-0.271341</td>\n",
       "      <td>-0.161473</td>\n",
       "      <td>-0.289652</td>\n",
       "      <td>-0.674375</td>\n",
       "      <td>0.419650</td>\n",
       "      <td>0.521455</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.268804</td>\n",
       "      <td>0.643173</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>2.539490</td>\n",
       "      <td>0.638036</td>\n",
       "      <td>1.302101</td>\n",
       "      <td>1.858974</td>\n",
       "      <td>1.970883</td>\n",
       "      <td>1.303916</td>\n",
       "      <td>3.160794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      operating_gross_rate  net_profit_rate  revenue_growth_rate  \\\n",
       "0                 0.310530         0.214147             0.195944   \n",
       "1                 0.420361         0.060193            -0.294623   \n",
       "2                 0.272657        -0.095466            -0.436961   \n",
       "3                 0.085944         0.155633            -0.335329   \n",
       "4                -0.039793         0.004708            -0.442476   \n",
       "...                    ...              ...                  ...   \n",
       "1634              0.022697         0.240658             0.719600   \n",
       "1635             -0.192042         0.167942             0.016839   \n",
       "1636             -0.273468         0.253157            -0.368156   \n",
       "1637             -0.256804         0.519405            -0.336905   \n",
       "1638             -0.004572         0.209224            -0.266261   \n",
       "\n",
       "      current_rate  quick_rate  debt_rate  receivables_turnover_rate  \\\n",
       "0        -0.553189   -0.513366  -0.818028                  -0.161824   \n",
       "1        -0.520781   -0.494960  -0.898471                  -0.064074   \n",
       "2        -0.507650   -0.496387  -0.926863                  -0.379883   \n",
       "3        -0.500379   -0.482945  -0.912075                  -0.284953   \n",
       "4        -0.512620   -0.477102  -0.863573                  -0.181562   \n",
       "...            ...         ...        ...                        ...   \n",
       "1634     -0.102197   -0.251399  -0.372635                  -0.285892   \n",
       "1635     -0.174049   -0.299321  -0.254929                  -0.070653   \n",
       "1636     -0.005312   -0.137752  -0.496257                   0.109809   \n",
       "1637     -0.127359   -0.166362  -0.352525                   0.290272   \n",
       "1638     -0.220006   -0.271341  -0.161473                  -0.289652   \n",
       "\n",
       "      cash_reinvest_rate  roe_rate  roa_rate  ...  export_usd_value_37071000  \\\n",
       "0              -0.205327 -0.182515 -0.220846  ...                   1.373233   \n",
       "1              -0.239816 -0.290044 -0.381183  ...                   0.645715   \n",
       "2              -0.225158 -0.392611 -0.532612  ...                  -1.000772   \n",
       "3              -0.168251 -0.218909 -0.271322  ...                  -0.675303   \n",
       "4               0.017126 -0.331402 -0.440567  ...                  -0.426416   \n",
       "...                  ...       ...       ...  ...                        ...   \n",
       "1634           -0.357940  0.681029  0.907451  ...                   0.320247   \n",
       "1635            0.204228  0.303849  0.390810  ...                   2.158186   \n",
       "1636            0.097313  0.644634  0.877759  ...                   0.013924   \n",
       "1637            0.617232  1.585929  2.118886  ...                  -0.445561   \n",
       "1638           -0.674375  0.419650  0.521455  ...                  -1.268804   \n",
       "\n",
       "      export_usd_value_37079090  export_usd_value_37050000306  \\\n",
       "0                     -1.970904                     -0.906099   \n",
       "1                     -1.007964                      2.049630   \n",
       "2                     -1.490323                     -1.252516   \n",
       "3                     -0.090814                     -0.457379   \n",
       "4                      0.163481                     -0.419705   \n",
       "...                         ...                           ...   \n",
       "1634                   1.151762                     -0.796139   \n",
       "1635                   0.311078                      0.694283   \n",
       "1636                   0.663179                     -0.035307   \n",
       "1637                   1.157097                      1.600605   \n",
       "1638                   0.643173                      0.096093   \n",
       "\n",
       "      export_usd_value_848620  export_usd_value_848610  \\\n",
       "0                   -1.108827                 0.353536   \n",
       "1                   -0.080664                -0.027240   \n",
       "2                   -0.754698                 1.438532   \n",
       "3                   -0.588868                 0.798135   \n",
       "4                    0.746536                 0.922537   \n",
       "...                       ...                      ...   \n",
       "1634                -0.793339                 0.088507   \n",
       "1635                -0.386217                -0.941320   \n",
       "1636                -0.247208                -2.363822   \n",
       "1637                 0.956559                -0.524846   \n",
       "1638                 2.539490                 0.638036   \n",
       "\n",
       "      export_usd_value_381800  new_cases_smoothed_USA  \\\n",
       "0                    1.099460               -0.625915   \n",
       "1                    1.817215               -0.625915   \n",
       "2                   -0.423973               -0.625915   \n",
       "3                   -0.154426               -0.625915   \n",
       "4                   -1.356062               -0.625915   \n",
       "...                       ...                     ...   \n",
       "1634                -0.711134               -0.588310   \n",
       "1635                -0.934054               -0.083800   \n",
       "1636                -0.428265                0.408293   \n",
       "1637                 0.656285                2.160336   \n",
       "1638                 1.302101                1.858974   \n",
       "\n",
       "      new_cases_smoothed_OWID_EUR  new_cases_smoothed_TWN  \\\n",
       "0                       -0.552314               -0.874567   \n",
       "1                       -0.552314               -0.874567   \n",
       "2                       -0.552314               -0.874567   \n",
       "3                       -0.552314               -0.874567   \n",
       "4                       -0.552314               -0.874567   \n",
       "...                           ...                     ...   \n",
       "1634                    -0.478457                1.381120   \n",
       "1635                    -0.241950                0.582231   \n",
       "1636                    -0.164609                0.491601   \n",
       "1637                     2.228015                1.488534   \n",
       "1638                     1.970883                1.303916   \n",
       "\n",
       "      people_fully_vaccinated_per_hundred_USA  \n",
       "0                                   -0.322412  \n",
       "1                                   -0.322412  \n",
       "2                                   -0.322412  \n",
       "3                                   -0.322412  \n",
       "4                                   -0.322412  \n",
       "...                                       ...  \n",
       "1634                                -0.322412  \n",
       "1635                                -0.322412  \n",
       "1636                                -0.322412  \n",
       "1637                                -0.259081  \n",
       "1638                                 3.160794  \n",
       "\n",
       "[1639 rows x 61 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_scaled = pd.DataFrame()\n",
    "a, b = X2.shape\n",
    "\n",
    "for i in range(b):\n",
    "    x2_new = mean_norm(X2[X2.columns[i]])\n",
    "    X2_scaled.insert(i,X2.columns[i],x2_new)\n",
    "X2_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b075b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 1311 D: 61\n"
     ]
    }
   ],
   "source": [
    "#分割資料為 測試集 與 訓練集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2_train, X2_test, y1_train, y1_test = train_test_split(X2_scaled, y1, test_size=0.2,random_state=1)\n",
    "N, D = X2_train.shape\n",
    "print (\"N:\", N, \"D:\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d88eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入數據調成標準值以免各特徵影響不同\n",
    "def mean_norm(df_input):\n",
    "    return df_input.apply(lambda x: ((x-df_input.mean())/ df_input.std()))\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e10e1",
   "metadata": {},
   "source": [
    "# 以迴圈處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54885694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import_list = addenv_factor2.columns[11:]\n",
    "result_list = []\n",
    "for item in import_list:\n",
    "    Xt = addenv_factor2[['net_profit_rate',\n",
    "                        'operating_gross_rate', \n",
    "                        'roe_rate',\n",
    "                        'roa_rate',\n",
    "                        'current_rate', \n",
    "                        'quick_rate',  \n",
    "                        'debt_rate',  \n",
    "                        'receivables_turnover_rate', \n",
    "                        'cash_reinvest_rate',\n",
    "                        item\n",
    "                        ]]\n",
    "\n",
    "    y1 = Roe_rul['roe_rate1']\n",
    "\n",
    "    Xt_scaled = pd.DataFrame()\n",
    "    a, b = Xt.shape\n",
    "\n",
    "    for i in range(b):\n",
    "        xt_new = mean_norm(Xt[Xt.columns[i]])\n",
    "        Xt_scaled.insert(i,Xt.columns[i],xt_new)\n",
    "\n",
    "\n",
    "    #分割資料為 測試集 與 訓練集\n",
    "    Xt_train, Xt_test, y1_train, y1_test = train_test_split(Xt_scaled, y1, test_size=0.2, random_state=1)\n",
    "    N, D = Xt_train.shape\n",
    "\n",
    "    for i in range(1,6):\n",
    "        \n",
    "        # 建立 DNN 模型\n",
    "        modelt = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Input(shape=(D,)),\n",
    "          tf.keras.layers.Dense(128, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.6),\n",
    "          tf.keras.layers.Dense(16, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.4),\n",
    "          tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "          ])\n",
    "\n",
    "        #編譯模型\n",
    "        modelt.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "#         modelt.summary()\n",
    "\n",
    "        # 訓練模型\n",
    "        rt = modelt.fit(Xt_train, y1_train, validation_data=(Xt_test, y1_test), epochs=50, verbose = 0 )\n",
    "        pred = modelt.predict(Xt_test)\n",
    "        P = np.round(pred).flatten()\n",
    "        tmp = [str(item)]\n",
    "        tmp.extend(modelt.evaluate(Xt_train, y1_train))\n",
    "        tmp.extend(modelt.evaluate(Xt_test, y1_test))\n",
    "        tmp.append(f1_score(y1_test, P))\n",
    "\n",
    "        # 評估模型 - evaluate() returns loss and accuracy\n",
    "        print(\"Train score:\", modelt.evaluate(Xt_train, y1_train))\n",
    "        print(\"Test score:\", modelt.evaluate(Xt_test, y1_test))\n",
    "        print(\"f1_score:\",f1_score(y1_test, P))\n",
    "        result_list.append(tmp)\n",
    "\n",
    "#         plt.plot(rt.history['loss'], label='loss')\n",
    "#         plt.plot(rt.history['val_loss'], label='val_loss')\n",
    "#         plt.legend()\n",
    "#         plt.savefig(f'./results/pre1_loss_{import_list[item]}_{i}.png')#儲存圖片\n",
    "#         plt.show() \n",
    "\n",
    "#         plt.plot(rt.history['accuracy'], label='acc')\n",
    "#         plt.plot(rt.history['val_accuracy'], label='val_acc')\n",
    "#         plt.legend()\n",
    "#         plt.savefig(f'./results/pre1_accuracy_{import_list[item]}_{i}.png')#儲存圖片\n",
    "#         plt.show() \n",
    "\n",
    "result_pd = pd.DataFrame(result_list,columns=[\"item\",\"train_loss\",\"train_accuracy\",\"test_loss\",\"test_accuracy\",\"F1_score\"])\n",
    "result_pd.to_csv(\"./results/all_factor_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef55c04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_director_rate</td>\n",
       "      <td>0.387345</td>\n",
       "      <td>0.839054</td>\n",
       "      <td>0.445520</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.836066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_director_rate</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.841343</td>\n",
       "      <td>0.433423</td>\n",
       "      <td>0.814024</td>\n",
       "      <td>0.837333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_director_rate</td>\n",
       "      <td>0.383422</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.437525</td>\n",
       "      <td>0.810976</td>\n",
       "      <td>0.835106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_director_rate</td>\n",
       "      <td>0.385504</td>\n",
       "      <td>0.839817</td>\n",
       "      <td>0.441390</td>\n",
       "      <td>0.810976</td>\n",
       "      <td>0.832432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_director_rate</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.438980</td>\n",
       "      <td>0.807927</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>people_fully_vaccinated_per_hundred_USA</td>\n",
       "      <td>0.381778</td>\n",
       "      <td>0.835240</td>\n",
       "      <td>0.439268</td>\n",
       "      <td>0.820122</td>\n",
       "      <td>0.840108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>people_fully_vaccinated_per_hundred_USA</td>\n",
       "      <td>0.386030</td>\n",
       "      <td>0.833715</td>\n",
       "      <td>0.442627</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>people_fully_vaccinated_per_hundred_USA</td>\n",
       "      <td>0.380850</td>\n",
       "      <td>0.835240</td>\n",
       "      <td>0.435353</td>\n",
       "      <td>0.814024</td>\n",
       "      <td>0.838196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>people_fully_vaccinated_per_hundred_USA</td>\n",
       "      <td>0.384406</td>\n",
       "      <td>0.839817</td>\n",
       "      <td>0.445491</td>\n",
       "      <td>0.820122</td>\n",
       "      <td>0.839237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>people_fully_vaccinated_per_hundred_USA</td>\n",
       "      <td>0.382884</td>\n",
       "      <td>0.833715</td>\n",
       "      <td>0.444298</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.827027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        item  train_loss  train_accuracy  \\\n",
       "0                          avg_director_rate    0.387345        0.839054   \n",
       "1                          avg_director_rate    0.379000        0.841343   \n",
       "2                          avg_director_rate    0.383422        0.840580   \n",
       "3                          avg_director_rate    0.385504        0.839817   \n",
       "4                          avg_director_rate    0.385352        0.838291   \n",
       "..                                       ...         ...             ...   \n",
       "245  people_fully_vaccinated_per_hundred_USA    0.381778        0.835240   \n",
       "246  people_fully_vaccinated_per_hundred_USA    0.386030        0.833715   \n",
       "247  people_fully_vaccinated_per_hundred_USA    0.380850        0.835240   \n",
       "248  people_fully_vaccinated_per_hundred_USA    0.384406        0.839817   \n",
       "249  people_fully_vaccinated_per_hundred_USA    0.382884        0.833715   \n",
       "\n",
       "     test_loss  test_accuracy  F1_score  \n",
       "0     0.445520       0.817073  0.836066  \n",
       "1     0.433423       0.814024  0.837333  \n",
       "2     0.437525       0.810976  0.835106  \n",
       "3     0.441390       0.810976  0.832432  \n",
       "4     0.438980       0.807927  0.829268  \n",
       "..         ...            ...       ...  \n",
       "245   0.439268       0.820122  0.840108  \n",
       "246   0.442627       0.817073  0.837838  \n",
       "247   0.435353       0.814024  0.838196  \n",
       "248   0.445491       0.820122  0.839237  \n",
       "249   0.444298       0.804878  0.827027  \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_factor_test = pd.read_csv(\"./results/all_factor_test.csv\")\n",
    "all_factor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "315e2a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BCI</th>\n",
       "      <td>0.381383</td>\n",
       "      <td>0.838139</td>\n",
       "      <td>0.451020</td>\n",
       "      <td>0.806707</td>\n",
       "      <td>0.827569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDI</th>\n",
       "      <td>0.380731</td>\n",
       "      <td>0.837529</td>\n",
       "      <td>0.450271</td>\n",
       "      <td>0.807317</td>\n",
       "      <td>0.827691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N1NG</th>\n",
       "      <td>0.374036</td>\n",
       "      <td>0.844851</td>\n",
       "      <td>0.439928</td>\n",
       "      <td>0.813415</td>\n",
       "      <td>0.836371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_board_bys</th>\n",
       "      <td>0.380156</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.437906</td>\n",
       "      <td>0.811585</td>\n",
       "      <td>0.831201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_director_pledge_rate</th>\n",
       "      <td>0.383744</td>\n",
       "      <td>0.836003</td>\n",
       "      <td>0.441177</td>\n",
       "      <td>0.812195</td>\n",
       "      <td>0.829855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_director_rate</th>\n",
       "      <td>0.384125</td>\n",
       "      <td>0.839817</td>\n",
       "      <td>0.439367</td>\n",
       "      <td>0.812195</td>\n",
       "      <td>0.834041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_export_rate</th>\n",
       "      <td>0.374693</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.447505</td>\n",
       "      <td>0.823171</td>\n",
       "      <td>0.842884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_import_rate</th>\n",
       "      <td>0.376115</td>\n",
       "      <td>0.840732</td>\n",
       "      <td>0.446412</td>\n",
       "      <td>0.823780</td>\n",
       "      <td>0.842479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgas_cpc</th>\n",
       "      <td>0.368020</td>\n",
       "      <td>0.847750</td>\n",
       "      <td>0.445623</td>\n",
       "      <td>0.812805</td>\n",
       "      <td>0.833960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change_rate_bys</th>\n",
       "      <td>0.368695</td>\n",
       "      <td>0.851259</td>\n",
       "      <td>0.442757</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.823846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_2801</th>\n",
       "      <td>0.374411</td>\n",
       "      <td>0.845461</td>\n",
       "      <td>0.448764</td>\n",
       "      <td>0.813415</td>\n",
       "      <td>0.835655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_2804</th>\n",
       "      <td>0.378766</td>\n",
       "      <td>0.839817</td>\n",
       "      <td>0.441685</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.838464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_37050000306</th>\n",
       "      <td>0.368015</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.439227</td>\n",
       "      <td>0.810976</td>\n",
       "      <td>0.833130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_37071000</th>\n",
       "      <td>0.378567</td>\n",
       "      <td>0.840122</td>\n",
       "      <td>0.442421</td>\n",
       "      <td>0.810976</td>\n",
       "      <td>0.834894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_37079090</th>\n",
       "      <td>0.374118</td>\n",
       "      <td>0.842563</td>\n",
       "      <td>0.438256</td>\n",
       "      <td>0.821951</td>\n",
       "      <td>0.842316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_381800</th>\n",
       "      <td>0.371094</td>\n",
       "      <td>0.850496</td>\n",
       "      <td>0.444643</td>\n",
       "      <td>0.810366</td>\n",
       "      <td>0.831610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_848610</th>\n",
       "      <td>0.375402</td>\n",
       "      <td>0.837834</td>\n",
       "      <td>0.444333</td>\n",
       "      <td>0.818902</td>\n",
       "      <td>0.837563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_848620</th>\n",
       "      <td>0.381966</td>\n",
       "      <td>0.836003</td>\n",
       "      <td>0.441594</td>\n",
       "      <td>0.810366</td>\n",
       "      <td>0.833398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_2801</th>\n",
       "      <td>0.376328</td>\n",
       "      <td>0.844546</td>\n",
       "      <td>0.443717</td>\n",
       "      <td>0.810366</td>\n",
       "      <td>0.833939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_2804</th>\n",
       "      <td>0.376808</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.440319</td>\n",
       "      <td>0.821341</td>\n",
       "      <td>0.840476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_37050000306</th>\n",
       "      <td>0.379201</td>\n",
       "      <td>0.840275</td>\n",
       "      <td>0.443793</td>\n",
       "      <td>0.822561</td>\n",
       "      <td>0.840888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_37071000</th>\n",
       "      <td>0.377525</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.445644</td>\n",
       "      <td>0.812805</td>\n",
       "      <td>0.831777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_37079090</th>\n",
       "      <td>0.377451</td>\n",
       "      <td>0.840427</td>\n",
       "      <td>0.439395</td>\n",
       "      <td>0.818902</td>\n",
       "      <td>0.838648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_381800</th>\n",
       "      <td>0.374556</td>\n",
       "      <td>0.846377</td>\n",
       "      <td>0.435877</td>\n",
       "      <td>0.828049</td>\n",
       "      <td>0.848357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_848610</th>\n",
       "      <td>0.378399</td>\n",
       "      <td>0.842715</td>\n",
       "      <td>0.442001</td>\n",
       "      <td>0.806098</td>\n",
       "      <td>0.829182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_848620</th>\n",
       "      <td>0.381330</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.440924</td>\n",
       "      <td>0.811585</td>\n",
       "      <td>0.832165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreign_rate_bys</th>\n",
       "      <td>0.379895</td>\n",
       "      <td>0.837986</td>\n",
       "      <td>0.434264</td>\n",
       "      <td>0.813415</td>\n",
       "      <td>0.834001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_2801</th>\n",
       "      <td>0.383362</td>\n",
       "      <td>0.834630</td>\n",
       "      <td>0.441244</td>\n",
       "      <td>0.814634</td>\n",
       "      <td>0.836013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_2804</th>\n",
       "      <td>0.380189</td>\n",
       "      <td>0.838902</td>\n",
       "      <td>0.440837</td>\n",
       "      <td>0.810976</td>\n",
       "      <td>0.832407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_37050000306</th>\n",
       "      <td>0.376638</td>\n",
       "      <td>0.842258</td>\n",
       "      <td>0.444817</td>\n",
       "      <td>0.812195</td>\n",
       "      <td>0.835642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_37071000</th>\n",
       "      <td>0.368203</td>\n",
       "      <td>0.849275</td>\n",
       "      <td>0.447578</td>\n",
       "      <td>0.815854</td>\n",
       "      <td>0.837626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_37079090</th>\n",
       "      <td>0.378716</td>\n",
       "      <td>0.841953</td>\n",
       "      <td>0.443239</td>\n",
       "      <td>0.803049</td>\n",
       "      <td>0.822396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_381800</th>\n",
       "      <td>0.377034</td>\n",
       "      <td>0.844699</td>\n",
       "      <td>0.438864</td>\n",
       "      <td>0.811585</td>\n",
       "      <td>0.832885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_848610</th>\n",
       "      <td>0.381280</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.440930</td>\n",
       "      <td>0.816463</td>\n",
       "      <td>0.837039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_848620</th>\n",
       "      <td>0.371742</td>\n",
       "      <td>0.843783</td>\n",
       "      <td>0.443887</td>\n",
       "      <td>0.818293</td>\n",
       "      <td>0.839962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_2801</th>\n",
       "      <td>0.383725</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.438337</td>\n",
       "      <td>0.815244</td>\n",
       "      <td>0.836972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_2804</th>\n",
       "      <td>0.372640</td>\n",
       "      <td>0.844546</td>\n",
       "      <td>0.437107</td>\n",
       "      <td>0.812195</td>\n",
       "      <td>0.833347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_37050000306</th>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.843173</td>\n",
       "      <td>0.446044</td>\n",
       "      <td>0.810976</td>\n",
       "      <td>0.832658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_37071000</th>\n",
       "      <td>0.380761</td>\n",
       "      <td>0.841190</td>\n",
       "      <td>0.450606</td>\n",
       "      <td>0.813415</td>\n",
       "      <td>0.835630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_37079090</th>\n",
       "      <td>0.372179</td>\n",
       "      <td>0.842258</td>\n",
       "      <td>0.438587</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.844421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_381800</th>\n",
       "      <td>0.382485</td>\n",
       "      <td>0.839664</td>\n",
       "      <td>0.439075</td>\n",
       "      <td>0.820732</td>\n",
       "      <td>0.842549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_848610</th>\n",
       "      <td>0.384276</td>\n",
       "      <td>0.833257</td>\n",
       "      <td>0.447423</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.837403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_848620</th>\n",
       "      <td>0.373469</td>\n",
       "      <td>0.846529</td>\n",
       "      <td>0.443148</td>\n",
       "      <td>0.815854</td>\n",
       "      <td>0.836375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_cases_smoothed_OWID_EUR</th>\n",
       "      <td>0.377091</td>\n",
       "      <td>0.837986</td>\n",
       "      <td>0.443436</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.841070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_cases_smoothed_TWN</th>\n",
       "      <td>0.373478</td>\n",
       "      <td>0.843173</td>\n",
       "      <td>0.441320</td>\n",
       "      <td>0.825610</td>\n",
       "      <td>0.846064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_cases_smoothed_USA</th>\n",
       "      <td>0.374285</td>\n",
       "      <td>0.838444</td>\n",
       "      <td>0.444749</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.838196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil_avg_value</th>\n",
       "      <td>0.376124</td>\n",
       "      <td>0.840885</td>\n",
       "      <td>0.442160</td>\n",
       "      <td>0.810366</td>\n",
       "      <td>0.832519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over1000_rate_bys</th>\n",
       "      <td>0.380014</td>\n",
       "      <td>0.837986</td>\n",
       "      <td>0.440615</td>\n",
       "      <td>0.808537</td>\n",
       "      <td>0.828363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people_fully_vaccinated_per_hundred_USA</th>\n",
       "      <td>0.383189</td>\n",
       "      <td>0.835545</td>\n",
       "      <td>0.441408</td>\n",
       "      <td>0.815244</td>\n",
       "      <td>0.836481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under400_rate_bys</th>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.839512</td>\n",
       "      <td>0.433167</td>\n",
       "      <td>0.813415</td>\n",
       "      <td>0.834247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        train_loss train_accuracy test_loss  \\\n",
       "                                              mean           mean      mean   \n",
       "item                                                                          \n",
       "BCI                                       0.381383       0.838139  0.451020   \n",
       "BDI                                       0.380731       0.837529  0.450271   \n",
       "N1NG                                      0.374036       0.844851  0.439928   \n",
       "avg_board_bys                             0.380156       0.840580  0.437906   \n",
       "avg_director_pledge_rate                  0.383744       0.836003  0.441177   \n",
       "avg_director_rate                         0.384125       0.839817  0.439367   \n",
       "avg_export_rate                           0.374693       0.840580  0.447505   \n",
       "avg_import_rate                           0.376115       0.840732  0.446412   \n",
       "avgas_cpc                                 0.368020       0.847750  0.445623   \n",
       "change_rate_bys                           0.368695       0.851259  0.442757   \n",
       "export_kgm_weight_2801                    0.374411       0.845461  0.448764   \n",
       "export_kgm_weight_2804                    0.378766       0.839817  0.441685   \n",
       "export_kgm_weight_37050000306             0.368015       0.843478  0.439227   \n",
       "export_kgm_weight_37071000                0.378567       0.840122  0.442421   \n",
       "export_kgm_weight_37079090                0.374118       0.842563  0.438256   \n",
       "export_kgm_weight_381800                  0.371094       0.850496  0.444643   \n",
       "export_kgm_weight_848610                  0.375402       0.837834  0.444333   \n",
       "export_kgm_weight_848620                  0.381966       0.836003  0.441594   \n",
       "export_usd_value_2801                     0.376328       0.844546  0.443717   \n",
       "export_usd_value_2804                     0.376808       0.842105  0.440319   \n",
       "export_usd_value_37050000306              0.379201       0.840275  0.443793   \n",
       "export_usd_value_37071000                 0.377525       0.841342  0.445644   \n",
       "export_usd_value_37079090                 0.377451       0.840427  0.439395   \n",
       "export_usd_value_381800                   0.374556       0.846377  0.435877   \n",
       "export_usd_value_848610                   0.378399       0.842715  0.442001   \n",
       "export_usd_value_848620                   0.381330       0.836308  0.440924   \n",
       "foreign_rate_bys                          0.379895       0.837986  0.434264   \n",
       "import_kgm_weight_2801                    0.383362       0.834630  0.441244   \n",
       "import_kgm_weight_2804                    0.380189       0.838902  0.440837   \n",
       "import_kgm_weight_37050000306             0.376638       0.842258  0.444817   \n",
       "import_kgm_weight_37071000                0.368203       0.849275  0.447578   \n",
       "import_kgm_weight_37079090                0.378716       0.841953  0.443239   \n",
       "import_kgm_weight_381800                  0.377034       0.844699  0.438864   \n",
       "import_kgm_weight_848610                  0.381280       0.834325  0.440930   \n",
       "import_kgm_weight_848620                  0.371742       0.843783  0.443887   \n",
       "import_usd_value_2801                     0.383725       0.834783  0.438337   \n",
       "import_usd_value_2804                     0.372640       0.844546  0.437107   \n",
       "import_usd_value_37050000306              0.377600       0.843173  0.446044   \n",
       "import_usd_value_37071000                 0.380761       0.841190  0.450606   \n",
       "import_usd_value_37079090                 0.372179       0.842258  0.438587   \n",
       "import_usd_value_381800                   0.382485       0.839664  0.439075   \n",
       "import_usd_value_848610                   0.384276       0.833257  0.447423   \n",
       "import_usd_value_848620                   0.373469       0.846529  0.443148   \n",
       "new_cases_smoothed_OWID_EUR               0.377091       0.837986  0.443436   \n",
       "new_cases_smoothed_TWN                    0.373478       0.843173  0.441320   \n",
       "new_cases_smoothed_USA                    0.374285       0.838444  0.444749   \n",
       "oil_avg_value                             0.376124       0.840885  0.442160   \n",
       "over1000_rate_bys                         0.380014       0.837986  0.440615   \n",
       "people_fully_vaccinated_per_hundred_USA   0.383189       0.835545  0.441408   \n",
       "under400_rate_bys                         0.378509       0.839512  0.433167   \n",
       "\n",
       "                                        test_accuracy  F1_score  \n",
       "                                                 mean      mean  \n",
       "item                                                             \n",
       "BCI                                          0.806707  0.827569  \n",
       "BDI                                          0.807317  0.827691  \n",
       "N1NG                                         0.813415  0.836371  \n",
       "avg_board_bys                                0.811585  0.831201  \n",
       "avg_director_pledge_rate                     0.812195  0.829855  \n",
       "avg_director_rate                            0.812195  0.834041  \n",
       "avg_export_rate                              0.823171  0.842884  \n",
       "avg_import_rate                              0.823780  0.842479  \n",
       "avgas_cpc                                    0.812805  0.833960  \n",
       "change_rate_bys                              0.800000  0.823846  \n",
       "export_kgm_weight_2801                       0.813415  0.835655  \n",
       "export_kgm_weight_2804                       0.817683  0.838464  \n",
       "export_kgm_weight_37050000306                0.810976  0.833130  \n",
       "export_kgm_weight_37071000                   0.810976  0.834894  \n",
       "export_kgm_weight_37079090                   0.821951  0.842316  \n",
       "export_kgm_weight_381800                     0.810366  0.831610  \n",
       "export_kgm_weight_848610                     0.818902  0.837563  \n",
       "export_kgm_weight_848620                     0.810366  0.833398  \n",
       "export_usd_value_2801                        0.810366  0.833939  \n",
       "export_usd_value_2804                        0.821341  0.840476  \n",
       "export_usd_value_37050000306                 0.822561  0.840888  \n",
       "export_usd_value_37071000                    0.812805  0.831777  \n",
       "export_usd_value_37079090                    0.818902  0.838648  \n",
       "export_usd_value_381800                      0.828049  0.848357  \n",
       "export_usd_value_848610                      0.806098  0.829182  \n",
       "export_usd_value_848620                      0.811585  0.832165  \n",
       "foreign_rate_bys                             0.813415  0.834001  \n",
       "import_kgm_weight_2801                       0.814634  0.836013  \n",
       "import_kgm_weight_2804                       0.810976  0.832407  \n",
       "import_kgm_weight_37050000306                0.812195  0.835642  \n",
       "import_kgm_weight_37071000                   0.815854  0.837626  \n",
       "import_kgm_weight_37079090                   0.803049  0.822396  \n",
       "import_kgm_weight_381800                     0.811585  0.832885  \n",
       "import_kgm_weight_848610                     0.816463  0.837039  \n",
       "import_kgm_weight_848620                     0.818293  0.839962  \n",
       "import_usd_value_2801                        0.815244  0.836972  \n",
       "import_usd_value_2804                        0.812195  0.833347  \n",
       "import_usd_value_37050000306                 0.810976  0.832658  \n",
       "import_usd_value_37071000                    0.813415  0.835630  \n",
       "import_usd_value_37079090                    0.825000  0.844421  \n",
       "import_usd_value_381800                      0.820732  0.842549  \n",
       "import_usd_value_848610                      0.817683  0.837403  \n",
       "import_usd_value_848620                      0.815854  0.836375  \n",
       "new_cases_smoothed_OWID_EUR                  0.819512  0.841070  \n",
       "new_cases_smoothed_TWN                       0.825610  0.846064  \n",
       "new_cases_smoothed_USA                       0.817073  0.838196  \n",
       "oil_avg_value                                0.810366  0.832519  \n",
       "over1000_rate_bys                            0.808537  0.828363  \n",
       "people_fully_vaccinated_per_hundred_USA      0.815244  0.836481  \n",
       "under400_rate_bys                            0.813415  0.834247  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_factor_group = all_factor_test.sort_values(['test_accuracy'],ascending=False).groupby(['item']).aggregate(['mean'])\n",
    "all_factor_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "1b788c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>export_usd_value_381800</th>\n",
       "      <td>0.828049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_cases_smoothed_TWN</th>\n",
       "      <td>0.825610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_37079090</th>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_import_rate</th>\n",
       "      <td>0.823780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_export_rate</th>\n",
       "      <td>0.823171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_37050000306</th>\n",
       "      <td>0.822561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_37079090</th>\n",
       "      <td>0.821951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_2804</th>\n",
       "      <td>0.821341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_381800</th>\n",
       "      <td>0.820732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_cases_smoothed_OWID_EUR</th>\n",
       "      <td>0.819512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_848610</th>\n",
       "      <td>0.818902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_37079090</th>\n",
       "      <td>0.818902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_848620</th>\n",
       "      <td>0.818293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_2804</th>\n",
       "      <td>0.817683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_848610</th>\n",
       "      <td>0.817683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_cases_smoothed_USA</th>\n",
       "      <td>0.817073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_848610</th>\n",
       "      <td>0.816463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_848620</th>\n",
       "      <td>0.815854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_37071000</th>\n",
       "      <td>0.815854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people_fully_vaccinated_per_hundred_USA</th>\n",
       "      <td>0.815244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_2801</th>\n",
       "      <td>0.815244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_kgm_weight_2801</th>\n",
       "      <td>0.814634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under400_rate_bys</th>\n",
       "      <td>0.813415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N1NG</th>\n",
       "      <td>0.813415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_2801</th>\n",
       "      <td>0.813415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             mean\n",
       "item                                             \n",
       "export_usd_value_381800                  0.828049\n",
       "new_cases_smoothed_TWN                   0.825610\n",
       "import_usd_value_37079090                0.825000\n",
       "avg_import_rate                          0.823780\n",
       "avg_export_rate                          0.823171\n",
       "export_usd_value_37050000306             0.822561\n",
       "export_kgm_weight_37079090               0.821951\n",
       "export_usd_value_2804                    0.821341\n",
       "import_usd_value_381800                  0.820732\n",
       "new_cases_smoothed_OWID_EUR              0.819512\n",
       "export_kgm_weight_848610                 0.818902\n",
       "export_usd_value_37079090                0.818902\n",
       "import_kgm_weight_848620                 0.818293\n",
       "export_kgm_weight_2804                   0.817683\n",
       "import_usd_value_848610                  0.817683\n",
       "new_cases_smoothed_USA                   0.817073\n",
       "import_kgm_weight_848610                 0.816463\n",
       "import_usd_value_848620                  0.815854\n",
       "import_kgm_weight_37071000               0.815854\n",
       "people_fully_vaccinated_per_hundred_USA  0.815244\n",
       "import_usd_value_2801                    0.815244\n",
       "import_kgm_weight_2801                   0.814634\n",
       "under400_rate_bys                        0.813415\n",
       "N1NG                                     0.813415\n",
       "export_kgm_weight_2801                   0.813415"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_acc = all_factor_group['test_accuracy'].sort_values(by=['mean'],ascending=False).head(25)\n",
    "top10_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eae1f6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>export_usd_value_381800</th>\n",
       "      <td>0.848357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_cases_smoothed_TWN</th>\n",
       "      <td>0.846064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_37079090</th>\n",
       "      <td>0.844421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_export_rate</th>\n",
       "      <td>0.842884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>import_usd_value_381800</th>\n",
       "      <td>0.842549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_import_rate</th>\n",
       "      <td>0.842479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_kgm_weight_37079090</th>\n",
       "      <td>0.842316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_cases_smoothed_OWID_EUR</th>\n",
       "      <td>0.841070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_37050000306</th>\n",
       "      <td>0.840888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>export_usd_value_2804</th>\n",
       "      <td>0.840476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mean\n",
       "item                                  \n",
       "export_usd_value_381800       0.848357\n",
       "new_cases_smoothed_TWN        0.846064\n",
       "import_usd_value_37079090     0.844421\n",
       "avg_export_rate               0.842884\n",
       "import_usd_value_381800       0.842549\n",
       "avg_import_rate               0.842479\n",
       "export_kgm_weight_37079090    0.842316\n",
       "new_cases_smoothed_OWID_EUR   0.841070\n",
       "export_usd_value_37050000306  0.840888\n",
       "export_usd_value_2804         0.840476"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_f1 = all_factor_group['F1_score'].sort_values(by=['mean'],ascending=False).head(10)\n",
    "top10_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc7b6a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-97-384704f50a6d>:3: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  if item in (top10_acc.index & top10_f1.index):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['avg_export_rate',\n",
       " 'avg_import_rate',\n",
       " 'export_kgm_weight_37079090',\n",
       " 'export_usd_value_2804',\n",
       " 'export_usd_value_37050000306',\n",
       " 'export_usd_value_381800',\n",
       " 'import_usd_value_37079090',\n",
       " 'import_usd_value_381800',\n",
       " 'new_cases_smoothed_OWID_EUR',\n",
       " 'new_cases_smoothed_TWN']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for item in all_factor_group.index:\n",
    "    if item in (top10_acc.index & top10_f1.index):\n",
    "        results.append(item)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e7b29c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_profit_rate</th>\n",
       "      <th>operating_gross_rate</th>\n",
       "      <th>roe_rate</th>\n",
       "      <th>roa_rate</th>\n",
       "      <th>current_rate</th>\n",
       "      <th>quick_rate</th>\n",
       "      <th>debt_rate</th>\n",
       "      <th>receivables_turnover_rate</th>\n",
       "      <th>cash_reinvest_rate</th>\n",
       "      <th>export_usd_value_381800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.35</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.91</td>\n",
       "      <td>154.53</td>\n",
       "      <td>103.70</td>\n",
       "      <td>18.22</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.74</td>\n",
       "      <td>107270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.22</td>\n",
       "      <td>40.93</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.37</td>\n",
       "      <td>166.92</td>\n",
       "      <td>110.41</td>\n",
       "      <td>16.86</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.34</td>\n",
       "      <td>112119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.00</td>\n",
       "      <td>37.03</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>171.94</td>\n",
       "      <td>109.89</td>\n",
       "      <td>16.38</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.51</td>\n",
       "      <td>96978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.26</td>\n",
       "      <td>32.10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.74</td>\n",
       "      <td>174.72</td>\n",
       "      <td>114.79</td>\n",
       "      <td>16.63</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.17</td>\n",
       "      <td>98799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.29</td>\n",
       "      <td>28.78</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>170.04</td>\n",
       "      <td>116.92</td>\n",
       "      <td>17.45</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.32</td>\n",
       "      <td>90681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>14.75</td>\n",
       "      <td>30.43</td>\n",
       "      <td>6.29</td>\n",
       "      <td>4.71</td>\n",
       "      <td>326.95</td>\n",
       "      <td>199.20</td>\n",
       "      <td>25.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>95038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>10.91</td>\n",
       "      <td>24.76</td>\n",
       "      <td>4.01</td>\n",
       "      <td>2.97</td>\n",
       "      <td>299.48</td>\n",
       "      <td>181.73</td>\n",
       "      <td>27.74</td>\n",
       "      <td>4.28</td>\n",
       "      <td>6.49</td>\n",
       "      <td>93532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>15.41</td>\n",
       "      <td>22.61</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.61</td>\n",
       "      <td>363.99</td>\n",
       "      <td>240.63</td>\n",
       "      <td>23.66</td>\n",
       "      <td>6.20</td>\n",
       "      <td>5.25</td>\n",
       "      <td>96949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>29.47</td>\n",
       "      <td>23.05</td>\n",
       "      <td>11.76</td>\n",
       "      <td>8.79</td>\n",
       "      <td>317.33</td>\n",
       "      <td>230.20</td>\n",
       "      <td>26.09</td>\n",
       "      <td>8.12</td>\n",
       "      <td>11.28</td>\n",
       "      <td>104276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>13.09</td>\n",
       "      <td>29.71</td>\n",
       "      <td>4.71</td>\n",
       "      <td>3.41</td>\n",
       "      <td>281.91</td>\n",
       "      <td>191.93</td>\n",
       "      <td>29.32</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-3.70</td>\n",
       "      <td>108639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      net_profit_rate  operating_gross_rate  roe_rate  roa_rate  current_rate  \\\n",
       "0               13.35                 38.03      1.07      0.91        154.53   \n",
       "1                5.22                 40.93      0.42      0.37        166.92   \n",
       "2               -3.00                 37.03     -0.20     -0.14        171.94   \n",
       "3               10.26                 32.10      0.85      0.74        174.72   \n",
       "4                2.29                 28.78      0.17      0.17        170.04   \n",
       "...               ...                   ...       ...       ...           ...   \n",
       "1634            14.75                 30.43      6.29      4.71        326.95   \n",
       "1635            10.91                 24.76      4.01      2.97        299.48   \n",
       "1636            15.41                 22.61      6.07      4.61        363.99   \n",
       "1637            29.47                 23.05     11.76      8.79        317.33   \n",
       "1638            13.09                 29.71      4.71      3.41        281.91   \n",
       "\n",
       "      quick_rate  debt_rate  receivables_turnover_rate  cash_reinvest_rate  \\\n",
       "0         103.70      18.22                       3.31                1.74   \n",
       "1         110.41      16.86                       4.35                1.34   \n",
       "2         109.89      16.38                       0.99                1.51   \n",
       "3         114.79      16.63                       2.00                2.17   \n",
       "4         116.92      17.45                       3.10                4.32   \n",
       "...          ...        ...                        ...                 ...   \n",
       "1634      199.20      25.75                       1.99               -0.03   \n",
       "1635      181.73      27.74                       4.28                6.49   \n",
       "1636      240.63      23.66                       6.20                5.25   \n",
       "1637      230.20      26.09                       8.12               11.28   \n",
       "1638      191.93      29.32                       1.95               -3.70   \n",
       "\n",
       "      export_usd_value_381800  \n",
       "0                      107270  \n",
       "1                      112119  \n",
       "2                       96978  \n",
       "3                       98799  \n",
       "4                       90681  \n",
       "...                       ...  \n",
       "1634                    95038  \n",
       "1635                    93532  \n",
       "1636                    96949  \n",
       "1637                   104276  \n",
       "1638                   108639  \n",
       "\n",
       "[1639 rows x 10 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_factor_f = get_data(\"\"\"SELECT \n",
    "                            net_profit_rate,\n",
    "                            operating_gross_rate, \n",
    "                            roe_rate,\n",
    "                            roa_rate,\n",
    "                            current_rate, \n",
    "                            quick_rate,  \n",
    "                            debt_rate,  \n",
    "                            receivables_turnover_rate, \n",
    "                            cash_reinvest_rate,\n",
    "                            export_usd_value_381800\n",
    "\n",
    "                            FROM tfb103d_project.datamining_alldata_afetl\n",
    "                            WHERE stock_report_date < '20212';\"\"\",'tfb103d_project')\n",
    "\n",
    "                            \n",
    "#                             avg_export_rate\n",
    "#                             export_kgm_weight_37079090,\n",
    "#                             export_usd_value_2804,\n",
    "#                             export_usd_value_37050000306,\n",
    "#                             new_cases_smoothed_OWID_EUR,\n",
    "#                             import_usd_value_381800\n",
    "#                             import_usd_value_37079090,\n",
    "#                             avg_import_rate\n",
    "#                             new_cases_smoothed_TWN\n",
    "company_factor_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0dbf515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  (1639, 10)\n",
      "y.shape:  (1639,)\n",
      "y.sum(): 884\n"
     ]
    }
   ],
   "source": [
    "X = company_factor_f\n",
    "\n",
    "y = Roe_rul['roe_rate1']\n",
    "\n",
    "print(\"x.shape: \" ,X.shape)\n",
    "print(\"y.shape: \" ,y.shape)\n",
    "print('y.sum():',y.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a36e11",
   "metadata": {},
   "source": [
    "<h3>ROE:  755 筆標記為 0 ； 884 筆為 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7861ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入數據調成標準值以免各特徵影響不同\n",
    "# you'll learn why scaling is needed in a later course\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "def mean_norm(df_input):\n",
    "    return df_input.apply(lambda x: ((x-df_input.mean())/ df_input.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c5add5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_profit_rate</th>\n",
       "      <th>operating_gross_rate</th>\n",
       "      <th>roe_rate</th>\n",
       "      <th>roa_rate</th>\n",
       "      <th>current_rate</th>\n",
       "      <th>quick_rate</th>\n",
       "      <th>debt_rate</th>\n",
       "      <th>receivables_turnover_rate</th>\n",
       "      <th>cash_reinvest_rate</th>\n",
       "      <th>export_usd_value_381800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.214147</td>\n",
       "      <td>0.310530</td>\n",
       "      <td>-0.182515</td>\n",
       "      <td>-0.220846</td>\n",
       "      <td>-0.553189</td>\n",
       "      <td>-0.513366</td>\n",
       "      <td>-0.818028</td>\n",
       "      <td>-0.161824</td>\n",
       "      <td>-0.205327</td>\n",
       "      <td>1.099460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060193</td>\n",
       "      <td>0.420361</td>\n",
       "      <td>-0.290044</td>\n",
       "      <td>-0.381183</td>\n",
       "      <td>-0.520781</td>\n",
       "      <td>-0.494960</td>\n",
       "      <td>-0.898471</td>\n",
       "      <td>-0.064074</td>\n",
       "      <td>-0.239816</td>\n",
       "      <td>1.817215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.095466</td>\n",
       "      <td>0.272657</td>\n",
       "      <td>-0.392611</td>\n",
       "      <td>-0.532612</td>\n",
       "      <td>-0.507650</td>\n",
       "      <td>-0.496387</td>\n",
       "      <td>-0.926863</td>\n",
       "      <td>-0.379883</td>\n",
       "      <td>-0.225158</td>\n",
       "      <td>-0.423973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155633</td>\n",
       "      <td>0.085944</td>\n",
       "      <td>-0.218909</td>\n",
       "      <td>-0.271322</td>\n",
       "      <td>-0.500379</td>\n",
       "      <td>-0.482945</td>\n",
       "      <td>-0.912075</td>\n",
       "      <td>-0.284953</td>\n",
       "      <td>-0.168251</td>\n",
       "      <td>-0.154426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004708</td>\n",
       "      <td>-0.039793</td>\n",
       "      <td>-0.331402</td>\n",
       "      <td>-0.440567</td>\n",
       "      <td>-0.512620</td>\n",
       "      <td>-0.477102</td>\n",
       "      <td>-0.863573</td>\n",
       "      <td>-0.181562</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>-1.356062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0.240658</td>\n",
       "      <td>0.022697</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.907451</td>\n",
       "      <td>-0.102197</td>\n",
       "      <td>-0.251399</td>\n",
       "      <td>-0.372635</td>\n",
       "      <td>-0.285892</td>\n",
       "      <td>-0.357940</td>\n",
       "      <td>-0.711134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>0.167942</td>\n",
       "      <td>-0.192042</td>\n",
       "      <td>0.303849</td>\n",
       "      <td>0.390810</td>\n",
       "      <td>-0.174049</td>\n",
       "      <td>-0.299321</td>\n",
       "      <td>-0.254929</td>\n",
       "      <td>-0.070653</td>\n",
       "      <td>0.204228</td>\n",
       "      <td>-0.934054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>0.253157</td>\n",
       "      <td>-0.273468</td>\n",
       "      <td>0.644634</td>\n",
       "      <td>0.877759</td>\n",
       "      <td>-0.005312</td>\n",
       "      <td>-0.137752</td>\n",
       "      <td>-0.496257</td>\n",
       "      <td>0.109809</td>\n",
       "      <td>0.097313</td>\n",
       "      <td>-0.428265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>0.519405</td>\n",
       "      <td>-0.256804</td>\n",
       "      <td>1.585929</td>\n",
       "      <td>2.118886</td>\n",
       "      <td>-0.127359</td>\n",
       "      <td>-0.166362</td>\n",
       "      <td>-0.352525</td>\n",
       "      <td>0.290272</td>\n",
       "      <td>0.617232</td>\n",
       "      <td>0.656285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.209224</td>\n",
       "      <td>-0.004572</td>\n",
       "      <td>0.419650</td>\n",
       "      <td>0.521455</td>\n",
       "      <td>-0.220006</td>\n",
       "      <td>-0.271341</td>\n",
       "      <td>-0.161473</td>\n",
       "      <td>-0.289652</td>\n",
       "      <td>-0.674375</td>\n",
       "      <td>1.302101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      net_profit_rate  operating_gross_rate  roe_rate  roa_rate  current_rate  \\\n",
       "0            0.214147              0.310530 -0.182515 -0.220846     -0.553189   \n",
       "1            0.060193              0.420361 -0.290044 -0.381183     -0.520781   \n",
       "2           -0.095466              0.272657 -0.392611 -0.532612     -0.507650   \n",
       "3            0.155633              0.085944 -0.218909 -0.271322     -0.500379   \n",
       "4            0.004708             -0.039793 -0.331402 -0.440567     -0.512620   \n",
       "...               ...                   ...       ...       ...           ...   \n",
       "1634         0.240658              0.022697  0.681029  0.907451     -0.102197   \n",
       "1635         0.167942             -0.192042  0.303849  0.390810     -0.174049   \n",
       "1636         0.253157             -0.273468  0.644634  0.877759     -0.005312   \n",
       "1637         0.519405             -0.256804  1.585929  2.118886     -0.127359   \n",
       "1638         0.209224             -0.004572  0.419650  0.521455     -0.220006   \n",
       "\n",
       "      quick_rate  debt_rate  receivables_turnover_rate  cash_reinvest_rate  \\\n",
       "0      -0.513366  -0.818028                  -0.161824           -0.205327   \n",
       "1      -0.494960  -0.898471                  -0.064074           -0.239816   \n",
       "2      -0.496387  -0.926863                  -0.379883           -0.225158   \n",
       "3      -0.482945  -0.912075                  -0.284953           -0.168251   \n",
       "4      -0.477102  -0.863573                  -0.181562            0.017126   \n",
       "...          ...        ...                        ...                 ...   \n",
       "1634   -0.251399  -0.372635                  -0.285892           -0.357940   \n",
       "1635   -0.299321  -0.254929                  -0.070653            0.204228   \n",
       "1636   -0.137752  -0.496257                   0.109809            0.097313   \n",
       "1637   -0.166362  -0.352525                   0.290272            0.617232   \n",
       "1638   -0.271341  -0.161473                  -0.289652           -0.674375   \n",
       "\n",
       "      export_usd_value_381800  \n",
       "0                    1.099460  \n",
       "1                    1.817215  \n",
       "2                   -0.423973  \n",
       "3                   -0.154426  \n",
       "4                   -1.356062  \n",
       "...                       ...  \n",
       "1634                -0.711134  \n",
       "1635                -0.934054  \n",
       "1636                -0.428265  \n",
       "1637                 0.656285  \n",
       "1638                 1.302101  \n",
       "\n",
       "[1639 rows x 10 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = pd.DataFrame()\n",
    "a, b = X.shape\n",
    "\n",
    "for i in range(b):\n",
    "    X_new = mean_norm(X[X.columns[i]])\n",
    "    X_scaled.insert(i,X.columns[i],X_new)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e25d15a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 1311 D: 10\n"
     ]
    }
   ],
   "source": [
    "#分割資料為 測試集 與 訓練集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2,random_state=1)\n",
    "N, D = X_train.shape\n",
    "print (\"N:\", N, \"D:\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5658addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout,LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e5cf1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立TF模型 for 淨利\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(D,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.8),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.6),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "#編譯模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "409c50cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,569\n",
      "Trainable params: 5,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8b537908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8230 - val_loss: 0.4475 - val_accuracy: 0.8262\n",
      "Epoch 2/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.8154 - val_loss: 0.4468 - val_accuracy: 0.8293\n",
      "Epoch 3/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8185 - val_loss: 0.4467 - val_accuracy: 0.8232\n",
      "Epoch 4/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8253 - val_loss: 0.4478 - val_accuracy: 0.8293\n",
      "Epoch 5/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8200 - val_loss: 0.4464 - val_accuracy: 0.8293\n",
      "Epoch 6/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8307 - val_loss: 0.4470 - val_accuracy: 0.8201\n",
      "Epoch 7/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8284 - val_loss: 0.4474 - val_accuracy: 0.8262\n",
      "Epoch 8/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8322 - val_loss: 0.4459 - val_accuracy: 0.8262\n",
      "Epoch 9/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8238 - val_loss: 0.4462 - val_accuracy: 0.8293\n",
      "Epoch 10/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.8177 - val_loss: 0.4459 - val_accuracy: 0.8293\n",
      "Epoch 11/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.8253 - val_loss: 0.4436 - val_accuracy: 0.8293\n",
      "Epoch 12/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8314 - val_loss: 0.4440 - val_accuracy: 0.8293\n",
      "Epoch 13/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8200 - val_loss: 0.4438 - val_accuracy: 0.8293\n",
      "Epoch 14/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.8108 - val_loss: 0.4443 - val_accuracy: 0.8262\n",
      "Epoch 15/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8230 - val_loss: 0.4442 - val_accuracy: 0.8262\n",
      "Epoch 16/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.8268 - val_loss: 0.4424 - val_accuracy: 0.8293\n",
      "Epoch 17/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8177 - val_loss: 0.4432 - val_accuracy: 0.8293\n",
      "Epoch 18/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8223 - val_loss: 0.4426 - val_accuracy: 0.8293\n",
      "Epoch 19/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8116 - val_loss: 0.4422 - val_accuracy: 0.8293\n",
      "Epoch 20/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8215 - val_loss: 0.4417 - val_accuracy: 0.8323\n",
      "Epoch 21/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8238 - val_loss: 0.4410 - val_accuracy: 0.8323\n",
      "Epoch 22/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8162 - val_loss: 0.4414 - val_accuracy: 0.8323\n",
      "Epoch 23/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.8246 - val_loss: 0.4425 - val_accuracy: 0.8323\n",
      "Epoch 24/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8314 - val_loss: 0.4415 - val_accuracy: 0.8293\n",
      "Epoch 25/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8268 - val_loss: 0.4407 - val_accuracy: 0.8293\n",
      "Epoch 26/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.8307 - val_loss: 0.4401 - val_accuracy: 0.8323\n",
      "Epoch 27/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8368 - val_loss: 0.4381 - val_accuracy: 0.8323\n",
      "Epoch 28/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.8253 - val_loss: 0.4394 - val_accuracy: 0.8354\n",
      "Epoch 29/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8223 - val_loss: 0.4389 - val_accuracy: 0.8384\n",
      "Epoch 30/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.8192 - val_loss: 0.4397 - val_accuracy: 0.8445\n",
      "Epoch 31/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.8230 - val_loss: 0.4396 - val_accuracy: 0.8415\n",
      "Epoch 32/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8391 - val_loss: 0.4389 - val_accuracy: 0.8354\n",
      "Epoch 33/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8291 - val_loss: 0.4394 - val_accuracy: 0.8384\n",
      "Epoch 34/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8299 - val_loss: 0.4404 - val_accuracy: 0.8354\n",
      "Epoch 35/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8322 - val_loss: 0.4396 - val_accuracy: 0.8354\n",
      "Epoch 36/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8284 - val_loss: 0.4394 - val_accuracy: 0.8323\n",
      "Epoch 37/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.8253 - val_loss: 0.4387 - val_accuracy: 0.8384\n",
      "Epoch 38/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.8223 - val_loss: 0.4384 - val_accuracy: 0.8384\n",
      "Epoch 39/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8146 - val_loss: 0.4390 - val_accuracy: 0.8354\n",
      "Epoch 40/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.8246 - val_loss: 0.4394 - val_accuracy: 0.8384\n",
      "Epoch 41/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.8200 - val_loss: 0.4390 - val_accuracy: 0.8415\n",
      "Epoch 42/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.8200 - val_loss: 0.4396 - val_accuracy: 0.8384\n",
      "Epoch 43/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8162 - val_loss: 0.4399 - val_accuracy: 0.8354\n",
      "Epoch 44/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8337 - val_loss: 0.4413 - val_accuracy: 0.8323\n",
      "Epoch 45/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8253 - val_loss: 0.4400 - val_accuracy: 0.8354\n",
      "Epoch 46/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8276 - val_loss: 0.4394 - val_accuracy: 0.8354\n",
      "Epoch 47/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8352 - val_loss: 0.4400 - val_accuracy: 0.8354\n",
      "Epoch 48/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8314 - val_loss: 0.4391 - val_accuracy: 0.8323\n",
      "Epoch 49/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4100 - accuracy: 0.8337 - val_loss: 0.4415 - val_accuracy: 0.8354\n",
      "Epoch 50/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8337 - val_loss: 0.4407 - val_accuracy: 0.8323\n",
      "Epoch 51/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8230 - val_loss: 0.4388 - val_accuracy: 0.8293\n",
      "Epoch 52/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8284 - val_loss: 0.4393 - val_accuracy: 0.8293\n",
      "Epoch 53/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.8162 - val_loss: 0.4386 - val_accuracy: 0.8293\n",
      "Epoch 54/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8291 - val_loss: 0.4389 - val_accuracy: 0.8262\n",
      "Epoch 55/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8322 - val_loss: 0.4391 - val_accuracy: 0.8293\n",
      "Epoch 56/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8307 - val_loss: 0.4383 - val_accuracy: 0.8262\n",
      "Epoch 57/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8299 - val_loss: 0.4373 - val_accuracy: 0.8262\n",
      "Epoch 58/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8368 - val_loss: 0.4350 - val_accuracy: 0.8293\n",
      "Epoch 59/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8337 - val_loss: 0.4390 - val_accuracy: 0.8323\n",
      "Epoch 60/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8299 - val_loss: 0.4395 - val_accuracy: 0.8323\n",
      "Epoch 61/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8383 - val_loss: 0.4387 - val_accuracy: 0.8293\n",
      "Epoch 62/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8330 - val_loss: 0.4371 - val_accuracy: 0.8232\n",
      "Epoch 63/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.8284 - val_loss: 0.4360 - val_accuracy: 0.8232\n",
      "Epoch 64/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8253 - val_loss: 0.4364 - val_accuracy: 0.8232\n",
      "Epoch 65/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8246 - val_loss: 0.4368 - val_accuracy: 0.8232\n",
      "Epoch 66/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8345 - val_loss: 0.4374 - val_accuracy: 0.8201\n",
      "Epoch 67/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8238 - val_loss: 0.4392 - val_accuracy: 0.8201\n",
      "Epoch 68/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.8345 - val_loss: 0.4400 - val_accuracy: 0.8232\n",
      "Epoch 69/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8223 - val_loss: 0.4389 - val_accuracy: 0.8171\n",
      "Epoch 70/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.8307 - val_loss: 0.4403 - val_accuracy: 0.8201\n",
      "Epoch 71/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.8314 - val_loss: 0.4396 - val_accuracy: 0.8201\n",
      "Epoch 72/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8421 - val_loss: 0.4382 - val_accuracy: 0.8232\n",
      "Epoch 73/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8268 - val_loss: 0.4395 - val_accuracy: 0.8171\n",
      "Epoch 74/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8299 - val_loss: 0.4406 - val_accuracy: 0.8140\n",
      "Epoch 75/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8284 - val_loss: 0.4405 - val_accuracy: 0.8232\n",
      "Epoch 76/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8291 - val_loss: 0.4410 - val_accuracy: 0.8171\n",
      "Epoch 77/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4067 - accuracy: 0.8291 - val_loss: 0.4412 - val_accuracy: 0.8201\n",
      "Epoch 78/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.8345 - val_loss: 0.4414 - val_accuracy: 0.8232\n",
      "Epoch 79/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.8284 - val_loss: 0.4413 - val_accuracy: 0.8201\n",
      "Epoch 80/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8284 - val_loss: 0.4415 - val_accuracy: 0.8232\n",
      "Epoch 81/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8177 - val_loss: 0.4418 - val_accuracy: 0.8262\n",
      "Epoch 82/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8200 - val_loss: 0.4426 - val_accuracy: 0.8232\n",
      "Epoch 83/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8192 - val_loss: 0.4410 - val_accuracy: 0.8262\n",
      "Epoch 84/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.8215 - val_loss: 0.4408 - val_accuracy: 0.8262\n",
      "Epoch 85/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8307 - val_loss: 0.4409 - val_accuracy: 0.8293\n",
      "Epoch 86/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8268 - val_loss: 0.4397 - val_accuracy: 0.8201\n",
      "Epoch 87/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8314 - val_loss: 0.4387 - val_accuracy: 0.8262\n",
      "Epoch 88/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8215 - val_loss: 0.4402 - val_accuracy: 0.8262\n",
      "Epoch 89/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8345 - val_loss: 0.4404 - val_accuracy: 0.8262\n",
      "Epoch 90/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8291 - val_loss: 0.4392 - val_accuracy: 0.8201\n",
      "Epoch 91/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8246 - val_loss: 0.4405 - val_accuracy: 0.8262\n",
      "Epoch 92/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8215 - val_loss: 0.4384 - val_accuracy: 0.8262\n",
      "Epoch 93/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8307 - val_loss: 0.4377 - val_accuracy: 0.8262\n",
      "Epoch 94/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8276 - val_loss: 0.4379 - val_accuracy: 0.8232\n",
      "Epoch 95/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.8299 - val_loss: 0.4380 - val_accuracy: 0.8201\n",
      "Epoch 96/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8246 - val_loss: 0.4377 - val_accuracy: 0.8262\n",
      "Epoch 97/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8215 - val_loss: 0.4374 - val_accuracy: 0.8232\n",
      "Epoch 98/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8398 - val_loss: 0.4376 - val_accuracy: 0.8293\n",
      "Epoch 99/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.8314 - val_loss: 0.4384 - val_accuracy: 0.8232\n",
      "Epoch 100/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8345 - val_loss: 0.4404 - val_accuracy: 0.8201\n",
      "Epoch 101/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8284 - val_loss: 0.4388 - val_accuracy: 0.8293\n",
      "Epoch 102/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8284 - val_loss: 0.4374 - val_accuracy: 0.8293\n",
      "Epoch 103/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8200 - val_loss: 0.4350 - val_accuracy: 0.8262\n",
      "Epoch 104/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3997 - accuracy: 0.8398 - val_loss: 0.4355 - val_accuracy: 0.8201\n",
      "Epoch 105/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8284 - val_loss: 0.4372 - val_accuracy: 0.8232\n",
      "Epoch 106/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8223 - val_loss: 0.4390 - val_accuracy: 0.8201\n",
      "Epoch 107/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4137 - accuracy: 0.8299 - val_loss: 0.4367 - val_accuracy: 0.8232\n",
      "Epoch 108/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8238 - val_loss: 0.4354 - val_accuracy: 0.8232\n",
      "Epoch 109/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4093 - accuracy: 0.8291 - val_loss: 0.4359 - val_accuracy: 0.8232\n",
      "Epoch 110/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8322 - val_loss: 0.4355 - val_accuracy: 0.8232\n",
      "Epoch 111/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4100 - accuracy: 0.8299 - val_loss: 0.4341 - val_accuracy: 0.8232\n",
      "Epoch 112/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8284 - val_loss: 0.4375 - val_accuracy: 0.8171\n",
      "Epoch 113/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8314 - val_loss: 0.4365 - val_accuracy: 0.8201\n",
      "Epoch 114/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8314 - val_loss: 0.4380 - val_accuracy: 0.8171\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8368 - val_loss: 0.4411 - val_accuracy: 0.8232\n",
      "Epoch 116/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8322 - val_loss: 0.4390 - val_accuracy: 0.8232\n",
      "Epoch 117/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.8322 - val_loss: 0.4369 - val_accuracy: 0.8171\n",
      "Epoch 118/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8261 - val_loss: 0.4372 - val_accuracy: 0.8232\n",
      "Epoch 119/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.8284 - val_loss: 0.4394 - val_accuracy: 0.8293\n",
      "Epoch 120/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8398 - val_loss: 0.4413 - val_accuracy: 0.8262\n",
      "Epoch 121/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8383 - val_loss: 0.4409 - val_accuracy: 0.8201\n",
      "Epoch 122/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8299 - val_loss: 0.4413 - val_accuracy: 0.8262\n",
      "Epoch 123/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4029 - accuracy: 0.8291 - val_loss: 0.4419 - val_accuracy: 0.8262\n",
      "Epoch 124/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8268 - val_loss: 0.4401 - val_accuracy: 0.8323\n",
      "Epoch 125/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8314 - val_loss: 0.4388 - val_accuracy: 0.8293\n",
      "Epoch 126/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8246 - val_loss: 0.4407 - val_accuracy: 0.8201\n",
      "Epoch 127/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8459 - val_loss: 0.4418 - val_accuracy: 0.8232\n",
      "Epoch 128/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8360 - val_loss: 0.4396 - val_accuracy: 0.8262\n",
      "Epoch 129/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8299 - val_loss: 0.4391 - val_accuracy: 0.8262\n",
      "Epoch 130/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8322 - val_loss: 0.4388 - val_accuracy: 0.8293\n",
      "Epoch 131/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8253 - val_loss: 0.4375 - val_accuracy: 0.8262\n",
      "Epoch 132/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8398 - val_loss: 0.4395 - val_accuracy: 0.8262\n",
      "Epoch 133/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8330 - val_loss: 0.4401 - val_accuracy: 0.8262\n",
      "Epoch 134/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.8223 - val_loss: 0.4394 - val_accuracy: 0.8262\n",
      "Epoch 135/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8383 - val_loss: 0.4395 - val_accuracy: 0.8262\n",
      "Epoch 136/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8330 - val_loss: 0.4402 - val_accuracy: 0.8293\n",
      "Epoch 137/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8299 - val_loss: 0.4382 - val_accuracy: 0.8262\n",
      "Epoch 138/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8314 - val_loss: 0.4379 - val_accuracy: 0.8262\n",
      "Epoch 139/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8238 - val_loss: 0.4378 - val_accuracy: 0.8171\n",
      "Epoch 140/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8238 - val_loss: 0.4370 - val_accuracy: 0.8201\n",
      "Epoch 141/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.8299 - val_loss: 0.4363 - val_accuracy: 0.8262\n",
      "Epoch 142/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8398 - val_loss: 0.4375 - val_accuracy: 0.8262\n",
      "Epoch 143/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8383 - val_loss: 0.4382 - val_accuracy: 0.8262\n",
      "Epoch 144/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8368 - val_loss: 0.4398 - val_accuracy: 0.8262\n",
      "Epoch 145/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8352 - val_loss: 0.4427 - val_accuracy: 0.8293\n",
      "Epoch 146/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8345 - val_loss: 0.4424 - val_accuracy: 0.8262\n",
      "Epoch 147/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.8299 - val_loss: 0.4408 - val_accuracy: 0.8262\n",
      "Epoch 148/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4094 - accuracy: 0.8215 - val_loss: 0.4404 - val_accuracy: 0.8262\n",
      "Epoch 149/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8223 - val_loss: 0.4408 - val_accuracy: 0.8323\n",
      "Epoch 150/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8337 - val_loss: 0.4400 - val_accuracy: 0.8262\n",
      "Epoch 151/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8421 - val_loss: 0.4377 - val_accuracy: 0.8262\n",
      "Epoch 152/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.8375 - val_loss: 0.4386 - val_accuracy: 0.8232\n",
      "Epoch 153/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8368 - val_loss: 0.4381 - val_accuracy: 0.8232\n",
      "Epoch 154/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8375 - val_loss: 0.4386 - val_accuracy: 0.8232\n",
      "Epoch 155/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8261 - val_loss: 0.4401 - val_accuracy: 0.8201\n",
      "Epoch 156/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8368 - val_loss: 0.4410 - val_accuracy: 0.8201\n",
      "Epoch 157/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8375 - val_loss: 0.4426 - val_accuracy: 0.8201\n",
      "Epoch 158/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8436 - val_loss: 0.4420 - val_accuracy: 0.8201\n",
      "Epoch 159/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8299 - val_loss: 0.4436 - val_accuracy: 0.8232\n",
      "Epoch 160/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8375 - val_loss: 0.4450 - val_accuracy: 0.8232\n",
      "Epoch 161/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8429 - val_loss: 0.4433 - val_accuracy: 0.8232\n",
      "Epoch 162/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8452 - val_loss: 0.4440 - val_accuracy: 0.8232\n",
      "Epoch 163/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8421 - val_loss: 0.4417 - val_accuracy: 0.8232\n",
      "Epoch 164/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8253 - val_loss: 0.4395 - val_accuracy: 0.8262\n",
      "Epoch 165/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4060 - accuracy: 0.8352 - val_loss: 0.4413 - val_accuracy: 0.8232\n",
      "Epoch 166/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8291 - val_loss: 0.4406 - val_accuracy: 0.8232\n",
      "Epoch 167/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.8345 - val_loss: 0.4396 - val_accuracy: 0.8262\n",
      "Epoch 168/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8337 - val_loss: 0.4420 - val_accuracy: 0.8171\n",
      "Epoch 169/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8268 - val_loss: 0.4405 - val_accuracy: 0.8171\n",
      "Epoch 170/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8314 - val_loss: 0.4388 - val_accuracy: 0.8262\n",
      "Epoch 171/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8299 - val_loss: 0.4447 - val_accuracy: 0.8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8307 - val_loss: 0.4437 - val_accuracy: 0.8232\n",
      "Epoch 173/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8276 - val_loss: 0.4438 - val_accuracy: 0.8262\n",
      "Epoch 174/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.8345 - val_loss: 0.4454 - val_accuracy: 0.8232\n",
      "Epoch 175/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8314 - val_loss: 0.4471 - val_accuracy: 0.8232\n",
      "Epoch 176/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8368 - val_loss: 0.4464 - val_accuracy: 0.8201\n",
      "Epoch 177/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8345 - val_loss: 0.4477 - val_accuracy: 0.8232\n",
      "Epoch 178/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8299 - val_loss: 0.4460 - val_accuracy: 0.8232\n",
      "Epoch 179/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8276 - val_loss: 0.4456 - val_accuracy: 0.8262\n",
      "Epoch 180/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8383 - val_loss: 0.4456 - val_accuracy: 0.8232\n",
      "Epoch 181/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4048 - accuracy: 0.8238 - val_loss: 0.4440 - val_accuracy: 0.8293\n",
      "Epoch 182/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8307 - val_loss: 0.4422 - val_accuracy: 0.8293\n",
      "Epoch 183/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8444 - val_loss: 0.4430 - val_accuracy: 0.8232\n",
      "Epoch 184/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8307 - val_loss: 0.4424 - val_accuracy: 0.8293\n",
      "Epoch 185/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8421 - val_loss: 0.4432 - val_accuracy: 0.8262\n",
      "Epoch 186/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8368 - val_loss: 0.4425 - val_accuracy: 0.8262\n",
      "Epoch 187/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8345 - val_loss: 0.4449 - val_accuracy: 0.8293\n",
      "Epoch 188/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8345 - val_loss: 0.4452 - val_accuracy: 0.8293\n",
      "Epoch 189/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8276 - val_loss: 0.4448 - val_accuracy: 0.8293\n",
      "Epoch 190/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8375 - val_loss: 0.4462 - val_accuracy: 0.8293\n",
      "Epoch 191/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8307 - val_loss: 0.4466 - val_accuracy: 0.8232\n",
      "Epoch 192/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8238 - val_loss: 0.4447 - val_accuracy: 0.8232\n",
      "Epoch 193/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8429 - val_loss: 0.4479 - val_accuracy: 0.8201\n",
      "Epoch 194/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8299 - val_loss: 0.4460 - val_accuracy: 0.8201\n",
      "Epoch 195/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8368 - val_loss: 0.4481 - val_accuracy: 0.8201\n",
      "Epoch 196/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8284 - val_loss: 0.4487 - val_accuracy: 0.8201\n",
      "Epoch 197/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8360 - val_loss: 0.4474 - val_accuracy: 0.8201\n",
      "Epoch 198/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8452 - val_loss: 0.4454 - val_accuracy: 0.8232\n",
      "Epoch 199/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8330 - val_loss: 0.4456 - val_accuracy: 0.8262\n",
      "Epoch 200/1000\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8406 - val_loss: 0.4446 - val_accuracy: 0.8201\n",
      "Epoch 201/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8330 - val_loss: 0.4452 - val_accuracy: 0.8140\n",
      "Epoch 202/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8268 - val_loss: 0.4451 - val_accuracy: 0.8171\n",
      "Epoch 203/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8459 - val_loss: 0.4457 - val_accuracy: 0.8201\n",
      "Epoch 204/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8375 - val_loss: 0.4444 - val_accuracy: 0.8201\n",
      "Epoch 205/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8375 - val_loss: 0.4438 - val_accuracy: 0.8201\n",
      "Epoch 206/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8383 - val_loss: 0.4441 - val_accuracy: 0.8171\n",
      "Epoch 207/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8322 - val_loss: 0.4450 - val_accuracy: 0.8201\n",
      "Epoch 208/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8345 - val_loss: 0.4464 - val_accuracy: 0.8201\n",
      "Epoch 209/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8429 - val_loss: 0.4465 - val_accuracy: 0.8232\n",
      "Epoch 210/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8406 - val_loss: 0.4460 - val_accuracy: 0.8201\n",
      "Epoch 211/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8413 - val_loss: 0.4467 - val_accuracy: 0.8201\n",
      "Epoch 212/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8322 - val_loss: 0.4453 - val_accuracy: 0.8201\n",
      "Epoch 213/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8360 - val_loss: 0.4475 - val_accuracy: 0.8171\n",
      "Epoch 214/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8322 - val_loss: 0.4491 - val_accuracy: 0.8171\n",
      "Epoch 215/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8314 - val_loss: 0.4494 - val_accuracy: 0.8171\n",
      "Epoch 216/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8406 - val_loss: 0.4500 - val_accuracy: 0.8201\n",
      "Epoch 217/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8337 - val_loss: 0.4489 - val_accuracy: 0.8171\n",
      "Epoch 218/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.4477 - val_accuracy: 0.8171\n",
      "Epoch 219/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8337 - val_loss: 0.4493 - val_accuracy: 0.8201\n",
      "Epoch 220/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8406 - val_loss: 0.4488 - val_accuracy: 0.8232\n",
      "Epoch 221/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8352 - val_loss: 0.4498 - val_accuracy: 0.8232\n",
      "Epoch 222/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8406 - val_loss: 0.4473 - val_accuracy: 0.8232\n",
      "Epoch 223/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8299 - val_loss: 0.4490 - val_accuracy: 0.8232\n",
      "Epoch 224/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8330 - val_loss: 0.4499 - val_accuracy: 0.8232\n",
      "Epoch 225/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8345 - val_loss: 0.4494 - val_accuracy: 0.8232\n",
      "Epoch 226/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8360 - val_loss: 0.4487 - val_accuracy: 0.8262\n",
      "Epoch 227/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8452 - val_loss: 0.4510 - val_accuracy: 0.8201\n",
      "Epoch 228/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8307 - val_loss: 0.4503 - val_accuracy: 0.8232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8330 - val_loss: 0.4509 - val_accuracy: 0.8171\n",
      "Epoch 230/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8352 - val_loss: 0.4519 - val_accuracy: 0.8171\n",
      "Epoch 231/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8452 - val_loss: 0.4547 - val_accuracy: 0.8201\n",
      "Epoch 232/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8223 - val_loss: 0.4534 - val_accuracy: 0.8232\n",
      "Epoch 233/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8223 - val_loss: 0.4549 - val_accuracy: 0.8201\n",
      "Epoch 234/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8330 - val_loss: 0.4578 - val_accuracy: 0.8201\n",
      "Epoch 235/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8391 - val_loss: 0.4567 - val_accuracy: 0.8201\n",
      "Epoch 236/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8307 - val_loss: 0.4545 - val_accuracy: 0.8232\n",
      "Epoch 237/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8436 - val_loss: 0.4525 - val_accuracy: 0.8201\n",
      "Epoch 238/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8268 - val_loss: 0.4507 - val_accuracy: 0.8171\n",
      "Epoch 239/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8360 - val_loss: 0.4533 - val_accuracy: 0.8171\n",
      "Epoch 240/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8398 - val_loss: 0.4515 - val_accuracy: 0.8171\n",
      "Epoch 241/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8413 - val_loss: 0.4526 - val_accuracy: 0.8171\n",
      "Epoch 242/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8322 - val_loss: 0.4544 - val_accuracy: 0.8171\n",
      "Epoch 243/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8375 - val_loss: 0.4545 - val_accuracy: 0.8201\n",
      "Epoch 244/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8375 - val_loss: 0.4527 - val_accuracy: 0.8171\n",
      "Epoch 245/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8368 - val_loss: 0.4530 - val_accuracy: 0.8201\n",
      "Epoch 246/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8398 - val_loss: 0.4554 - val_accuracy: 0.8171\n",
      "Epoch 247/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8452 - val_loss: 0.4546 - val_accuracy: 0.8201\n",
      "Epoch 248/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8383 - val_loss: 0.4551 - val_accuracy: 0.8201\n",
      "Epoch 249/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8413 - val_loss: 0.4565 - val_accuracy: 0.8171\n",
      "Epoch 250/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8421 - val_loss: 0.4571 - val_accuracy: 0.8232\n",
      "Epoch 251/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8360 - val_loss: 0.4554 - val_accuracy: 0.8171\n",
      "Epoch 252/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8375 - val_loss: 0.4540 - val_accuracy: 0.8171\n",
      "Epoch 253/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8444 - val_loss: 0.4537 - val_accuracy: 0.8232\n",
      "Epoch 254/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8413 - val_loss: 0.4519 - val_accuracy: 0.8171\n",
      "Epoch 255/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8322 - val_loss: 0.4522 - val_accuracy: 0.8201\n",
      "Epoch 256/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8307 - val_loss: 0.4500 - val_accuracy: 0.8171\n",
      "Epoch 257/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8436 - val_loss: 0.4522 - val_accuracy: 0.8201\n",
      "Epoch 258/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8383 - val_loss: 0.4552 - val_accuracy: 0.8232\n",
      "Epoch 259/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8368 - val_loss: 0.4546 - val_accuracy: 0.8232\n",
      "Epoch 260/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8299 - val_loss: 0.4538 - val_accuracy: 0.8201\n",
      "Epoch 261/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8398 - val_loss: 0.4589 - val_accuracy: 0.8201\n",
      "Epoch 262/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8391 - val_loss: 0.4575 - val_accuracy: 0.8171\n",
      "Epoch 263/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8406 - val_loss: 0.4549 - val_accuracy: 0.8171\n",
      "Epoch 264/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8490 - val_loss: 0.4558 - val_accuracy: 0.8171\n",
      "Epoch 265/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8337 - val_loss: 0.4535 - val_accuracy: 0.8201\n",
      "Epoch 266/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8360 - val_loss: 0.4537 - val_accuracy: 0.8201\n",
      "Epoch 267/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8368 - val_loss: 0.4565 - val_accuracy: 0.8262\n",
      "Epoch 268/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8413 - val_loss: 0.4544 - val_accuracy: 0.8232\n",
      "Epoch 269/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8421 - val_loss: 0.4547 - val_accuracy: 0.8232\n",
      "Epoch 270/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8337 - val_loss: 0.4562 - val_accuracy: 0.8171\n",
      "Epoch 271/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8391 - val_loss: 0.4576 - val_accuracy: 0.8201\n",
      "Epoch 272/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8383 - val_loss: 0.4533 - val_accuracy: 0.8201\n",
      "Epoch 273/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8322 - val_loss: 0.4534 - val_accuracy: 0.8140\n",
      "Epoch 274/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8391 - val_loss: 0.4543 - val_accuracy: 0.8201\n",
      "Epoch 275/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8398 - val_loss: 0.4528 - val_accuracy: 0.8201\n",
      "Epoch 276/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8421 - val_loss: 0.4563 - val_accuracy: 0.8171\n",
      "Epoch 277/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8368 - val_loss: 0.4539 - val_accuracy: 0.8232\n",
      "Epoch 278/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8421 - val_loss: 0.4577 - val_accuracy: 0.8293\n",
      "Epoch 279/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8429 - val_loss: 0.4519 - val_accuracy: 0.8262\n",
      "Epoch 280/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8413 - val_loss: 0.4532 - val_accuracy: 0.8293\n",
      "Epoch 281/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8383 - val_loss: 0.4529 - val_accuracy: 0.8201\n",
      "Epoch 282/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8383 - val_loss: 0.4532 - val_accuracy: 0.8201\n",
      "Epoch 283/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8413 - val_loss: 0.4539 - val_accuracy: 0.8262\n",
      "Epoch 284/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8345 - val_loss: 0.4555 - val_accuracy: 0.8262\n",
      "Epoch 285/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8391 - val_loss: 0.4570 - val_accuracy: 0.8262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8436 - val_loss: 0.4546 - val_accuracy: 0.8201\n",
      "Epoch 287/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8375 - val_loss: 0.4551 - val_accuracy: 0.8201\n",
      "Epoch 288/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8467 - val_loss: 0.4563 - val_accuracy: 0.8232\n",
      "Epoch 289/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8429 - val_loss: 0.4579 - val_accuracy: 0.8232\n",
      "Epoch 290/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8368 - val_loss: 0.4551 - val_accuracy: 0.8232\n",
      "Epoch 291/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8375 - val_loss: 0.4529 - val_accuracy: 0.8201\n",
      "Epoch 292/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8322 - val_loss: 0.4526 - val_accuracy: 0.8201\n",
      "Epoch 293/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8360 - val_loss: 0.4555 - val_accuracy: 0.8232\n",
      "Epoch 294/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8452 - val_loss: 0.4558 - val_accuracy: 0.8171\n",
      "Epoch 295/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8368 - val_loss: 0.4562 - val_accuracy: 0.8232\n",
      "Epoch 296/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8406 - val_loss: 0.4559 - val_accuracy: 0.8201\n",
      "Epoch 297/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8398 - val_loss: 0.4542 - val_accuracy: 0.8171\n",
      "Epoch 298/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8337 - val_loss: 0.4544 - val_accuracy: 0.8140\n",
      "Epoch 299/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8261 - val_loss: 0.4542 - val_accuracy: 0.8140\n",
      "Epoch 300/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8330 - val_loss: 0.4545 - val_accuracy: 0.8110\n",
      "Epoch 301/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8345 - val_loss: 0.4573 - val_accuracy: 0.8140\n",
      "Epoch 302/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8322 - val_loss: 0.4549 - val_accuracy: 0.8140\n",
      "Epoch 303/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8291 - val_loss: 0.4530 - val_accuracy: 0.8201\n",
      "Epoch 304/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8352 - val_loss: 0.4541 - val_accuracy: 0.8110\n",
      "Epoch 305/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8375 - val_loss: 0.4589 - val_accuracy: 0.8110\n",
      "Epoch 306/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8375 - val_loss: 0.4585 - val_accuracy: 0.8140\n",
      "Epoch 307/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8352 - val_loss: 0.4581 - val_accuracy: 0.8140\n",
      "Epoch 308/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8345 - val_loss: 0.4595 - val_accuracy: 0.8201\n",
      "Epoch 309/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8474 - val_loss: 0.4583 - val_accuracy: 0.8201\n",
      "Epoch 310/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8520 - val_loss: 0.4604 - val_accuracy: 0.8201\n",
      "Epoch 311/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8360 - val_loss: 0.4579 - val_accuracy: 0.8201\n",
      "Epoch 312/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8337 - val_loss: 0.4590 - val_accuracy: 0.8201\n",
      "Epoch 313/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8406 - val_loss: 0.4603 - val_accuracy: 0.8201\n",
      "Epoch 314/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8520 - val_loss: 0.4596 - val_accuracy: 0.8201\n",
      "Epoch 315/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8337 - val_loss: 0.4612 - val_accuracy: 0.8232\n",
      "Epoch 316/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8436 - val_loss: 0.4612 - val_accuracy: 0.8201\n",
      "Epoch 317/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8421 - val_loss: 0.4586 - val_accuracy: 0.8201\n",
      "Epoch 318/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8352 - val_loss: 0.4581 - val_accuracy: 0.8201\n",
      "Epoch 319/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8429 - val_loss: 0.4600 - val_accuracy: 0.8201\n",
      "Epoch 320/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8406 - val_loss: 0.4577 - val_accuracy: 0.8201\n",
      "Epoch 321/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8337 - val_loss: 0.4589 - val_accuracy: 0.8201\n",
      "Epoch 322/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8444 - val_loss: 0.4614 - val_accuracy: 0.8201\n",
      "Epoch 323/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8413 - val_loss: 0.4632 - val_accuracy: 0.8201\n",
      "Epoch 324/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8360 - val_loss: 0.4648 - val_accuracy: 0.8171\n",
      "Epoch 325/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8497 - val_loss: 0.4646 - val_accuracy: 0.8201\n",
      "Epoch 326/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8452 - val_loss: 0.4623 - val_accuracy: 0.8110\n",
      "Epoch 327/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8345 - val_loss: 0.4611 - val_accuracy: 0.8140\n",
      "Epoch 328/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8520 - val_loss: 0.4635 - val_accuracy: 0.8171\n",
      "Epoch 329/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8322 - val_loss: 0.4595 - val_accuracy: 0.8140\n",
      "Epoch 330/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8444 - val_loss: 0.4587 - val_accuracy: 0.8171\n",
      "Epoch 331/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8330 - val_loss: 0.4582 - val_accuracy: 0.8171\n",
      "Epoch 332/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8429 - val_loss: 0.4610 - val_accuracy: 0.8110\n",
      "Epoch 333/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8291 - val_loss: 0.4643 - val_accuracy: 0.8079\n",
      "Epoch 334/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8413 - val_loss: 0.4635 - val_accuracy: 0.8079\n",
      "Epoch 335/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8360 - val_loss: 0.4617 - val_accuracy: 0.8110\n",
      "Epoch 336/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8436 - val_loss: 0.4612 - val_accuracy: 0.8110\n",
      "Epoch 337/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8383 - val_loss: 0.4600 - val_accuracy: 0.8079\n",
      "Epoch 338/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8360 - val_loss: 0.4580 - val_accuracy: 0.8110\n",
      "Epoch 339/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8406 - val_loss: 0.4603 - val_accuracy: 0.8201\n",
      "Epoch 340/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8444 - val_loss: 0.4586 - val_accuracy: 0.8140\n",
      "Epoch 341/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8314 - val_loss: 0.4578 - val_accuracy: 0.8171\n",
      "Epoch 342/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8383 - val_loss: 0.4565 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8421 - val_loss: 0.4557 - val_accuracy: 0.8110\n",
      "Epoch 344/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8360 - val_loss: 0.4584 - val_accuracy: 0.8171\n",
      "Epoch 345/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8429 - val_loss: 0.4599 - val_accuracy: 0.8110\n",
      "Epoch 346/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8413 - val_loss: 0.4625 - val_accuracy: 0.8110\n",
      "Epoch 347/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8238 - val_loss: 0.4599 - val_accuracy: 0.8140\n",
      "Epoch 348/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8421 - val_loss: 0.4612 - val_accuracy: 0.8171\n",
      "Epoch 349/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8398 - val_loss: 0.4591 - val_accuracy: 0.8171\n",
      "Epoch 350/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8429 - val_loss: 0.4585 - val_accuracy: 0.8201\n",
      "Epoch 351/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8391 - val_loss: 0.4619 - val_accuracy: 0.8232\n",
      "Epoch 352/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8368 - val_loss: 0.4646 - val_accuracy: 0.8232\n",
      "Epoch 353/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8398 - val_loss: 0.4635 - val_accuracy: 0.8232\n",
      "Epoch 354/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8413 - val_loss: 0.4617 - val_accuracy: 0.8232\n",
      "Epoch 355/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8421 - val_loss: 0.4637 - val_accuracy: 0.8232\n",
      "Epoch 356/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8421 - val_loss: 0.4625 - val_accuracy: 0.8232\n",
      "Epoch 357/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8413 - val_loss: 0.4584 - val_accuracy: 0.8140\n",
      "Epoch 358/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8406 - val_loss: 0.4616 - val_accuracy: 0.8171\n",
      "Epoch 359/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8551 - val_loss: 0.4650 - val_accuracy: 0.8140\n",
      "Epoch 360/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8345 - val_loss: 0.4630 - val_accuracy: 0.8140\n",
      "Epoch 361/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8452 - val_loss: 0.4640 - val_accuracy: 0.8110\n",
      "Epoch 362/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8398 - val_loss: 0.4630 - val_accuracy: 0.8110\n",
      "Epoch 363/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8368 - val_loss: 0.4635 - val_accuracy: 0.8171\n",
      "Epoch 364/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8284 - val_loss: 0.4631 - val_accuracy: 0.8140\n",
      "Epoch 365/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8391 - val_loss: 0.4592 - val_accuracy: 0.8171\n",
      "Epoch 366/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8505 - val_loss: 0.4615 - val_accuracy: 0.8201\n",
      "Epoch 367/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8398 - val_loss: 0.4622 - val_accuracy: 0.8171\n",
      "Epoch 368/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8330 - val_loss: 0.4619 - val_accuracy: 0.8171\n",
      "Epoch 369/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8360 - val_loss: 0.4615 - val_accuracy: 0.8171\n",
      "Epoch 370/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8307 - val_loss: 0.4585 - val_accuracy: 0.8140\n",
      "Epoch 371/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8391 - val_loss: 0.4574 - val_accuracy: 0.8140\n",
      "Epoch 372/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8398 - val_loss: 0.4635 - val_accuracy: 0.8140\n",
      "Epoch 373/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8383 - val_loss: 0.4631 - val_accuracy: 0.8171\n",
      "Epoch 374/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8322 - val_loss: 0.4624 - val_accuracy: 0.8171\n",
      "Epoch 375/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8375 - val_loss: 0.4640 - val_accuracy: 0.8171\n",
      "Epoch 376/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8429 - val_loss: 0.4689 - val_accuracy: 0.8171\n",
      "Epoch 377/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8368 - val_loss: 0.4674 - val_accuracy: 0.8171\n",
      "Epoch 378/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8421 - val_loss: 0.4678 - val_accuracy: 0.8171\n",
      "Epoch 379/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8406 - val_loss: 0.4654 - val_accuracy: 0.8140\n",
      "Epoch 380/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8429 - val_loss: 0.4659 - val_accuracy: 0.8201\n",
      "Epoch 381/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8421 - val_loss: 0.4641 - val_accuracy: 0.8171\n",
      "Epoch 382/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8436 - val_loss: 0.4649 - val_accuracy: 0.8232\n",
      "Epoch 383/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8497 - val_loss: 0.4647 - val_accuracy: 0.8232\n",
      "Epoch 384/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8299 - val_loss: 0.4658 - val_accuracy: 0.8232\n",
      "Epoch 385/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8383 - val_loss: 0.4671 - val_accuracy: 0.8232\n",
      "Epoch 386/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8406 - val_loss: 0.4682 - val_accuracy: 0.8171\n",
      "Epoch 387/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8497 - val_loss: 0.4685 - val_accuracy: 0.8171\n",
      "Epoch 388/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8436 - val_loss: 0.4687 - val_accuracy: 0.8140\n",
      "Epoch 389/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8383 - val_loss: 0.4690 - val_accuracy: 0.8110\n",
      "Epoch 390/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8360 - val_loss: 0.4681 - val_accuracy: 0.8110\n",
      "Epoch 391/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8345 - val_loss: 0.4686 - val_accuracy: 0.8171\n",
      "Epoch 392/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8429 - val_loss: 0.4700 - val_accuracy: 0.8171\n",
      "Epoch 393/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8429 - val_loss: 0.4717 - val_accuracy: 0.8171\n",
      "Epoch 394/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8474 - val_loss: 0.4681 - val_accuracy: 0.8140\n",
      "Epoch 395/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8383 - val_loss: 0.4713 - val_accuracy: 0.8140\n",
      "Epoch 396/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8368 - val_loss: 0.4683 - val_accuracy: 0.8171\n",
      "Epoch 397/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8528 - val_loss: 0.4628 - val_accuracy: 0.8171\n",
      "Epoch 398/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8291 - val_loss: 0.4615 - val_accuracy: 0.8171\n",
      "Epoch 399/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8345 - val_loss: 0.4626 - val_accuracy: 0.8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8474 - val_loss: 0.4672 - val_accuracy: 0.8201\n",
      "Epoch 401/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8375 - val_loss: 0.4682 - val_accuracy: 0.8171\n",
      "Epoch 402/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8497 - val_loss: 0.4682 - val_accuracy: 0.8201\n",
      "Epoch 403/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8398 - val_loss: 0.4670 - val_accuracy: 0.8171\n",
      "Epoch 404/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8482 - val_loss: 0.4680 - val_accuracy: 0.8171\n",
      "Epoch 405/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8375 - val_loss: 0.4709 - val_accuracy: 0.8232\n",
      "Epoch 406/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8490 - val_loss: 0.4700 - val_accuracy: 0.8171\n",
      "Epoch 407/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8383 - val_loss: 0.4660 - val_accuracy: 0.8171\n",
      "Epoch 408/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8398 - val_loss: 0.4666 - val_accuracy: 0.8232\n",
      "Epoch 409/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8391 - val_loss: 0.4692 - val_accuracy: 0.8201\n",
      "Epoch 410/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8383 - val_loss: 0.4686 - val_accuracy: 0.8201\n",
      "Epoch 411/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8429 - val_loss: 0.4684 - val_accuracy: 0.8232\n",
      "Epoch 412/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8413 - val_loss: 0.4699 - val_accuracy: 0.8232\n",
      "Epoch 413/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8398 - val_loss: 0.4696 - val_accuracy: 0.8232\n",
      "Epoch 414/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8391 - val_loss: 0.4730 - val_accuracy: 0.8201\n",
      "Epoch 415/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8406 - val_loss: 0.4723 - val_accuracy: 0.8232\n",
      "Epoch 416/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8391 - val_loss: 0.4687 - val_accuracy: 0.8171\n",
      "Epoch 417/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8406 - val_loss: 0.4676 - val_accuracy: 0.8201\n",
      "Epoch 418/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8360 - val_loss: 0.4659 - val_accuracy: 0.8201\n",
      "Epoch 419/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8375 - val_loss: 0.4671 - val_accuracy: 0.8171\n",
      "Epoch 420/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8375 - val_loss: 0.4633 - val_accuracy: 0.8171\n",
      "Epoch 421/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8398 - val_loss: 0.4646 - val_accuracy: 0.8201\n",
      "Epoch 422/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8383 - val_loss: 0.4652 - val_accuracy: 0.8201\n",
      "Epoch 423/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8413 - val_loss: 0.4602 - val_accuracy: 0.8232\n",
      "Epoch 424/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8459 - val_loss: 0.4594 - val_accuracy: 0.8232\n",
      "Epoch 425/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8383 - val_loss: 0.4619 - val_accuracy: 0.8232\n",
      "Epoch 426/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8314 - val_loss: 0.4628 - val_accuracy: 0.8201\n",
      "Epoch 427/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8413 - val_loss: 0.4609 - val_accuracy: 0.8262\n",
      "Epoch 428/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8391 - val_loss: 0.4615 - val_accuracy: 0.8201\n",
      "Epoch 429/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8444 - val_loss: 0.4638 - val_accuracy: 0.8262\n",
      "Epoch 430/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8375 - val_loss: 0.4647 - val_accuracy: 0.8232\n",
      "Epoch 431/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8368 - val_loss: 0.4635 - val_accuracy: 0.8232\n",
      "Epoch 432/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.4626 - val_accuracy: 0.8232\n",
      "Epoch 433/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8459 - val_loss: 0.4640 - val_accuracy: 0.8232\n",
      "Epoch 434/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8421 - val_loss: 0.4660 - val_accuracy: 0.8262\n",
      "Epoch 435/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8490 - val_loss: 0.4697 - val_accuracy: 0.8262\n",
      "Epoch 436/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8345 - val_loss: 0.4651 - val_accuracy: 0.8232\n",
      "Epoch 437/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8345 - val_loss: 0.4637 - val_accuracy: 0.8232\n",
      "Epoch 438/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8444 - val_loss: 0.4625 - val_accuracy: 0.8232\n",
      "Epoch 439/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8467 - val_loss: 0.4648 - val_accuracy: 0.8232\n",
      "Epoch 440/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8276 - val_loss: 0.4622 - val_accuracy: 0.8232\n",
      "Epoch 441/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8345 - val_loss: 0.4621 - val_accuracy: 0.8232\n",
      "Epoch 442/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8452 - val_loss: 0.4647 - val_accuracy: 0.8262\n",
      "Epoch 443/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8276 - val_loss: 0.4629 - val_accuracy: 0.8232\n",
      "Epoch 444/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8352 - val_loss: 0.4657 - val_accuracy: 0.8262\n",
      "Epoch 445/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8474 - val_loss: 0.4657 - val_accuracy: 0.8262\n",
      "Epoch 446/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8375 - val_loss: 0.4679 - val_accuracy: 0.8232\n",
      "Epoch 447/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8413 - val_loss: 0.4674 - val_accuracy: 0.8262\n",
      "Epoch 448/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8444 - val_loss: 0.4666 - val_accuracy: 0.8232\n",
      "Epoch 449/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8467 - val_loss: 0.4642 - val_accuracy: 0.8232\n",
      "Epoch 450/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8368 - val_loss: 0.4675 - val_accuracy: 0.8201\n",
      "Epoch 451/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8368 - val_loss: 0.4673 - val_accuracy: 0.8140\n",
      "Epoch 452/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8383 - val_loss: 0.4710 - val_accuracy: 0.8140\n",
      "Epoch 453/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8413 - val_loss: 0.4696 - val_accuracy: 0.8140\n",
      "Epoch 454/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8383 - val_loss: 0.4701 - val_accuracy: 0.8110\n",
      "Epoch 455/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8299 - val_loss: 0.4708 - val_accuracy: 0.8140\n",
      "Epoch 456/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8429 - val_loss: 0.4749 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8421 - val_loss: 0.4742 - val_accuracy: 0.8140\n",
      "Epoch 458/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8360 - val_loss: 0.4717 - val_accuracy: 0.8171\n",
      "Epoch 459/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8268 - val_loss: 0.4669 - val_accuracy: 0.8171\n",
      "Epoch 460/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8421 - val_loss: 0.4713 - val_accuracy: 0.8171\n",
      "Epoch 461/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8391 - val_loss: 0.4749 - val_accuracy: 0.8171\n",
      "Epoch 462/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8398 - val_loss: 0.4748 - val_accuracy: 0.8201\n",
      "Epoch 463/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8452 - val_loss: 0.4763 - val_accuracy: 0.8140\n",
      "Epoch 464/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8368 - val_loss: 0.4764 - val_accuracy: 0.8140\n",
      "Epoch 465/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8368 - val_loss: 0.4778 - val_accuracy: 0.8171\n",
      "Epoch 466/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8482 - val_loss: 0.4817 - val_accuracy: 0.8232\n",
      "Epoch 467/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8467 - val_loss: 0.4791 - val_accuracy: 0.8232\n",
      "Epoch 468/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8360 - val_loss: 0.4771 - val_accuracy: 0.8232\n",
      "Epoch 469/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8352 - val_loss: 0.4716 - val_accuracy: 0.8201\n",
      "Epoch 470/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8391 - val_loss: 0.4712 - val_accuracy: 0.8201\n",
      "Epoch 471/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8444 - val_loss: 0.4741 - val_accuracy: 0.8201\n",
      "Epoch 472/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8368 - val_loss: 0.4730 - val_accuracy: 0.8232\n",
      "Epoch 473/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8421 - val_loss: 0.4725 - val_accuracy: 0.8171\n",
      "Epoch 474/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8398 - val_loss: 0.4725 - val_accuracy: 0.8201\n",
      "Epoch 475/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8474 - val_loss: 0.4762 - val_accuracy: 0.8201\n",
      "Epoch 476/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8413 - val_loss: 0.4745 - val_accuracy: 0.8201\n",
      "Epoch 477/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8429 - val_loss: 0.4745 - val_accuracy: 0.8140\n",
      "Epoch 478/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8429 - val_loss: 0.4793 - val_accuracy: 0.8201\n",
      "Epoch 479/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8406 - val_loss: 0.4758 - val_accuracy: 0.8201\n",
      "Epoch 480/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8360 - val_loss: 0.4781 - val_accuracy: 0.8201\n",
      "Epoch 481/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8368 - val_loss: 0.4794 - val_accuracy: 0.8201\n",
      "Epoch 482/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8452 - val_loss: 0.4790 - val_accuracy: 0.8171\n",
      "Epoch 483/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8383 - val_loss: 0.4751 - val_accuracy: 0.8140\n",
      "Epoch 484/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8421 - val_loss: 0.4760 - val_accuracy: 0.8140\n",
      "Epoch 485/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8444 - val_loss: 0.4756 - val_accuracy: 0.8140\n",
      "Epoch 486/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8497 - val_loss: 0.4784 - val_accuracy: 0.8140\n",
      "Epoch 487/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8436 - val_loss: 0.4733 - val_accuracy: 0.8140\n",
      "Epoch 488/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8459 - val_loss: 0.4758 - val_accuracy: 0.8140\n",
      "Epoch 489/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8452 - val_loss: 0.4736 - val_accuracy: 0.8140\n",
      "Epoch 490/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8482 - val_loss: 0.4776 - val_accuracy: 0.8171\n",
      "Epoch 491/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8482 - val_loss: 0.4785 - val_accuracy: 0.8171\n",
      "Epoch 492/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8467 - val_loss: 0.4748 - val_accuracy: 0.8140\n",
      "Epoch 493/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8284 - val_loss: 0.4777 - val_accuracy: 0.8110\n",
      "Epoch 494/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8352 - val_loss: 0.4729 - val_accuracy: 0.8110\n",
      "Epoch 495/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8368 - val_loss: 0.4737 - val_accuracy: 0.8110\n",
      "Epoch 496/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8352 - val_loss: 0.4715 - val_accuracy: 0.8110\n",
      "Epoch 497/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8421 - val_loss: 0.4720 - val_accuracy: 0.8201\n",
      "Epoch 498/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8497 - val_loss: 0.4749 - val_accuracy: 0.8201\n",
      "Epoch 499/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8368 - val_loss: 0.4753 - val_accuracy: 0.8201\n",
      "Epoch 500/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8429 - val_loss: 0.4797 - val_accuracy: 0.8201\n",
      "Epoch 501/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8352 - val_loss: 0.4810 - val_accuracy: 0.8171\n",
      "Epoch 502/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8452 - val_loss: 0.4821 - val_accuracy: 0.8140\n",
      "Epoch 503/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8444 - val_loss: 0.4808 - val_accuracy: 0.8140\n",
      "Epoch 504/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8368 - val_loss: 0.4815 - val_accuracy: 0.8171\n",
      "Epoch 505/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8421 - val_loss: 0.4790 - val_accuracy: 0.8140\n",
      "Epoch 506/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8398 - val_loss: 0.4780 - val_accuracy: 0.8171\n",
      "Epoch 507/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8436 - val_loss: 0.4791 - val_accuracy: 0.8140\n",
      "Epoch 508/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8444 - val_loss: 0.4826 - val_accuracy: 0.8171\n",
      "Epoch 509/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8459 - val_loss: 0.4775 - val_accuracy: 0.8140\n",
      "Epoch 510/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8352 - val_loss: 0.4804 - val_accuracy: 0.8110\n",
      "Epoch 511/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8452 - val_loss: 0.4806 - val_accuracy: 0.8140\n",
      "Epoch 512/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8337 - val_loss: 0.4805 - val_accuracy: 0.8140\n",
      "Epoch 513/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8429 - val_loss: 0.4774 - val_accuracy: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8528 - val_loss: 0.4776 - val_accuracy: 0.8171\n",
      "Epoch 515/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8490 - val_loss: 0.4732 - val_accuracy: 0.8171\n",
      "Epoch 516/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8368 - val_loss: 0.4746 - val_accuracy: 0.8171\n",
      "Epoch 517/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8444 - val_loss: 0.4740 - val_accuracy: 0.8171\n",
      "Epoch 518/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8467 - val_loss: 0.4760 - val_accuracy: 0.8140\n",
      "Epoch 519/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8528 - val_loss: 0.4759 - val_accuracy: 0.8110\n",
      "Epoch 520/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8444 - val_loss: 0.4816 - val_accuracy: 0.8171\n",
      "Epoch 521/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8337 - val_loss: 0.4783 - val_accuracy: 0.8140\n",
      "Epoch 522/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8360 - val_loss: 0.4756 - val_accuracy: 0.8201\n",
      "Epoch 523/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8391 - val_loss: 0.4747 - val_accuracy: 0.8140\n",
      "Epoch 524/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8459 - val_loss: 0.4778 - val_accuracy: 0.8140\n",
      "Epoch 525/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8337 - val_loss: 0.4765 - val_accuracy: 0.8079\n",
      "Epoch 526/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8459 - val_loss: 0.4754 - val_accuracy: 0.8079\n",
      "Epoch 527/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8497 - val_loss: 0.4812 - val_accuracy: 0.8140\n",
      "Epoch 528/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8436 - val_loss: 0.4824 - val_accuracy: 0.8140\n",
      "Epoch 529/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8467 - val_loss: 0.4802 - val_accuracy: 0.8140\n",
      "Epoch 530/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8429 - val_loss: 0.4839 - val_accuracy: 0.8171\n",
      "Epoch 531/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8413 - val_loss: 0.4804 - val_accuracy: 0.8140\n",
      "Epoch 532/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8452 - val_loss: 0.4766 - val_accuracy: 0.8140\n",
      "Epoch 533/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8513 - val_loss: 0.4779 - val_accuracy: 0.8140\n",
      "Epoch 534/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8391 - val_loss: 0.4772 - val_accuracy: 0.8201\n",
      "Epoch 535/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8398 - val_loss: 0.4786 - val_accuracy: 0.8232\n",
      "Epoch 536/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8406 - val_loss: 0.4794 - val_accuracy: 0.8201\n",
      "Epoch 537/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8474 - val_loss: 0.4794 - val_accuracy: 0.8140\n",
      "Epoch 538/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8406 - val_loss: 0.4803 - val_accuracy: 0.8171\n",
      "Epoch 539/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8444 - val_loss: 0.4798 - val_accuracy: 0.8171\n",
      "Epoch 540/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8330 - val_loss: 0.4805 - val_accuracy: 0.8232\n",
      "Epoch 541/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8444 - val_loss: 0.4788 - val_accuracy: 0.8171\n",
      "Epoch 542/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8467 - val_loss: 0.4815 - val_accuracy: 0.8201\n",
      "Epoch 543/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8520 - val_loss: 0.4854 - val_accuracy: 0.8232\n",
      "Epoch 544/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8391 - val_loss: 0.4842 - val_accuracy: 0.8201\n",
      "Epoch 545/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8360 - val_loss: 0.4797 - val_accuracy: 0.8171\n",
      "Epoch 546/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8322 - val_loss: 0.4818 - val_accuracy: 0.8232\n",
      "Epoch 547/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8337 - val_loss: 0.4844 - val_accuracy: 0.8201\n",
      "Epoch 548/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8444 - val_loss: 0.4802 - val_accuracy: 0.8201\n",
      "Epoch 549/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8535 - val_loss: 0.4776 - val_accuracy: 0.8140\n",
      "Epoch 550/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8474 - val_loss: 0.4753 - val_accuracy: 0.8140\n",
      "Epoch 551/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8375 - val_loss: 0.4773 - val_accuracy: 0.8232\n",
      "Epoch 552/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8383 - val_loss: 0.4802 - val_accuracy: 0.8171\n",
      "Epoch 553/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8505 - val_loss: 0.4789 - val_accuracy: 0.8201\n",
      "Epoch 554/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8383 - val_loss: 0.4796 - val_accuracy: 0.8171\n",
      "Epoch 555/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8352 - val_loss: 0.4743 - val_accuracy: 0.8171\n",
      "Epoch 556/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8444 - val_loss: 0.4780 - val_accuracy: 0.8171\n",
      "Epoch 557/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8505 - val_loss: 0.4813 - val_accuracy: 0.8201\n",
      "Epoch 558/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8421 - val_loss: 0.4838 - val_accuracy: 0.8140\n",
      "Epoch 559/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8421 - val_loss: 0.4816 - val_accuracy: 0.8110\n",
      "Epoch 560/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8452 - val_loss: 0.4793 - val_accuracy: 0.8079\n",
      "Epoch 561/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8398 - val_loss: 0.4788 - val_accuracy: 0.8110\n",
      "Epoch 562/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8391 - val_loss: 0.4811 - val_accuracy: 0.8110\n",
      "Epoch 563/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8467 - val_loss: 0.4818 - val_accuracy: 0.8201\n",
      "Epoch 564/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8307 - val_loss: 0.4760 - val_accuracy: 0.8201\n",
      "Epoch 565/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8391 - val_loss: 0.4773 - val_accuracy: 0.8201\n",
      "Epoch 566/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8368 - val_loss: 0.4756 - val_accuracy: 0.8171\n",
      "Epoch 567/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8452 - val_loss: 0.4778 - val_accuracy: 0.8140\n",
      "Epoch 568/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8421 - val_loss: 0.4779 - val_accuracy: 0.8110\n",
      "Epoch 569/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8505 - val_loss: 0.4810 - val_accuracy: 0.8171\n",
      "Epoch 570/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8513 - val_loss: 0.4799 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8505 - val_loss: 0.4773 - val_accuracy: 0.8140\n",
      "Epoch 572/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8391 - val_loss: 0.4790 - val_accuracy: 0.8171\n",
      "Epoch 573/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8307 - val_loss: 0.4816 - val_accuracy: 0.8171\n",
      "Epoch 574/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8413 - val_loss: 0.4786 - val_accuracy: 0.8140\n",
      "Epoch 575/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8360 - val_loss: 0.4821 - val_accuracy: 0.8140\n",
      "Epoch 576/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8459 - val_loss: 0.4839 - val_accuracy: 0.8201\n",
      "Epoch 577/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8474 - val_loss: 0.4867 - val_accuracy: 0.8171\n",
      "Epoch 578/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8368 - val_loss: 0.4863 - val_accuracy: 0.8171\n",
      "Epoch 579/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8429 - val_loss: 0.4880 - val_accuracy: 0.8140\n",
      "Epoch 580/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8528 - val_loss: 0.4876 - val_accuracy: 0.8140\n",
      "Epoch 581/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8383 - val_loss: 0.4855 - val_accuracy: 0.8171\n",
      "Epoch 582/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8459 - val_loss: 0.4922 - val_accuracy: 0.8140\n",
      "Epoch 583/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8429 - val_loss: 0.4876 - val_accuracy: 0.8171\n",
      "Epoch 584/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8421 - val_loss: 0.4787 - val_accuracy: 0.8171\n",
      "Epoch 585/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8398 - val_loss: 0.4795 - val_accuracy: 0.8171\n",
      "Epoch 586/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8421 - val_loss: 0.4802 - val_accuracy: 0.8140\n",
      "Epoch 587/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8383 - val_loss: 0.4830 - val_accuracy: 0.8171\n",
      "Epoch 588/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8436 - val_loss: 0.4833 - val_accuracy: 0.8171\n",
      "Epoch 589/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8375 - val_loss: 0.4858 - val_accuracy: 0.8110\n",
      "Epoch 590/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8383 - val_loss: 0.4778 - val_accuracy: 0.8110\n",
      "Epoch 591/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8474 - val_loss: 0.4849 - val_accuracy: 0.8110\n",
      "Epoch 592/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8452 - val_loss: 0.4829 - val_accuracy: 0.8110\n",
      "Epoch 593/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8375 - val_loss: 0.4845 - val_accuracy: 0.8140\n",
      "Epoch 594/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8413 - val_loss: 0.4818 - val_accuracy: 0.8171\n",
      "Epoch 595/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8391 - val_loss: 0.4810 - val_accuracy: 0.8201\n",
      "Epoch 596/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8482 - val_loss: 0.4822 - val_accuracy: 0.8171\n",
      "Epoch 597/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8490 - val_loss: 0.4821 - val_accuracy: 0.8201\n",
      "Epoch 598/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8505 - val_loss: 0.4841 - val_accuracy: 0.8201\n",
      "Epoch 599/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8429 - val_loss: 0.4858 - val_accuracy: 0.8140\n",
      "Epoch 600/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8391 - val_loss: 0.4809 - val_accuracy: 0.8110\n",
      "Epoch 601/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8467 - val_loss: 0.4833 - val_accuracy: 0.8140\n",
      "Epoch 602/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8429 - val_loss: 0.4846 - val_accuracy: 0.8140\n",
      "Epoch 603/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8360 - val_loss: 0.4836 - val_accuracy: 0.8171\n",
      "Epoch 604/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8375 - val_loss: 0.4811 - val_accuracy: 0.8140\n",
      "Epoch 605/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8429 - val_loss: 0.4857 - val_accuracy: 0.8171\n",
      "Epoch 606/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8421 - val_loss: 0.4872 - val_accuracy: 0.8201\n",
      "Epoch 607/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8452 - val_loss: 0.4899 - val_accuracy: 0.8201\n",
      "Epoch 608/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8368 - val_loss: 0.4890 - val_accuracy: 0.8201\n",
      "Epoch 609/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8322 - val_loss: 0.4868 - val_accuracy: 0.8201\n",
      "Epoch 610/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8307 - val_loss: 0.4824 - val_accuracy: 0.8171\n",
      "Epoch 611/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8436 - val_loss: 0.4829 - val_accuracy: 0.8140\n",
      "Epoch 612/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8413 - val_loss: 0.4864 - val_accuracy: 0.8110\n",
      "Epoch 613/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8482 - val_loss: 0.4894 - val_accuracy: 0.8232\n",
      "Epoch 614/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8406 - val_loss: 0.4878 - val_accuracy: 0.8140\n",
      "Epoch 615/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8474 - val_loss: 0.4916 - val_accuracy: 0.8140\n",
      "Epoch 616/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8482 - val_loss: 0.4889 - val_accuracy: 0.8232\n",
      "Epoch 617/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8398 - val_loss: 0.4862 - val_accuracy: 0.8140\n",
      "Epoch 618/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8345 - val_loss: 0.4899 - val_accuracy: 0.8140\n",
      "Epoch 619/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8482 - val_loss: 0.4904 - val_accuracy: 0.8110\n",
      "Epoch 620/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8436 - val_loss: 0.4877 - val_accuracy: 0.8049\n",
      "Epoch 621/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8391 - val_loss: 0.4887 - val_accuracy: 0.8110\n",
      "Epoch 622/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8375 - val_loss: 0.4888 - val_accuracy: 0.8110\n",
      "Epoch 623/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8398 - val_loss: 0.4900 - val_accuracy: 0.8140\n",
      "Epoch 624/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8474 - val_loss: 0.4887 - val_accuracy: 0.8140\n",
      "Epoch 625/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8474 - val_loss: 0.4908 - val_accuracy: 0.8140\n",
      "Epoch 626/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8413 - val_loss: 0.4922 - val_accuracy: 0.8171\n",
      "Epoch 627/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8368 - val_loss: 0.4908 - val_accuracy: 0.8110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8429 - val_loss: 0.4944 - val_accuracy: 0.8140\n",
      "Epoch 629/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8436 - val_loss: 0.4944 - val_accuracy: 0.8110\n",
      "Epoch 630/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8528 - val_loss: 0.4926 - val_accuracy: 0.8140\n",
      "Epoch 631/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8513 - val_loss: 0.4928 - val_accuracy: 0.8171\n",
      "Epoch 632/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8436 - val_loss: 0.4922 - val_accuracy: 0.8140\n",
      "Epoch 633/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8337 - val_loss: 0.4882 - val_accuracy: 0.8110\n",
      "Epoch 634/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8490 - val_loss: 0.4901 - val_accuracy: 0.8110\n",
      "Epoch 635/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8467 - val_loss: 0.4924 - val_accuracy: 0.8110\n",
      "Epoch 636/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8337 - val_loss: 0.4943 - val_accuracy: 0.8079\n",
      "Epoch 637/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8474 - val_loss: 0.4980 - val_accuracy: 0.8171\n",
      "Epoch 638/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8398 - val_loss: 0.4946 - val_accuracy: 0.8140\n",
      "Epoch 639/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8452 - val_loss: 0.4892 - val_accuracy: 0.8049\n",
      "Epoch 640/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8467 - val_loss: 0.4910 - val_accuracy: 0.8140\n",
      "Epoch 641/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8474 - val_loss: 0.4895 - val_accuracy: 0.8140\n",
      "Epoch 642/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8467 - val_loss: 0.4892 - val_accuracy: 0.8201\n",
      "Epoch 643/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8345 - val_loss: 0.4858 - val_accuracy: 0.8201\n",
      "Epoch 644/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8330 - val_loss: 0.4880 - val_accuracy: 0.8201\n",
      "Epoch 645/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8467 - val_loss: 0.4914 - val_accuracy: 0.8171\n",
      "Epoch 646/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8452 - val_loss: 0.4923 - val_accuracy: 0.8140\n",
      "Epoch 647/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8497 - val_loss: 0.4948 - val_accuracy: 0.8171\n",
      "Epoch 648/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8452 - val_loss: 0.4951 - val_accuracy: 0.8171\n",
      "Epoch 649/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8543 - val_loss: 0.4981 - val_accuracy: 0.8140\n",
      "Epoch 650/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8467 - val_loss: 0.4930 - val_accuracy: 0.8140\n",
      "Epoch 651/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8444 - val_loss: 0.4921 - val_accuracy: 0.8140\n",
      "Epoch 652/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8444 - val_loss: 0.4956 - val_accuracy: 0.8140\n",
      "Epoch 653/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8467 - val_loss: 0.4971 - val_accuracy: 0.8140\n",
      "Epoch 654/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8551 - val_loss: 0.4960 - val_accuracy: 0.8140\n",
      "Epoch 655/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8421 - val_loss: 0.4930 - val_accuracy: 0.8140\n",
      "Epoch 656/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8497 - val_loss: 0.4970 - val_accuracy: 0.8140\n",
      "Epoch 657/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8345 - val_loss: 0.4911 - val_accuracy: 0.8140\n",
      "Epoch 658/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8391 - val_loss: 0.4912 - val_accuracy: 0.8110\n",
      "Epoch 659/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8528 - val_loss: 0.4956 - val_accuracy: 0.8140\n",
      "Epoch 660/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8612 - val_loss: 0.4930 - val_accuracy: 0.8171\n",
      "Epoch 661/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8253 - val_loss: 0.4873 - val_accuracy: 0.8110\n",
      "Epoch 662/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8513 - val_loss: 0.4873 - val_accuracy: 0.8110\n",
      "Epoch 663/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8505 - val_loss: 0.4894 - val_accuracy: 0.8110\n",
      "Epoch 664/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8406 - val_loss: 0.4910 - val_accuracy: 0.8110\n",
      "Epoch 665/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8490 - val_loss: 0.4867 - val_accuracy: 0.8140\n",
      "Epoch 666/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8352 - val_loss: 0.4869 - val_accuracy: 0.8171\n",
      "Epoch 667/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8482 - val_loss: 0.4871 - val_accuracy: 0.8171\n",
      "Epoch 668/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8429 - val_loss: 0.4933 - val_accuracy: 0.8171\n",
      "Epoch 669/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8436 - val_loss: 0.4888 - val_accuracy: 0.8140\n",
      "Epoch 670/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8535 - val_loss: 0.4899 - val_accuracy: 0.8140\n",
      "Epoch 671/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8497 - val_loss: 0.4872 - val_accuracy: 0.8110\n",
      "Epoch 672/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8467 - val_loss: 0.4907 - val_accuracy: 0.8171\n",
      "Epoch 673/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8482 - val_loss: 0.4914 - val_accuracy: 0.8171\n",
      "Epoch 674/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8391 - val_loss: 0.4894 - val_accuracy: 0.8201\n",
      "Epoch 675/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8391 - val_loss: 0.4863 - val_accuracy: 0.8201\n",
      "Epoch 676/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8337 - val_loss: 0.4866 - val_accuracy: 0.8110\n",
      "Epoch 677/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8413 - val_loss: 0.4856 - val_accuracy: 0.8171\n",
      "Epoch 678/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8436 - val_loss: 0.4896 - val_accuracy: 0.8201\n",
      "Epoch 679/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8413 - val_loss: 0.4887 - val_accuracy: 0.8171\n",
      "Epoch 680/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8345 - val_loss: 0.4880 - val_accuracy: 0.8140\n",
      "Epoch 681/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8413 - val_loss: 0.4899 - val_accuracy: 0.8140\n",
      "Epoch 682/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8589 - val_loss: 0.4970 - val_accuracy: 0.8140\n",
      "Epoch 683/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8528 - val_loss: 0.4958 - val_accuracy: 0.8171\n",
      "Epoch 684/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8467 - val_loss: 0.4946 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8505 - val_loss: 0.4915 - val_accuracy: 0.8171\n",
      "Epoch 686/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8474 - val_loss: 0.4879 - val_accuracy: 0.8140\n",
      "Epoch 687/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8474 - val_loss: 0.4903 - val_accuracy: 0.8171\n",
      "Epoch 688/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8513 - val_loss: 0.4914 - val_accuracy: 0.8201\n",
      "Epoch 689/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8375 - val_loss: 0.4882 - val_accuracy: 0.8171\n",
      "Epoch 690/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8452 - val_loss: 0.4877 - val_accuracy: 0.8201\n",
      "Epoch 691/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8421 - val_loss: 0.4889 - val_accuracy: 0.8171\n",
      "Epoch 692/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8452 - val_loss: 0.4889 - val_accuracy: 0.8201\n",
      "Epoch 693/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8474 - val_loss: 0.4880 - val_accuracy: 0.8201\n",
      "Epoch 694/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8391 - val_loss: 0.4865 - val_accuracy: 0.8201\n",
      "Epoch 695/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8459 - val_loss: 0.4871 - val_accuracy: 0.8140\n",
      "Epoch 696/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8482 - val_loss: 0.4908 - val_accuracy: 0.8171\n",
      "Epoch 697/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8452 - val_loss: 0.4978 - val_accuracy: 0.8171\n",
      "Epoch 698/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8421 - val_loss: 0.5001 - val_accuracy: 0.8201\n",
      "Epoch 699/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8474 - val_loss: 0.4959 - val_accuracy: 0.8201\n",
      "Epoch 700/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8467 - val_loss: 0.4947 - val_accuracy: 0.8201\n",
      "Epoch 701/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8474 - val_loss: 0.4961 - val_accuracy: 0.8201\n",
      "Epoch 702/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8299 - val_loss: 0.4956 - val_accuracy: 0.8232\n",
      "Epoch 703/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8436 - val_loss: 0.4952 - val_accuracy: 0.8171\n",
      "Epoch 704/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8474 - val_loss: 0.4985 - val_accuracy: 0.8171\n",
      "Epoch 705/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8398 - val_loss: 0.4970 - val_accuracy: 0.8171\n",
      "Epoch 706/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8413 - val_loss: 0.4999 - val_accuracy: 0.8171\n",
      "Epoch 707/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8406 - val_loss: 0.4985 - val_accuracy: 0.8140\n",
      "Epoch 708/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8406 - val_loss: 0.4985 - val_accuracy: 0.8171\n",
      "Epoch 709/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8497 - val_loss: 0.4980 - val_accuracy: 0.8140\n",
      "Epoch 710/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8482 - val_loss: 0.4952 - val_accuracy: 0.8140\n",
      "Epoch 711/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8421 - val_loss: 0.4963 - val_accuracy: 0.8171\n",
      "Epoch 712/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8513 - val_loss: 0.4938 - val_accuracy: 0.8201\n",
      "Epoch 713/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8452 - val_loss: 0.4890 - val_accuracy: 0.8140\n",
      "Epoch 714/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8459 - val_loss: 0.4870 - val_accuracy: 0.8140\n",
      "Epoch 715/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8444 - val_loss: 0.4942 - val_accuracy: 0.8110\n",
      "Epoch 716/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8520 - val_loss: 0.4971 - val_accuracy: 0.8110\n",
      "Epoch 717/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8490 - val_loss: 0.4970 - val_accuracy: 0.8110\n",
      "Epoch 718/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8490 - val_loss: 0.4936 - val_accuracy: 0.8140\n",
      "Epoch 719/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8459 - val_loss: 0.4943 - val_accuracy: 0.8110\n",
      "Epoch 720/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8444 - val_loss: 0.4949 - val_accuracy: 0.8140\n",
      "Epoch 721/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8467 - val_loss: 0.4933 - val_accuracy: 0.8079\n",
      "Epoch 722/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8528 - val_loss: 0.4947 - val_accuracy: 0.8140\n",
      "Epoch 723/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8444 - val_loss: 0.4967 - val_accuracy: 0.8140\n",
      "Epoch 724/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8513 - val_loss: 0.4956 - val_accuracy: 0.8079\n",
      "Epoch 725/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8421 - val_loss: 0.4933 - val_accuracy: 0.8079\n",
      "Epoch 726/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8368 - val_loss: 0.4993 - val_accuracy: 0.8049\n",
      "Epoch 727/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8482 - val_loss: 0.5033 - val_accuracy: 0.8018\n",
      "Epoch 728/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8520 - val_loss: 0.5006 - val_accuracy: 0.8049\n",
      "Epoch 729/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8429 - val_loss: 0.5022 - val_accuracy: 0.8110\n",
      "Epoch 730/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8406 - val_loss: 0.4997 - val_accuracy: 0.8110\n",
      "Epoch 731/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8368 - val_loss: 0.4976 - val_accuracy: 0.8110\n",
      "Epoch 732/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8574 - val_loss: 0.4993 - val_accuracy: 0.8110\n",
      "Epoch 733/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8467 - val_loss: 0.4975 - val_accuracy: 0.8079\n",
      "Epoch 734/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8375 - val_loss: 0.4985 - val_accuracy: 0.8079\n",
      "Epoch 735/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8520 - val_loss: 0.4986 - val_accuracy: 0.8110\n",
      "Epoch 736/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8474 - val_loss: 0.4985 - val_accuracy: 0.8110\n",
      "Epoch 737/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8467 - val_loss: 0.4963 - val_accuracy: 0.8171\n",
      "Epoch 738/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8452 - val_loss: 0.4971 - val_accuracy: 0.8140\n",
      "Epoch 739/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8368 - val_loss: 0.4948 - val_accuracy: 0.8110\n",
      "Epoch 740/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8505 - val_loss: 0.4993 - val_accuracy: 0.8110\n",
      "Epoch 741/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8520 - val_loss: 0.5003 - val_accuracy: 0.8110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8459 - val_loss: 0.4982 - val_accuracy: 0.8110\n",
      "Epoch 743/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8474 - val_loss: 0.5027 - val_accuracy: 0.8140\n",
      "Epoch 744/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8513 - val_loss: 0.4990 - val_accuracy: 0.8140\n",
      "Epoch 745/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8474 - val_loss: 0.4996 - val_accuracy: 0.8110\n",
      "Epoch 746/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8467 - val_loss: 0.5026 - val_accuracy: 0.8079\n",
      "Epoch 747/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8505 - val_loss: 0.5030 - val_accuracy: 0.8079\n",
      "Epoch 748/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8444 - val_loss: 0.5004 - val_accuracy: 0.8079\n",
      "Epoch 749/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8551 - val_loss: 0.5037 - val_accuracy: 0.8110\n",
      "Epoch 750/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8528 - val_loss: 0.4965 - val_accuracy: 0.8110\n",
      "Epoch 751/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8490 - val_loss: 0.5008 - val_accuracy: 0.8140\n",
      "Epoch 752/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8459 - val_loss: 0.5019 - val_accuracy: 0.8110\n",
      "Epoch 753/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8436 - val_loss: 0.4968 - val_accuracy: 0.8110\n",
      "Epoch 754/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8513 - val_loss: 0.4978 - val_accuracy: 0.8140\n",
      "Epoch 755/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8543 - val_loss: 0.4987 - val_accuracy: 0.8140\n",
      "Epoch 756/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8558 - val_loss: 0.5021 - val_accuracy: 0.8140\n",
      "Epoch 757/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8467 - val_loss: 0.5005 - val_accuracy: 0.8140\n",
      "Epoch 758/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8497 - val_loss: 0.4982 - val_accuracy: 0.8140\n",
      "Epoch 759/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8528 - val_loss: 0.5010 - val_accuracy: 0.8140\n",
      "Epoch 760/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8459 - val_loss: 0.5007 - val_accuracy: 0.8110\n",
      "Epoch 761/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8352 - val_loss: 0.4991 - val_accuracy: 0.8140\n",
      "Epoch 762/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8444 - val_loss: 0.4967 - val_accuracy: 0.8140\n",
      "Epoch 763/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8337 - val_loss: 0.4969 - val_accuracy: 0.8140\n",
      "Epoch 764/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8444 - val_loss: 0.4988 - val_accuracy: 0.8110\n",
      "Epoch 765/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8528 - val_loss: 0.4955 - val_accuracy: 0.8110\n",
      "Epoch 766/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8520 - val_loss: 0.4969 - val_accuracy: 0.8140\n",
      "Epoch 767/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8375 - val_loss: 0.4971 - val_accuracy: 0.8171\n",
      "Epoch 768/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8551 - val_loss: 0.5006 - val_accuracy: 0.8140\n",
      "Epoch 769/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8490 - val_loss: 0.5007 - val_accuracy: 0.8140\n",
      "Epoch 770/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8330 - val_loss: 0.4983 - val_accuracy: 0.8140\n",
      "Epoch 771/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8444 - val_loss: 0.4964 - val_accuracy: 0.8140\n",
      "Epoch 772/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8459 - val_loss: 0.4962 - val_accuracy: 0.8140\n",
      "Epoch 773/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8444 - val_loss: 0.4961 - val_accuracy: 0.8140\n",
      "Epoch 774/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8452 - val_loss: 0.4971 - val_accuracy: 0.8110\n",
      "Epoch 775/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8474 - val_loss: 0.4994 - val_accuracy: 0.8171\n",
      "Epoch 776/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8391 - val_loss: 0.5043 - val_accuracy: 0.8140\n",
      "Epoch 777/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8459 - val_loss: 0.5080 - val_accuracy: 0.8110\n",
      "Epoch 778/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8528 - val_loss: 0.5055 - val_accuracy: 0.8140\n",
      "Epoch 779/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8337 - val_loss: 0.5042 - val_accuracy: 0.8171\n",
      "Epoch 780/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8459 - val_loss: 0.5130 - val_accuracy: 0.8171\n",
      "Epoch 781/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8360 - val_loss: 0.5071 - val_accuracy: 0.8110\n",
      "Epoch 782/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8352 - val_loss: 0.5041 - val_accuracy: 0.8171\n",
      "Epoch 783/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8513 - val_loss: 0.5063 - val_accuracy: 0.8201\n",
      "Epoch 784/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8444 - val_loss: 0.5050 - val_accuracy: 0.8140\n",
      "Epoch 785/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8452 - val_loss: 0.5073 - val_accuracy: 0.8171\n",
      "Epoch 786/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8474 - val_loss: 0.5027 - val_accuracy: 0.8171\n",
      "Epoch 787/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8490 - val_loss: 0.5037 - val_accuracy: 0.8171\n",
      "Epoch 788/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8268 - val_loss: 0.5018 - val_accuracy: 0.8140\n",
      "Epoch 789/1000\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8360 - val_loss: 0.4975 - val_accuracy: 0.8171\n",
      "Epoch 790/1000\n",
      " 1/41 [..............................] - ETA: 0s - loss: 0.2669 - accuracy: 0.9375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-207-a106dd1e6c2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 訓練模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "# 四捨五入得到 0,1\n",
    "# 將預測值從(N,1)壓扁成 (N,) \n",
    "P = np.round(pred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估模型 - evaluate() returns loss and accuracy\n",
    "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
    "print(\"Test score:\", model.evaluate(X_test, y_test))\n",
    "print(\"f1_score:\",f1_score(y_test, P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8d6f8052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15748b54100>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 劃出 model.fit() training 和 validating 的 loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "32a95ad9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15749e1ddc0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 劃出準確性 accuracy \n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "22810c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,  32],\n",
       "       [ 26, 154]], dtype=int64)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "pred_test = np.round(pred_test).flatten()\n",
    "cm = confusion_matrix(y_test, pred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6ad62622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DNN_F3_model_01\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('DNN_F3_model_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b1fdac4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 708us/step - loss: 0.3851 - accuracy: 0.8413\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.4104 - accuracy: 0.8201\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.3851 - accuracy: 0.8413\n",
      "Train score: [0.385126531124115, 0.8413425087928772]\n",
      "11/11 [==============================] - 0s 879us/step - loss: 0.4104 - accuracy: 0.8201\n",
      "Test score: [0.4103618860244751, 0.8201219439506531]\n",
      "f1_score: 0.8383561643835616\n",
      "41/41 [==============================] - 0s 756us/step - loss: 0.3832 - accuracy: 0.8406\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.4104 - accuracy: 0.8049\n",
      "41/41 [==============================] - 0s 732us/step - loss: 0.3832 - accuracy: 0.8406\n",
      "Train score: [0.38320842385292053, 0.8405796885490417]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4104 - accuracy: 0.8049\n",
      "Test score: [0.4103763997554779, 0.8048780560493469]\n",
      "f1_score: 0.8315789473684212\n",
      "41/41 [==============================] - 0s 683us/step - loss: 0.3824 - accuracy: 0.8368\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.4072 - accuracy: 0.8110\n",
      "41/41 [==============================] - 0s 659us/step - loss: 0.3824 - accuracy: 0.8368\n",
      "Train score: [0.3823728561401367, 0.8367658257484436]\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.4072 - accuracy: 0.8110\n",
      "Test score: [0.40723708271980286, 0.8109756112098694]\n",
      "f1_score: 0.835978835978836\n",
      "41/41 [==============================] - 0s 659us/step - loss: 0.3858 - accuracy: 0.8337\n",
      "11/11 [==============================] - 0s 976us/step - loss: 0.4029 - accuracy: 0.8201\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.3858 - accuracy: 0.8337\n",
      "Train score: [0.3857947587966919, 0.8337147235870361]\n",
      "11/11 [==============================] - 0s 976us/step - loss: 0.4029 - accuracy: 0.8201\n",
      "Test score: [0.4028802812099457, 0.8201219439506531]\n",
      "f1_score: 0.8451443569553805\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3883 - accuracy: 0.8406\n",
      "11/11 [==============================] - 0s 879us/step - loss: 0.4056 - accuracy: 0.8201\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.3883 - accuracy: 0.8406\n",
      "Train score: [0.3882574141025543, 0.8405796885490417]\n",
      "11/11 [==============================] - 0s 743us/step - loss: 0.4056 - accuracy: 0.8201\n",
      "Test score: [0.40557220578193665, 0.8201219439506531]\n",
      "f1_score: 0.8459530026109661\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3804 - accuracy: 0.8391\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4365 - accuracy: 0.8140\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.3804 - accuracy: 0.8391\n",
      "Train score: [0.3804158866405487, 0.8390541672706604]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4365 - accuracy: 0.8140\n",
      "Test score: [0.43650612235069275, 0.8140243887901306]\n",
      "f1_score: 0.8364611260053619\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.3746 - accuracy: 0.8360\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.4267 - accuracy: 0.8110\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3746 - accuracy: 0.8360\n",
      "Train score: [0.3746258616447449, 0.8360030651092529]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4267 - accuracy: 0.8110\n",
      "Test score: [0.42671576142311096, 0.8109756112098694]\n",
      "f1_score: 0.8333333333333333\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.3758 - accuracy: 0.8360\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4288 - accuracy: 0.8171\n",
      "41/41 [==============================] - 0s 561us/step - loss: 0.3758 - accuracy: 0.8360\n",
      "Train score: [0.3757980763912201, 0.8360030651092529]\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.4288 - accuracy: 0.8171\n",
      "Test score: [0.4287542402744293, 0.8170731663703918]\n",
      "f1_score: 0.8378378378378378\n",
      "41/41 [==============================] - 0s 624us/step - loss: 0.3778 - accuracy: 0.8444\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4370 - accuracy: 0.8262\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.3778 - accuracy: 0.8444\n",
      "Train score: [0.3778400123119354, 0.8443936109542847]\n",
      "11/11 [==============================] - 0s 976us/step - loss: 0.4370 - accuracy: 0.8262\n",
      "Test score: [0.43696585297584534, 0.8262194991111755]\n",
      "f1_score: 0.8463611859838275\n",
      "41/41 [==============================] - 0s 633us/step - loss: 0.3757 - accuracy: 0.8444\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4376 - accuracy: 0.8140\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.3757 - accuracy: 0.8444\n",
      "Train score: [0.37568026781082153, 0.8443936109542847]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4376 - accuracy: 0.8140\n",
      "Test score: [0.43762272596359253, 0.8140243887901306]\n",
      "f1_score: 0.828169014084507\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3895 - accuracy: 0.8230\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3689 - accuracy: 0.8598\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.3895 - accuracy: 0.8230\n",
      "Train score: [0.38949868083000183, 0.8230358362197876]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3689 - accuracy: 0.8598\n",
      "Test score: [0.36886799335479736, 0.8597561120986938]\n",
      "f1_score: 0.8749999999999999\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3949 - accuracy: 0.8253\n",
      "11/11 [==============================] - 0s 879us/step - loss: 0.3792 - accuracy: 0.8476\n",
      "41/41 [==============================] - 0s 560us/step - loss: 0.3949 - accuracy: 0.8253\n",
      "Train score: [0.39487889409065247, 0.8253241777420044]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3792 - accuracy: 0.8476\n",
      "Test score: [0.37919551134109497, 0.8475610017776489]\n",
      "f1_score: 0.8595505617977528\n",
      "41/41 [==============================] - 0s 659us/step - loss: 0.3861 - accuracy: 0.8345\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3805 - accuracy: 0.8354\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.3861 - accuracy: 0.8345\n",
      "Train score: [0.38610830903053284, 0.8344774842262268]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3805 - accuracy: 0.8354\n",
      "Test score: [0.38050973415374756, 0.8353658318519592]\n",
      "f1_score: 0.8474576271186441\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.3894 - accuracy: 0.8352\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3771 - accuracy: 0.8537\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.3894 - accuracy: 0.8352\n",
      "Train score: [0.3893875479698181, 0.8352402448654175]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3771 - accuracy: 0.8537\n",
      "Test score: [0.3770710527896881, 0.8536585569381714]\n",
      "f1_score: 0.8651685393258427\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.3875 - accuracy: 0.8360\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3748 - accuracy: 0.8476\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3875 - accuracy: 0.8360\n",
      "Train score: [0.3874659240245819, 0.8360030651092529]\n",
      "11/11 [==============================] - 0s 840us/step - loss: 0.3748 - accuracy: 0.8476\n",
      "Test score: [0.3747704029083252, 0.8475610017776489]\n",
      "f1_score: 0.8603351955307262\n",
      "41/41 [==============================] - 0s 659us/step - loss: 0.3894 - accuracy: 0.8314\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3686 - accuracy: 0.8506\n",
      "41/41 [==============================] - 0s 666us/step - loss: 0.3894 - accuracy: 0.8314\n",
      "Train score: [0.38940438628196716, 0.8314263820648193]\n",
      "11/11 [==============================] - 0s 778us/step - loss: 0.3686 - accuracy: 0.8506\n",
      "Test score: [0.3685935437679291, 0.8506097793579102]\n",
      "f1_score: 0.8672086720867208\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3878 - accuracy: 0.8299\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3731 - accuracy: 0.8476\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3878 - accuracy: 0.8299\n",
      "Train score: [0.3878364861011505, 0.829900860786438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 781us/step - loss: 0.3731 - accuracy: 0.8476\n",
      "Test score: [0.3731452524662018, 0.8475610017776489]\n",
      "f1_score: 0.8641304347826086\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3839 - accuracy: 0.8421\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3726 - accuracy: 0.8506\n",
      "41/41 [==============================] - 0s 609us/step - loss: 0.3839 - accuracy: 0.8421\n",
      "Train score: [0.38387852907180786, 0.8421052694320679]\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3726 - accuracy: 0.8506\n",
      "Test score: [0.3725730776786804, 0.8506097793579102]\n",
      "f1_score: 0.8650137741046833\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3881 - accuracy: 0.8360\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8628\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3881 - accuracy: 0.8360\n",
      "Train score: [0.38809698820114136, 0.8360030651092529]\n",
      "11/11 [==============================] - 0s 879us/step - loss: 0.3644 - accuracy: 0.8628\n",
      "Test score: [0.3643856942653656, 0.8628048896789551]\n",
      "f1_score: 0.8753462603878116\n",
      "41/41 [==============================] - 0s 659us/step - loss: 0.3929 - accuracy: 0.8330\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3680 - accuracy: 0.8598\n",
      "41/41 [==============================] - 0s 560us/step - loss: 0.3929 - accuracy: 0.8330\n",
      "Train score: [0.39293918013572693, 0.8329519629478455]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3680 - accuracy: 0.8598\n",
      "Test score: [0.36797428131103516, 0.8597561120986938]\n",
      "f1_score: 0.8729281767955801\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.3944 - accuracy: 0.8276\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3755 - accuracy: 0.8476\n",
      "41/41 [==============================] - 0s 579us/step - loss: 0.3944 - accuracy: 0.8276\n",
      "Train score: [0.3943673372268677, 0.8276125192642212]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3755 - accuracy: 0.8476\n",
      "Test score: [0.37554794549942017, 0.8475610017776489]\n",
      "f1_score: 0.8717948717948718\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3890 - accuracy: 0.8307\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3708 - accuracy: 0.8506\n",
      "41/41 [==============================] - 0s 585us/step - loss: 0.3890 - accuracy: 0.8307\n",
      "Train score: [0.38897863030433655, 0.8306636214256287]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3708 - accuracy: 0.8506\n",
      "Test score: [0.37083566188812256, 0.8506097793579102]\n",
      "f1_score: 0.8759493670886076\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3907 - accuracy: 0.8307\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.3770 - accuracy: 0.8476\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.3907 - accuracy: 0.8307\n",
      "Train score: [0.3906683027744293, 0.8306636214256287]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3770 - accuracy: 0.8476\n",
      "Test score: [0.3770490288734436, 0.8475610017776489]\n",
      "f1_score: 0.8717948717948718\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3878 - accuracy: 0.8345\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3703 - accuracy: 0.8384\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.3878 - accuracy: 0.8345\n",
      "Train score: [0.38782936334609985, 0.8344774842262268]\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.3703 - accuracy: 0.8384\n",
      "Test score: [0.3702600598335266, 0.8384146094322205]\n",
      "f1_score: 0.8658227848101266\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3884 - accuracy: 0.8345\n",
      "11/11 [==============================] - 0s 679us/step - loss: 0.3729 - accuracy: 0.8384\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.3884 - accuracy: 0.8345\n",
      "Train score: [0.38841134309768677, 0.8344774842262268]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3729 - accuracy: 0.8384\n",
      "Test score: [0.3728618323802948, 0.8384146094322205]\n",
      "f1_score: 0.8658227848101266\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "random = [12,100,6,20,72]\n",
    "for k in random:\n",
    "    Xt = addenv_factor2[['operating_gross_rate', 'net_profit_rate', 'revenue_growth_rate',\n",
    "           'current_rate', 'quick_rate', 'cash_reinvest_rate', 'roe_rate',\n",
    "           'roa_rate', 'foreign_rate_bys', 'avg_import_rate', 'avg_export_rate',\n",
    "           'export_kgm_weight_37050000306', 'new_cases_smoothed_USA',\n",
    "           'new_cases_smoothed_TWN']]\n",
    "\n",
    "    y1 = Roe_rul['roe_rate1']\n",
    "\n",
    "    Xt_scaled = pd.DataFrame()\n",
    "    a, b = Xt.shape\n",
    "\n",
    "    for i in range(b):\n",
    "        xt_new = mean_norm(Xt[Xt.columns[i]])\n",
    "        Xt_scaled.insert(i,Xt.columns[i],xt_new)\n",
    "\n",
    "\n",
    "    #分割資料為 測試集 與 訓練集\n",
    "    Xt_train, Xt_test, y1_train, y1_test = train_test_split(Xt_scaled, y1, test_size=0.2, random_state=k)\n",
    "    N, D = Xt_train.shape\n",
    "\n",
    "    for x in range(1,6):\n",
    "        \n",
    "        # 建立 DNN 模型\n",
    "        modelt = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Input(shape=(D,)),\n",
    "          tf.keras.layers.Dense(128, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.6),\n",
    "          tf.keras.layers.Dense(32, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.4),\n",
    "          tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "          ])\n",
    "\n",
    "        #編譯模型\n",
    "        modelt.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "#         modelt.summary()\n",
    "\n",
    "        # 訓練模型\n",
    "        rt = modelt.fit(Xt_train, y1_train, validation_data=(Xt_test, y1_test), epochs=50, verbose = 0 )\n",
    "        pred = modelt.predict(Xt_test)\n",
    "        P = np.round(pred).flatten()\n",
    "        tmp = [str(k)]\n",
    "        tmp.extend(modelt.evaluate(Xt_train, y1_train))\n",
    "        tmp.extend(modelt.evaluate(Xt_test, y1_test))\n",
    "        tmp.append(f1_score(y1_test, P))\n",
    "\n",
    "        # 評估模型 - evaluate() returns loss and accuracy\n",
    "        print(\"Train score:\", modelt.evaluate(Xt_train, y1_train))\n",
    "        \n",
    "        print(\"Test score:\", modelt.evaluate(Xt_test, y1_test))\n",
    "        print(\"f1_score:\",f1_score(y1_test, P))\n",
    "        result_list.append(tmp)\n",
    "\n",
    "#         plt.plot(rt.history['loss'], label='loss')\n",
    "#         plt.plot(rt.history['val_loss'], label='val_loss')\n",
    "#         plt.legend()\n",
    "#         plt.savefig(f'./results/pre1_loss_{import_list[item]}_{i}.png')#儲存圖片\n",
    "#         plt.show() \n",
    "\n",
    "#         plt.plot(rt.history['accuracy'], label='acc')\n",
    "#         plt.plot(rt.history['val_accuracy'], label='val_acc')\n",
    "#         plt.legend()\n",
    "#         plt.savefig(f'./results/pre1_accuracy_{import_list[item]}_{i}.png')#儲存圖片\n",
    "#         plt.show() \n",
    "\n",
    "result_pd = pd.DataFrame(result_list,columns=[\"random_state\",\"train_loss\",\"train_accuracy\",\"test_loss\",\"test_accuracy\",\"F1_score\"])\n",
    "result_pd.to_csv(\"./results/F1_all_random_test_02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "be6a6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 609us/step - loss: 0.4250 - accuracy: 0.8314\n",
      "11/11 [==============================] - 0s 586us/step - loss: 0.3820 - accuracy: 0.8567\n",
      "41/41 [==============================] - 0s 464us/step - loss: 0.4250 - accuracy: 0.8314\n",
      "Train score: [0.4249718189239502, 0.8314263820648193]\n",
      "11/11 [==============================] - 0s 586us/step - loss: 0.3820 - accuracy: 0.8567\n",
      "Test score: [0.3820338547229767, 0.8567073345184326]\n",
      "f1_score: 0.8719346049046323\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.4219 - accuracy: 0.8322\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3752 - accuracy: 0.8567\n",
      "41/41 [==============================] - 0s 659us/step - loss: 0.4219 - accuracy: 0.8322\n",
      "Train score: [0.42191624641418457, 0.83218914270401]\n",
      "11/11 [==============================] - 0s 976us/step - loss: 0.3752 - accuracy: 0.8567\n",
      "Test score: [0.375216007232666, 0.8567073345184326]\n",
      "f1_score: 0.8698060941828254\n",
      "41/41 [==============================] - 0s 561us/step - loss: 0.4191 - accuracy: 0.8307\n",
      "11/11 [==============================] - 0s 586us/step - loss: 0.3765 - accuracy: 0.8659\n",
      "41/41 [==============================] - 0s 512us/step - loss: 0.4191 - accuracy: 0.8307\n",
      "Train score: [0.41908061504364014, 0.8306636214256287]\n",
      "11/11 [==============================] - 0s 779us/step - loss: 0.3765 - accuracy: 0.8659\n",
      "Test score: [0.3765416741371155, 0.8658536672592163]\n",
      "f1_score: 0.8835978835978837\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.4225 - accuracy: 0.8352\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.3769 - accuracy: 0.8628\n",
      "41/41 [==============================] - 0s 537us/step - loss: 0.4225 - accuracy: 0.8352\n",
      "Train score: [0.42253950238227844, 0.8352402448654175]\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.3769 - accuracy: 0.8628\n",
      "Test score: [0.37694424390792847, 0.8628048896789551]\n",
      "f1_score: 0.8760330578512396\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.4162 - accuracy: 0.8314\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.3680 - accuracy: 0.8780\n",
      "41/41 [==============================] - 0s 708us/step - loss: 0.4162 - accuracy: 0.8314\n",
      "Train score: [0.4162213206291199, 0.8314263820648193]\n",
      "11/11 [==============================] - 0s 976us/step - loss: 0.3680 - accuracy: 0.8780\n",
      "Test score: [0.36803197860717773, 0.8780487775802612]\n",
      "f1_score: 0.891304347826087\n",
      "41/41 [==============================] - 0s 732us/step - loss: 0.4138 - accuracy: 0.8429\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.4123 - accuracy: 0.8262\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.4138 - accuracy: 0.8429\n",
      "Train score: [0.41376417875289917, 0.8428680300712585]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.4123 - accuracy: 0.8262\n",
      "Test score: [0.4123465418815613, 0.8262194991111755]\n",
      "f1_score: 0.8503937007874015\n",
      "41/41 [==============================] - 0s 804us/step - loss: 0.4132 - accuracy: 0.8330\n",
      "11/11 [==============================] - 0s 980us/step - loss: 0.4130 - accuracy: 0.8293\n",
      "41/41 [==============================] - 0s 732us/step - loss: 0.4132 - accuracy: 0.8330\n",
      "Train score: [0.4131612777709961, 0.8329519629478455]\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8293\n",
      "Test score: [0.41304996609687805, 0.8292682766914368]\n",
      "f1_score: 0.8526315789473684\n",
      "41/41 [==============================] - 0s 952us/step - loss: 0.4124 - accuracy: 0.8375\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8323\n",
      "41/41 [==============================] - 0s 929us/step - loss: 0.4124 - accuracy: 0.8375\n",
      "Train score: [0.41240617632865906, 0.8375285863876343]\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8323\n",
      "Test score: [0.41409963369369507, 0.832317054271698]\n",
      "f1_score: 0.8541114058355438\n",
      "41/41 [==============================] - 0s 830us/step - loss: 0.4099 - accuracy: 0.8459\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8293\n",
      "41/41 [==============================] - 0s 903us/step - loss: 0.4099 - accuracy: 0.8459\n",
      "Train score: [0.40990275144577026, 0.845919132232666]\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8293\n",
      "Test score: [0.40898099541664124, 0.8292682766914368]\n",
      "f1_score: 0.8510638297872339\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8398\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.4205 - accuracy: 0.8262\n",
      "41/41 [==============================] - 0s 854us/step - loss: 0.4128 - accuracy: 0.8398\n",
      "Train score: [0.4128499925136566, 0.8398169279098511]\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8262\n",
      "Test score: [0.4204618036746979, 0.8262194991111755]\n",
      "f1_score: 0.8488063660477454\n",
      "41/41 [==============================] - 0s 805us/step - loss: 0.4078 - accuracy: 0.8413\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8415\n",
      "41/41 [==============================] - 0s 896us/step - loss: 0.4078 - accuracy: 0.8413\n",
      "Train score: [0.40780505537986755, 0.8413425087928772]\n",
      "11/11 [==============================] - 0s 978us/step - loss: 0.4274 - accuracy: 0.8415\n",
      "Test score: [0.427365779876709, 0.8414633870124817]\n",
      "f1_score: 0.8571428571428571\n",
      "41/41 [==============================] - 0s 878us/step - loss: 0.4097 - accuracy: 0.8398\n",
      "11/11 [==============================] - 0s 976us/step - loss: 0.4218 - accuracy: 0.8354\n",
      "41/41 [==============================] - 0s 878us/step - loss: 0.4097 - accuracy: 0.8398\n",
      "Train score: [0.4097210764884949, 0.8398169279098511]\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8354\n",
      "Test score: [0.42182308435440063, 0.8353658318519592]\n",
      "f1_score: 0.8532608695652173\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4061 - accuracy: 0.8375\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8354\n",
      "41/41 [==============================] - 0s 805us/step - loss: 0.4061 - accuracy: 0.8375\n",
      "Train score: [0.406113862991333, 0.8375285863876343]\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8354\n",
      "Test score: [0.42501771450042725, 0.8353658318519592]\n",
      "f1_score: 0.8548387096774194\n",
      "41/41 [==============================] - 0s 903us/step - loss: 0.4076 - accuracy: 0.8383\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8415\n",
      "41/41 [==============================] - 0s 878us/step - loss: 0.4076 - accuracy: 0.8383\n",
      "Train score: [0.4075603783130646, 0.8382914066314697]\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8415\n",
      "Test score: [0.42200642824172974, 0.8414633870124817]\n",
      "f1_score: 0.8579234972677595\n",
      "41/41 [==============================] - 0s 927us/step - loss: 0.4078 - accuracy: 0.8413\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8354\n",
      "41/41 [==============================] - 0s 756us/step - loss: 0.4078 - accuracy: 0.8413\n",
      "Train score: [0.40781664848327637, 0.8413425087928772]\n",
      "11/11 [==============================] - 0s 879us/step - loss: 0.4294 - accuracy: 0.8354\n",
      "Test score: [0.42944303154945374, 0.8353658318519592]\n",
      "f1_score: 0.855614973262032\n",
      "41/41 [==============================] - 0s 683us/step - loss: 0.4204 - accuracy: 0.8368\n",
      "11/11 [==============================] - 0s 879us/step - loss: 0.3736 - accuracy: 0.8628\n",
      "41/41 [==============================] - 0s 585us/step - loss: 0.4204 - accuracy: 0.8368\n",
      "Train score: [0.42040443420410156, 0.8367658257484436]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3736 - accuracy: 0.8628\n",
      "Test score: [0.37355512380599976, 0.8628048896789551]\n",
      "f1_score: 0.8760330578512397\n",
      "41/41 [==============================] - 0s 781us/step - loss: 0.4265 - accuracy: 0.8383\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3713 - accuracy: 0.8598\n",
      "41/41 [==============================] - 0s 650us/step - loss: 0.4265 - accuracy: 0.8383\n",
      "Train score: [0.42649826407432556, 0.8382914066314697]\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3713 - accuracy: 0.8598\n",
      "Test score: [0.37130963802337646, 0.8597561120986938]\n",
      "f1_score: 0.8736263736263736\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.4192 - accuracy: 0.8352\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.3654 - accuracy: 0.8598\n",
      "41/41 [==============================] - 0s 609us/step - loss: 0.4192 - accuracy: 0.8352\n",
      "Train score: [0.41922450065612793, 0.8352402448654175]\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3654 - accuracy: 0.8598\n",
      "Test score: [0.3654034733772278, 0.8597561120986938]\n",
      "f1_score: 0.8722222222222223\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.4220 - accuracy: 0.8368\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3706 - accuracy: 0.8537\n",
      "41/41 [==============================] - 0s 577us/step - loss: 0.4220 - accuracy: 0.8368\n",
      "Train score: [0.42197808623313904, 0.8367658257484436]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3706 - accuracy: 0.8537\n",
      "Test score: [0.3705986738204956, 0.8536585569381714]\n",
      "f1_score: 0.8666666666666667\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.4208 - accuracy: 0.8375\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.3712 - accuracy: 0.8628\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.4208 - accuracy: 0.8375\n",
      "Train score: [0.42080122232437134, 0.8375285863876343]\n",
      "11/11 [==============================] - 0s 682us/step - loss: 0.3712 - accuracy: 0.8628\n",
      "Test score: [0.3711607754230499, 0.8628048896789551]\n",
      "f1_score: 0.8753462603878116\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.4183 - accuracy: 0.8352\n",
      "11/11 [==============================] - 0s 683us/step - loss: 0.3879 - accuracy: 0.8445\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.4183 - accuracy: 0.8352\n",
      "Train score: [0.41833704710006714, 0.8352402448654175]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3879 - accuracy: 0.8445\n",
      "Test score: [0.3878845274448395, 0.8445122241973877]\n",
      "f1_score: 0.864\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.4149 - accuracy: 0.8337\n",
      "11/11 [==============================] - 0s 777us/step - loss: 0.3853 - accuracy: 0.8659\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.4149 - accuracy: 0.8337\n",
      "Train score: [0.41493546962738037, 0.8337147235870361]\n",
      "11/11 [==============================] - 0s 967us/step - loss: 0.3853 - accuracy: 0.8659\n",
      "Test score: [0.3853406012058258, 0.8658536672592163]\n",
      "f1_score: 0.8848167539267016\n",
      "41/41 [==============================] - 0s 634us/step - loss: 0.4173 - accuracy: 0.8314\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3873 - accuracy: 0.8567\n",
      "41/41 [==============================] - 0s 659us/step - loss: 0.4173 - accuracy: 0.8314\n",
      "Train score: [0.41732585430145264, 0.8314263820648193]\n",
      "11/11 [==============================] - 0s 781us/step - loss: 0.3873 - accuracy: 0.8567\n",
      "Test score: [0.3873245120048523, 0.8567073345184326]\n",
      "f1_score: 0.8759894459102903\n",
      "41/41 [==============================] - 0s 756us/step - loss: 0.4161 - accuracy: 0.8391\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8598\n",
      "41/41 [==============================] - 0s 708us/step - loss: 0.4161 - accuracy: 0.8391\n",
      "Train score: [0.41609710454940796, 0.8390541672706604]\n",
      "11/11 [==============================] - 0s 980us/step - loss: 0.3895 - accuracy: 0.8598\n",
      "Test score: [0.3894551992416382, 0.8597561120986938]\n",
      "f1_score: 0.8789473684210526\n",
      "41/41 [==============================] - 0s 610us/step - loss: 0.4176 - accuracy: 0.8307\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3883 - accuracy: 0.8598\n",
      "41/41 [==============================] - 0s 586us/step - loss: 0.4176 - accuracy: 0.8307\n",
      "Train score: [0.417629599571228, 0.8306636214256287]\n",
      "11/11 [==============================] - 0s 878us/step - loss: 0.3883 - accuracy: 0.8598\n",
      "Test score: [0.38827085494995117, 0.8597561120986938]\n",
      "f1_score: 0.8802083333333334\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "random = [6,12,100,20,72]\n",
    "for k in random:\n",
    "    Xt = addenv_factor2[['net_profit_rate','operating_gross_rate', 'roe_rate','roa_rate',\n",
    "                    'current_rate', 'quick_rate',  'debt_rate',  'receivables_turnover_rate', \n",
    "                    'cash_reinvest_rate','export_usd_value_381800','new_cases_smoothed_TWN',\n",
    "                     'import_usd_value_37079090','avg_import_rate']]\n",
    "\n",
    "    y1 = Roe_rul['roe_rate1']\n",
    "\n",
    "    Xt_scaled = pd.DataFrame()\n",
    "    a, b = Xt.shape\n",
    "\n",
    "    for i in range(b):\n",
    "        xt_new = mean_norm(Xt[Xt.columns[i]])\n",
    "        Xt_scaled.insert(i,Xt.columns[i],xt_new)\n",
    "\n",
    "\n",
    "    #分割資料為 測試集 與 訓練集\n",
    "    Xt_train, Xt_test, y1_train, y1_test = train_test_split(Xt_scaled, y1, test_size=0.2, random_state=k)\n",
    "    N, D = Xt_train.shape\n",
    "\n",
    "    for x in range(1,6):\n",
    "        \n",
    "        # 建立 DNN 模型\n",
    "        modelt = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Input(shape=(D,)),\n",
    "          tf.keras.layers.Dense(128, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.8),\n",
    "          tf.keras.layers.Dense(32, activation='relu'),\n",
    "          tf.keras.layers.Dropout(0.6),\n",
    "          tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "          ])\n",
    "\n",
    "        #編譯模型\n",
    "        modelt.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "#         modelt.summary()\n",
    "\n",
    "        # 訓練模型\n",
    "        rt = modelt.fit(Xt_train, y1_train, validation_data=(Xt_test, y1_test), epochs=50, verbose = 0 )\n",
    "        pred = modelt.predict(Xt_test)\n",
    "        P = np.round(pred).flatten()\n",
    "        tmp = [str(k)]\n",
    "        tmp.extend(modelt.evaluate(Xt_train, y1_train))\n",
    "        tmp.extend(modelt.evaluate(Xt_test, y1_test))\n",
    "        tmp.append(f1_score(y1_test, P))\n",
    "\n",
    "        # 評估模型 - evaluate() returns loss and accuracy\n",
    "        print(\"Train score:\", modelt.evaluate(Xt_train, y1_train))\n",
    "        print(\"Test score:\", modelt.evaluate(Xt_test, y1_test))\n",
    "        print(\"f1_score:\",f1_score(y1_test, P))\n",
    "        result_list.append(tmp)\n",
    "\n",
    "#         plt.plot(rt.history['loss'], label='loss')\n",
    "#         plt.plot(rt.history['val_loss'], label='val_loss')\n",
    "#         plt.legend()\n",
    "#         plt.savefig(f'./results/pre1_loss_{import_list[item]}_{i}.png')#儲存圖片\n",
    "#         plt.show() \n",
    "\n",
    "#         plt.plot(rt.history['accuracy'], label='acc')\n",
    "#         plt.plot(rt.history['val_accuracy'], label='val_acc')\n",
    "#         plt.legend()\n",
    "#         plt.savefig(f'./results/pre1_accuracy_{import_list[item]}_{i}.png')#儲存圖片\n",
    "#         plt.show() \n",
    "\n",
    "result_pd = pd.DataFrame(result_list,columns=[\"random_state\",\"train_loss\",\"train_accuracy\",\"test_loss\",\"test_accuracy\",\"F1_score\"])\n",
    "result_pd.to_csv(\"./results/F3_all_random_test_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d74e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
