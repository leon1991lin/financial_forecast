{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.153.129:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://devenv:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb3242402d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.153.129:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://devenv:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://devenv:7077 appName=PySparkShell>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Data and Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "raw_train = spark.read.csv(\"hdfs://devenv/user/spark/spark_mllib_101/train\",\n",
    "                      inferSchema=True,\n",
    "                      header=True)\n",
    "raw_test = spark.read.csv(\"hdfs://devenv/user/spark/spark_mllib_101/test\",\n",
    "                      inferSchema=True,\n",
    "                      header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------------+---------------+-------------------+------------+------------+------------------+------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+-----+\n",
      "|stock_code|stock_report_date|operating_gross_rate|net_profit_rate|revenue_growth_rate|current_rate|  quick_rate|cash_reinvest_rate|    roe_rate|    roa_rate|foreign_rate_bys|avg_import_rate|avg_export_rate|export_kgm_weight_37050000306|new_cases_smoothed_USA|new_cases_smoothed_TWN|new_cases_smoothed_OWID_EUR|label|\n",
      "+----------+-----------------+--------------------+---------------+-------------------+------------+------------+------------------+------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+-----+\n",
      "|      2302|            20211|        -0.100223498|   -0.007912025|         1.32096154|-0.481106719|-0.441839507|      -0.409650054|-0.347840037|-0.460037026|    -0.605859958|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|    0|\n",
      "|      2303|            20211|        -0.152181711|    0.296171533|       -0.027280983|-0.326541885| -0.28164175|       0.116017502| 0.266556595| 0.248214375|     1.280055378|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|    1|\n",
      "|      2329|            20211|        -0.650825464|    0.040721151|        -0.21208448|-0.539211174|-0.453028459|      -0.192132445| 0.070403581|-0.064938104|     0.595710608|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|    1|\n",
      "|      2330|            20211|          0.84937102|    0.591672767|         0.10365267|-0.456444348| -0.35820028|       0.239450113| 0.801519361| 0.915492554|     2.866941804|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|    1|\n",
      "|      2337|            20211|         0.148710631|    0.102985078|       -0.256227826|-0.455326507| -0.48490368|      -0.021225752| 0.010422907|-0.091278032|    -0.050449709|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|    1|\n",
      "+----------+-----------------+--------------------+---------------+-------------------+------------+------------+------------------+------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+-----------------+--------------------+---------------+-------------------+------------+------------+------------------+-----------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+-----+\n",
      "|stock_code|stock_report_date|operating_gross_rate|net_profit_rate|revenue_growth_rate|current_rate|  quick_rate|cash_reinvest_rate|   roe_rate|    roa_rate|foreign_rate_bys|avg_import_rate|avg_export_rate|export_kgm_weight_37050000306|new_cases_smoothed_USA|new_cases_smoothed_TWN|new_cases_smoothed_OWID_EUR|label|\n",
      "+----------+-----------------+--------------------+---------------+-------------------+------------+------------+------------------+-----------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+-----+\n",
      "|      2302|            20212|         0.175852981|    0.160705421|        0.711933009|-0.448060539|-0.408490147|      -0.319880882|-0.15655032|-0.179077792|    -0.595941918|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|    0|\n",
      "|      2303|            20212|          0.03083528|    0.335044418|        0.054022581|-0.288209247|-0.265063735|       0.677937992| 0.41569773| 0.371134039|     1.048469141|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|    1|\n",
      "|      2329|            20212|         -0.40654431|     0.11476474|        0.149791195|-0.536789184|-0.453415118|       0.734043725|0.474057304| 0.315527524|    -0.315261381|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|    1|\n",
      "|      2330|            20212|         0.759413515|    0.550948793|        0.180965874|-0.411404663|-0.318374378|       0.624421755|0.741538688| 0.824766135|     2.840658997|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|    1|\n",
      "|      2337|            20212|         0.334441857|    0.226334966|        0.267506783|-0.427566783|-0.463975748|       0.462146713|0.433529822| 0.341867453|    -0.052433317|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|    1|\n",
      "+----------+-----------------+--------------------+---------------+-------------------+------------+------------+------------------+-----------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_train.show(5)\n",
    "raw_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = raw_train.select('label','operating_gross_rate',\n",
    "       'net_profit_rate', 'revenue_growth_rate', 'current_rate', 'quick_rate',\n",
    "       'cash_reinvest_rate', 'roa_rate', 'foreign_rate_bys',\n",
    "       'avg_import_rate', 'avg_export_rate', 'export_kgm_weight_37050000306',\n",
    "       'new_cases_smoothed_USA', 'new_cases_smoothed_TWN',\n",
    "       'new_cases_smoothed_OWID_EUR',)\n",
    "data_test = raw_test.select('label','operating_gross_rate',\n",
    "       'net_profit_rate', 'revenue_growth_rate', 'current_rate', 'quick_rate',\n",
    "       'cash_reinvest_rate', 'roa_rate', 'foreign_rate_bys',\n",
    "       'avg_import_rate', 'avg_export_rate', 'export_kgm_weight_37050000306',\n",
    "       'new_cases_smoothed_USA', 'new_cases_smoothed_TWN',\n",
    "       'new_cases_smoothed_OWID_EUR',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------+-------------------+------------+------------+------------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+\n",
      "|label|operating_gross_rate|net_profit_rate|revenue_growth_rate|current_rate|  quick_rate|cash_reinvest_rate|    roa_rate|foreign_rate_bys|avg_import_rate|avg_export_rate|export_kgm_weight_37050000306|new_cases_smoothed_USA|new_cases_smoothed_TWN|new_cases_smoothed_OWID_EUR|\n",
      "+-----+--------------------+---------------+-------------------+------------+------------+------------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+\n",
      "|    0|        -0.100223498|   -0.007912025|         1.32096154|-0.481106719|-0.441839507|      -0.409650054|-0.460037026|    -0.605859958|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|\n",
      "|    1|        -0.152181711|    0.296171533|       -0.027280983|-0.326541885| -0.28164175|       0.116017502| 0.248214375|     1.280055378|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|\n",
      "|    1|        -0.650825464|    0.040721151|        -0.21208448|-0.539211174|-0.453028459|      -0.192132445|-0.064938104|     0.595710608|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|\n",
      "|    1|          0.84937102|    0.591672767|         0.10365267|-0.456444348| -0.35820028|       0.239450113| 0.915492554|     2.866941804|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|\n",
      "|    1|         0.148710631|    0.102985078|       -0.256227826|-0.455326507| -0.48490368|      -0.021225752|-0.091278032|    -0.050449709|   -1.511413276|   -1.511413276|                  2.823498971|           1.928740454|          -0.207683189|                1.923804593|\n",
      "+-----+--------------------+---------------+-------------------+------------+------------+------------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------+-------------------+------------+------------+------------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+\n",
      "|label|operating_gross_rate|net_profit_rate|revenue_growth_rate|current_rate|  quick_rate|cash_reinvest_rate|    roa_rate|foreign_rate_bys|avg_import_rate|avg_export_rate|export_kgm_weight_37050000306|new_cases_smoothed_USA|new_cases_smoothed_TWN|new_cases_smoothed_OWID_EUR|\n",
      "+-----+--------------------+---------------+-------------------+------------+------------+------------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+\n",
      "|    0|         0.175852981|    0.160705421|        0.711933009|-0.448060539|-0.408490147|      -0.319880882|-0.179077792|    -0.595941918|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|\n",
      "|    1|          0.03083528|    0.335044418|        0.054022581|-0.288209247|-0.265063735|       0.677937992| 0.371134039|     1.048469141|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|\n",
      "|    1|         -0.40654431|     0.11476474|        0.149791195|-0.536789184|-0.453415118|       0.734043725| 0.315527524|    -0.315261381|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|\n",
      "|    1|         0.759413515|    0.550948793|        0.180965874|-0.411404663|-0.318374378|       0.624421755| 0.824766135|     2.840658997|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|\n",
      "|    1|         0.334441857|    0.226334966|        0.267506783|-0.427566783|-0.463975748|       0.462146713| 0.341867453|    -0.052433317|   -1.888952763|   -1.888952763|                  0.411059973|           0.131543691|           3.308867062|                 0.80738538|\n",
      "+-----+--------------------+---------------+-------------------+------------+------------+------------------+------------+----------------+---------------+---------------+-----------------------------+----------------------+----------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('label', 'int'),\n",
       " ('operating_gross_rate', 'double'),\n",
       " ('net_profit_rate', 'double'),\n",
       " ('revenue_growth_rate', 'double'),\n",
       " ('current_rate', 'double'),\n",
       " ('quick_rate', 'double'),\n",
       " ('cash_reinvest_rate', 'double'),\n",
       " ('roa_rate', 'double'),\n",
       " ('foreign_rate_bys', 'double'),\n",
       " ('avg_import_rate', 'double'),\n",
       " ('avg_export_rate', 'double'),\n",
       " ('export_kgm_weight_37050000306', 'double'),\n",
       " ('new_cases_smoothed_USA', 'double'),\n",
       " ('new_cases_smoothed_TWN', 'double'),\n",
       " ('new_cases_smoothed_OWID_EUR', 'double')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.dtypes\n",
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCols = [x for (x, dataType) in data_train.dtypes if ((dataType == 'double')&(x != 'label'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['operating_gross_rate', 'net_profit_rate', 'revenue_growth_rate', 'current_rate', 'quick_rate', 'cash_reinvest_rate', 'roa_rate', 'foreign_rate_bys', 'avg_import_rate', 'avg_export_rate', 'export_kgm_weight_37050000306', 'new_cases_smoothed_USA', 'new_cases_smoothed_TWN', 'new_cases_smoothed_OWID_EUR']\n"
     ]
    }
   ],
   "source": [
    "print(numCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                                                          |label|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|[-0.100223498,-0.007912025,1.32096154,-0.481106719,-0.441839507,-0.409650054,-0.460037026,-0.605859958,-1.511413276,-1.511413276,2.823498971,1.928740454,-0.207683189,1.923804593]|0    |\n",
      "|[-0.152181711,0.296171533,-0.027280983,-0.326541885,-0.28164175,0.116017502,0.248214375,1.280055378,-1.511413276,-1.511413276,2.823498971,1.928740454,-0.207683189,1.923804593]   |1    |\n",
      "|[-0.650825464,0.040721151,-0.21208448,-0.539211174,-0.453028459,-0.192132445,-0.064938104,0.595710608,-1.511413276,-1.511413276,2.823498971,1.928740454,-0.207683189,1.923804593] |1    |\n",
      "|[0.84937102,0.591672767,0.10365267,-0.456444348,-0.35820028,0.239450113,0.915492554,2.866941804,-1.511413276,-1.511413276,2.823498971,1.928740454,-0.207683189,1.923804593]       |1    |\n",
      "|[0.148710631,0.102985078,-0.256227826,-0.455326507,-0.48490368,-0.021225752,-0.091278032,-0.050449709,-1.511413276,-1.511413276,2.823498971,1.928740454,-0.207683189,1.923804593] |1    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                                                       |label|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|[0.175852981,0.160705421,0.711933009,-0.448060539,-0.408490147,-0.319880882,-0.179077792,-0.595941918,-1.888952763,-1.888952763,0.411059973,0.131543691,3.308867062,0.80738538]|0    |\n",
      "|[0.03083528,0.335044418,0.054022581,-0.288209247,-0.265063735,0.677937992,0.371134039,1.048469141,-1.888952763,-1.888952763,0.411059973,0.131543691,3.308867062,0.80738538]    |1    |\n",
      "|[-0.40654431,0.11476474,0.149791195,-0.536789184,-0.453415118,0.734043725,0.315527524,-0.315261381,-1.888952763,-1.888952763,0.411059973,0.131543691,3.308867062,0.80738538]   |1    |\n",
      "|[0.759413515,0.550948793,0.180965874,-0.411404663,-0.318374378,0.624421755,0.824766135,2.840658997,-1.888952763,-1.888952763,0.411059973,0.131543691,3.308867062,0.80738538]   |1    |\n",
      "|[0.334441857,0.226334966,0.267506783,-0.427566783,-0.463975748,0.462146713,0.341867453,-0.052433317,-1.888952763,-1.888952763,0.411059973,0.131543691,3.308867062,0.80738538]  |1    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary class\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=numCols, outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "data_assembled_train = assembler.transform(data_train)\n",
    "data_assembled_test = assembler.transform(data_test)\n",
    "\n",
    "# Check the resulting column\n",
    "data_assembled_train.select('features', 'label').show(5, truncate=False)\n",
    "data_assembled_test.select('features', 'label').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into training and testing sets in a 80:20 ratio\n",
    "# data_train, data_test = data_assembled.randomSplit([0.8, 0.2], seed=17)\n",
    "# data_test \n",
    "# # Check that training set has around 80% of records\n",
    "# training_ratio = data_train.count() / data.count()\n",
    "# print(training_ratio)\n",
    "\n",
    "data_train = data_assembled_train\n",
    "data_test = data_assembled_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0    |0.0       |[0.5922330097087378,0.4077669902912621] |\n",
      "|1    |1.0       |[0.12115732368896925,0.8788426763110307]|\n",
      "|1    |1.0       |[0.12115732368896925,0.8788426763110307]|\n",
      "|1    |1.0       |[0.12115732368896925,0.8788426763110307]|\n",
      "|1    |1.0       |[0.12115732368896925,0.8788426763110307]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create a classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(data_train)\n",
    "\n",
    "#label is y(ROE)\n",
    "#features are all of X\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = tree_model.transform(data_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|    6|\n",
      "|    0|       0.0|   29|\n",
      "|    1|       1.0|  103|\n",
      "|    0|       1.0|   11|\n",
      "+-----+----------+-----+\n",
      "\n",
      "0.8859060402684564\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       1.0|  109|\n",
      "|    0|       1.0|   40|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the logistic regression class\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create a classifier object and train on training data\n",
    "logistic = LogisticRegression().fit(data_train)\n",
    "\n",
    "# Create predictions for the testing data and show confusion matrix\n",
    "prediction = logistic.transform(data_test)\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       1.0|  109|\n",
      "|    0|       1.0|   40|\n",
      "+-----+----------+-----+\n",
      "\n",
      "0.7315436241610739\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.82\n",
      "recall    = 0.85\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}'.format(precision, recall))\n",
    "\n",
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# Find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: \"areaUnderROC\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the logistic regression class\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "accuracy_all = {}\n",
    "F1_score_all = {}\n",
    "lr_params = [0,0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for r in lr_params:\n",
    "    # Create a classifier object and train on training data\n",
    "    logistic = LogisticRegression(regParam=r).fit(data_train)\n",
    "\n",
    "    # Create predictions for the testing data and show confusion matrix\n",
    "    prediction = logistic.transform(data_test)\n",
    "\n",
    "    # Calculate the elements of the confusion matrix\n",
    "    TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "    TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "    FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "    FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "    # Accuracy measures the proportion of correct predictions\n",
    "    accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "    accuracy_all[f'regParam:{r}'] = accuracy\n",
    "    try:\n",
    "        Recall = TP/(TP+FN) #(召回率)\n",
    "        Precision = TP/(TP+FP) #(準確率)\n",
    "        F1_score = 2 * Precision * Recall / (Precision + Recall)\n",
    "        F1_score_all[f'regParam:{r}_f1'] = F1_score\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regParam:0.1': 0.7449664429530202,\n",
       " 'regParam:0.01': 0.738255033557047,\n",
       " 'regParam:1': 0.738255033557047,\n",
       " 'regParam:10': 0.738255033557047,\n",
       " 'regParam:0': 0.7315436241610739,\n",
       " 'regParam:0.001': 0.7315436241610739}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_all_sorted = dict(sorted(accuracy_all.items(), key=lambda item: item[1], reverse=True))\n",
    "accuracy_all_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regParam:0.1_f1': 0.8515625,\n",
       " 'regParam:0.01_f1': 0.8482490272373542,\n",
       " 'regParam:1_f1': 0.8482490272373542,\n",
       " 'regParam:10_f1': 0.8482490272373542,\n",
       " 'regParam:0_f1': 0.8449612403100776,\n",
       " 'regParam:0.001_f1': 0.8449612403100776}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_score_all_sorted = dict(sorted(F1_score_all.items(), key=lambda item: item[1], reverse=True))\n",
    "F1_score_all_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------------------------------------+\n",
      "|label|prediction|probability                              |\n",
      "+-----+----------+-----------------------------------------+\n",
      "|0    |1.0       |[0.3802570762636994,0.6197429237363005]  |\n",
      "|1    |1.0       |[0.04794774700918855,0.9520522529908115] |\n",
      "|1    |1.0       |[0.09829421721424084,0.9017057827857592] |\n",
      "|1    |1.0       |[0.015705235426879845,0.9842947645731202]|\n",
      "|1    |1.0       |[0.11858475860662772,0.8814152413933724] |\n",
      "+-----+----------+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create a classifier object and fit to the training data\n",
    "tree = RandomForestClassifier(maxDepth=10, numTrees=50)\n",
    "tree_model = tree.fit(data_train)\n",
    "\n",
    "#label is y(ROE)\n",
    "#features are all of X\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = tree_model.transform(data_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|    6|\n",
      "|    0|       0.0|   28|\n",
      "|    1|       1.0|  103|\n",
      "|    0|       1.0|   12|\n",
      "+-----+----------+-----+\n",
      "\n",
      "0.8791946308724832\n",
      "0.9196428571428571\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "Recall = TP/(TP+FN) #(召回率)\n",
    "Precision = TP/(TP+FP) #(準確率)\n",
    "F1_score = 2 * Precision * Recall / (Precision + Recall)\n",
    "print(accuracy)\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_prediction = prediction.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "prediction_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_label = prediction.select(\"label\").rdd.flatMap(lambda x: x).collect()\n",
    "prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "accuracy_all = {}\n",
    "F1_score_all = {}\n",
    "Depth = [0, 1, 3, 5, 7, 10]\n",
    "tree_num = [10, 50, 100, 150, 200]\n",
    "# Create a classifier object and fit to the training data\n",
    "for d in Depth:\n",
    "    for t in tree_num:\n",
    "        tree = RandomForestClassifier(maxDepth=d, numTrees=t)\n",
    "        tree_model = tree.fit(data_train)\n",
    "\n",
    "        #label is y(ROE)\n",
    "        #features are all of X\n",
    "        # Create predictions for the testing data and take a look at the predictions\n",
    "        prediction = tree_model.transform(data_test)\n",
    "#         prediction.select('label', 'prediction', 'probability').show(5, False)\n",
    "        # Create a confusion matrix\n",
    "#         prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "        # Calculate the elements of the confusion matrix\n",
    "        TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "        TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "        FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "        FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "        # Accuracy measures the proportion of correct predictions\n",
    "        accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "        accuracy_all[f'Tree:{t} & Depth:{d}'] = accuracy\n",
    "        try:\n",
    "            Recall = TP/(TP+FN) #(召回率)\n",
    "            Precision = TP/(TP+FP) #(準確率)\n",
    "            F1_score = 2 * Precision * Recall / (Precision + Recall)\n",
    "            F1_score_all[f'Tree:{t} & Depth:{d}_f1'] = F1_score\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tree:150 & Depth:3': 0.8791946308724832, 'Tree:50 & Depth:10': 0.8791946308724832, 'Tree:150 & Depth:1': 0.87248322147651, 'Tree:50 & Depth:3': 0.87248322147651, 'Tree:200 & Depth:3': 0.87248322147651, 'Tree:100 & Depth:5': 0.87248322147651, 'Tree:150 & Depth:5': 0.87248322147651, 'Tree:200 & Depth:5': 0.87248322147651, 'Tree:10 & Depth:7': 0.87248322147651, 'Tree:200 & Depth:7': 0.87248322147651, 'Tree:100 & Depth:10': 0.87248322147651, 'Tree:50 & Depth:1': 0.8657718120805369, 'Tree:200 & Depth:1': 0.8657718120805369, 'Tree:10 & Depth:5': 0.8657718120805369, 'Tree:100 & Depth:7': 0.8657718120805369, 'Tree:200 & Depth:10': 0.8657718120805369, 'Tree:100 & Depth:3': 0.8590604026845637, 'Tree:50 & Depth:5': 0.8590604026845637, 'Tree:50 & Depth:7': 0.8590604026845637, 'Tree:150 & Depth:7': 0.8590604026845637, 'Tree:150 & Depth:10': 0.8590604026845637, 'Tree:10 & Depth:1': 0.8523489932885906, 'Tree:100 & Depth:1': 0.8523489932885906, 'Tree:10 & Depth:3': 0.8523489932885906, 'Tree:10 & Depth:10': 0.8523489932885906, 'Tree:10 & Depth:0': 0.7315436241610739, 'Tree:50 & Depth:0': 0.2684563758389262, 'Tree:100 & Depth:0': 0.2684563758389262, 'Tree:150 & Depth:0': 0.2684563758389262, 'Tree:200 & Depth:0': 0.2684563758389262}\n"
     ]
    }
   ],
   "source": [
    "accuracy_all_sorted = dict(sorted(accuracy_all.items(), key=lambda item: item[1], reverse=True))\n",
    "F1_score_all_sorted = dict(sorted(F1_score_all.items(), key=lambda item: item[1], reverse=True))\n",
    "print(accuracy_all_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tree:50 & Depth:10_f1': 0.9196428571428571, 'Tree:150 & Depth:3_f1': 0.918918918918919, 'Tree:100 & Depth:5_f1': 0.9155555555555556, 'Tree:150 & Depth:5_f1': 0.9155555555555556, 'Tree:200 & Depth:5_f1': 0.9155555555555556, 'Tree:200 & Depth:7_f1': 0.9155555555555556, 'Tree:100 & Depth:10_f1': 0.9155555555555556, 'Tree:10 & Depth:7_f1': 0.9147982062780269, 'Tree:150 & Depth:1_f1': 0.9140271493212669, 'Tree:50 & Depth:3_f1': 0.9140271493212669, 'Tree:200 & Depth:3_f1': 0.9140271493212669, 'Tree:100 & Depth:7_f1': 0.911504424778761, 'Tree:200 & Depth:10_f1': 0.911504424778761, 'Tree:50 & Depth:1_f1': 0.9090909090909092, 'Tree:200 & Depth:1_f1': 0.9090909090909092, 'Tree:10 & Depth:5_f1': 0.9090909090909092, 'Tree:150 & Depth:7_f1': 0.907488986784141, 'Tree:150 & Depth:10_f1': 0.907488986784141, 'Tree:50 & Depth:7_f1': 0.9066666666666666, 'Tree:50 & Depth:5_f1': 0.9058295964125561, 'Tree:100 & Depth:3_f1': 0.903225806451613, 'Tree:10 & Depth:10_f1': 0.9026548672566371, 'Tree:10 & Depth:1_f1': 0.8981481481481481, 'Tree:100 & Depth:1_f1': 0.8981481481481481, 'Tree:10 & Depth:3_f1': 0.8981481481481481, 'Tree:10 & Depth:0_f1': 0.8449612403100776}\n"
     ]
    }
   ],
   "source": [
    "print(F1_score_all_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|   24|\n",
      "|    0|       0.0|  128|\n",
      "|    1|       1.0|  173|\n",
      "|    0|       1.0|   26|\n",
      "+-----+----------+-----+\n",
      "\n",
      "0.8575498575498576\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tree:50 & Depth:6': 50}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_all = {}\n",
    "\n",
    "Depth = [0, 1, 3, 5, 7, 10]\n",
    "tree = [10, 50, 100, 150, 200]\n",
    "t = 50\n",
    "a =50\n",
    "d =6\n",
    "accuracy_all[f'Tree:{t} & Depth:{d}'] = a\n",
    "accuracy_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
